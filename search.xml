<search>
    
     <entry>
        <title>奇怪现象：两个Consumer消费同一个分区（Partition）</title>
        <url>https://orchidflower.github.io/2022/05/27/Two-Kafka-Consumer-consume-one-partition/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Kafka</tag><tag>Redis</tag><tag>Rebalancing</tag>
        </tags>
        <content type="html"> 最近生产上碰到一个奇怪的问题，现场人员反馈Kafka工作不正常。经过开发人员检查，发现一个奇怪的现象：线上两台服务器竟然在同时消费一个Kafka Topic中的一个分区（Partition）。
1. 背景 我们的程序要实现的功能是这样的：系统会定时扫描库存表，根据库存情况决定是否要执行出库操作。之前是采用定时任务处理，执行策略是1分钟一次，为了防止多台服务器并发执行，使用Quartz集群模式确保定时任务只在一台服务器上执行。最近客户提出需求，某些时候客户希望响应更及时一些，譬如某项请求到达的时候，就要立即检查库存并决定是否需要出库。因此，开发人员对系统进行了调整，改为使用Kafka Consumer来触发扫描库存动作；定时任务和接口处同时负责发送触发库存扫描的消息。
相关的代码如下：
Consumer用来处理扫描库存的功能：
1public class LibraryOutboundTriggerConsumer { 2 private final OutboundService outboundService; 3 private final BoxInfoService boxInfoService; 4 5 @KafkaListener(topics = &amp;#34;${fwm.core.topic.library-outbound-trigger}&amp;#34;) 6 public void consume(ConsumerRecord&amp;lt;String, String&amp;gt; record) { 7 log.info(&amp;#34;\n\n&amp;#34;); 8 log.info(&amp;#34;=====================开始执行出库扫描=====================&amp;#34;); 9 if (boxInfoService.hasBoxUpdateTask()) { 10 log.info(&amp;#34;=====================存在料箱更新任务，执行出库扫描结束=====================&amp;#34;); 11 return; 12 } 13 Stopwatch stopwatch = Stopwatch.createStarted(); 14 try { 15 boxInfoService.startOutboundTask(90); 16 outboundService.outboundTaskScan(); 17 } finally { 18 boxInfoService.stopOutboundTask(); 19 } 20 21 log.info(&amp;#34;=====================执行出库扫描结束,总耗时{}ms=====================&amp;#34;, stopwatch.elapsed(TimeUnit.MILLISECONDS)); 22 } 23} 定时任务相关代码，用来发送触发扫描的Kafka消息：
1public class LibraryScanJob extends QuartzJobBean { 2 private final KafkaTemplate&amp;lt;String, String&amp;gt; kafkaTemplate; 3 private final CoreProperties coreProperties; 4 5 @Override 6 protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { 7 kafkaTemplate.send(coreProperties.getTopic().getLibraryOutboundTrigger(), &amp;#34;1&amp;#34;, &amp;#34;Job Trigger&amp;#34;); 8 } 9} 我们服务端部署的情况是：应用部署在两台服务器上server01，server02；Kafka部署在三台服务器上Kafka01，Kafka02，Kafka03。Consumer负责消费library-outbound-trigger这个Topic，这个Topic虽然被创建为三个分区，但是实际使用中只用了一个分区，这是因为在发送消息的时候指定了Key值。我们知道，默认情况下Kafka会调用Partitioner对发送内容进行分区，默认的分区算法为DefaultPartitioner，简单来说其算法是：如果Key有值，则根据key计算一个Hash值，然后针对分区数取余；如果Key为空，则使用Round-Robin策略进行分区。
DefaultPartitioner is a Partitioner that uses a 32-bit murmur2 hash to compute the partition for a record (with the key defined) or chooses a partition in a round-robin fashion (per the available partitions of the topic).
DefaultPartitioner is the default partitioning strategy (per ProducerConfig.PARTITIONER_CLASS_CONFIG configuration property).
因为上述代码中我们指定了Key固定为1，所以它总会分配到同一个分区中，也就是虽然我们创建了三个分区，实际上应该只有一个分区有数据。通过工具软件查看Kafka中的数据也确实证明了这一点。
因为实际上只有一个分区有数据，所以Consumer应该只在一台服务器上才能够执行。但是经过观察日志发现，两台服务器上都能够看到执行出库扫描这种日志。
2.问题分析 Kafka中一个Partition只能由一个Consumer Group中的一个Consumer消费，这是保证负载均衡的需要，也是Kafka实现消息相对有序性的一个核心设计理念。用过Kafka的人都应该见过这张图： 这张图描述了两个Consumer Group同时在消费一个Topic，不论哪个Consumer Group，对于一个特定的Partition来说，总是只有一个Consumer在消费其中的消息。对我们的系统来说，只有一个分区有数据，按理说应该只有一台服务器消费才正确。
我们在生产环境安装了Kafka管理工具Kowl，经过查看Kafka的运行状态，发现该Topic经常出现没有Consumer消费的情况，而且消费者也不固定；另外，该Topic出现了非常巨大的Lag，消费Offset始终没有更新。明显是Kafka触发Rebalancing导致的。但是因为服务端禁用了Rebalance相关的日志，所以从日志中没有找到相关证据，只能通过分析代码来确认问题。
注意上面Consumer中的代码，Stopwatch计时的范围并不包括对hasBoxUpdateTask的调用，该函数是用于防并发设置的，但是这个函数本身写的有问题，导致执行时间过长。而日志中看到的扫描时间并没有包含这个函数执行的时间，因此没有看出异常情况。hasBoxUpdateTask的代码如下：
1 @Override 2 public boolean hasBoxUpdateTask() { 3 List&amp;lt;String&amp;gt; keys = new ArrayList&amp;lt;&amp;gt;(); 4 redisTemplate.execute((RedisConnection connection) -&amp;gt; { 5 try (Cursor&amp;lt;byte[]&amp;gt; cursor = connection.scan( 6 ScanOptions.scanOptions().count(10).match(BOX_UPDATE_TASK_PREFIX &#43; &amp;#34;*&amp;#34;).build())) { 7 cursor.forEachRemaining(value -&amp;gt; { 8 keys.add(new String(value)); 9 }); 10 } catch (Exception e) { 11 log.error(&amp;#34;hasBoxUpdateTask&amp;#34;, e); 12 } 13 return keys; 14 }); 15 16 return keys.size() &amp;gt; 0; 17 } 可以看到代码里面使用了Redis中生产环境不建议用的Scan指令。虽然Scan命令比Keys *要安全一些，但是同样有可能导致全库扫描：当全库键值很多，匹配数量又很少的时候，一次调用就会触发全库扫描，耗时会很长。经过实验，我们全库19w&#43;，一次不匹配的扫描耗时大概15~20秒。
在Spring中，我们对于Consumer配置如下：
1spring: 2 kafka: 3 consumer: 4 enable-auto-commit: true 5 auto-commit-interval: 1000ms 按照上面的配置，期望的表现是每秒钟提交一次Offset，那为什么会出现Offset始终没有更新的情况呢？
3. 原因解读 以前一直知道Kafka Consumer如果处理时间过长就可能导致问题。这次正好查阅一下文档来明确问题产生的原因及问题的表现。
经过研究，发现之前对于自动提交还有些理解不准确的地方。首先，看一下O&#39;Reilly经典的Kafka: The Definitive Guide中关于自动提交的描述（第4章）：
Automatic Commit
The easiest way to commit offsets is to allow the consumer to do it for you. If you configure enable.auto.commit=true, then every five seconds the consumer will commit the largest offset your client received from poll(). The five-second interval is the default and is controlled by setting auto.commit.interval.ms. Just like everything else in the consumer, the automatic commits are driven by the poll loop. Whenever you poll, the consumer checks if it is time to commit, and if it is, it will commit the offsets it returned in the last poll.
Kafka的自动提交机制是依赖于poll循环机制的：
1while(true) { 2 // 每次调用poll的时候判断是否需要提交offset 3 ConsumerRecords records = consumer.poll(Duration.ofMillis(10000)); 4 processRetrievedRecords(records); 5} 也就是说： Kafka只有在发生一次poll的时候才会将上次处理完的Offset提交上去。 如果消息处理时间过长，就会出现Offset没有来得及提交的情况。
而一次消费时间的长短又与max.poll.records有关：Kafka一次poll可以拉取最多max.poll.records条记录，然后缓存在本地进行处理。只有本地缓存的数据处理完毕，才会再次进行poll。而这个值默认为500。
max.poll.records
The maximum number of records returned in a single call to poll(). Note, that max.poll.records does not impact the underlying fetching behavior. The consumer will cache the records from each fetch request and returns them incrementally from each poll.
Type:	int Default:	500
而判断处理时间是否超时则与max.poll.interval.ms有关：max.poll.interval.ms定义了两次poll之间的时间间隔。
max.poll.interval.ms
The maximum delay between invocations of poll() when using consumer group management. This places an upper bound on the amount of time that the consumer can be idle before fetching more records. If poll() is not called before expiration of this timeout, then the consumer is considered failed and the group will rebalance in order to reassign the partitions to another member. For consumers using a non-null group.instance.id which reach this timeout, partitions will not be immediately reassigned. Instead, the consumer will stop sending heartbeats and partitions will be reassigned after expiration of session.timeout.ms. This mirrors the behavior of a static consumer which has shutdown.
Type:	int Default:	300000 (5 minutes)
可以看到两次poll之间的最长时间为5分钟，如果超过5分钟，则会被判定为Consumer LeaveGroup，然后触发Rebalancing。
综合起来看，这个问题出现的原因应该是这样：
Kafka一次获取了大量的记录，例如500条； 每条记录消费大概占用15~20秒； 记录还没处理完，时间就超过了5分钟，引起了Rebalancing； Rebalancing之后，Consumer由另一台服务器接管，进入上面同样的处理；而此时第一台服务器上的消息还没有处理完毕，也在继续循环处理； 这样两台服务器都在处理数据，但是Offset却永远没有办法更新；看上去就像是两个Consumer在消费同一个Partition。 4. 修改及总结 修改代码，不再使用Redis的Scan指令，提高处理速度，问题得以解决。
两点教训：
在Redis生产环境中不能够使用类似Keys，Scan这种指令，这种指令很容易导致超长的处理时间； Kafka的自动提交机制依赖于poll循环，如果一次消息处理时间过长，就会出问题。最好的方法是提高处理速度；如果实在不行，可以降低每次拉取的记录数，修改max.poll.records参数。在springboot中可以通过spring.kafka.consumer.max-poll-records参数进行修改。 </content>
    </entry>
    
     <entry>
        <title>Flex布局添加滚动条需要注意的规则</title>
        <url>https://orchidflower.github.io/2022/03/02/Adding-Scrollbar-In-Flex-Layout/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Flex</tag><tag>弹性布局</tag>
        </tags>
        <content type="html"> 好久不写前端代码了，有些生疏了。最近用Electron写了一个客户端程序，碰到了Flex布局添加滚动条的问题，耗费了不少时间，所以总结一下要点：
根据滚动条的方向，确定好父元素的flex-flow方向： 如果要设置水平滚动条，那么父元素的flex-flow要设置为row；如果要设置纵向滚动条，那么父元素的flex-flow要设置为column。 元素本身flex设置为1； 滚动方向的大小（宽度或者高度）设置为0，非滚动方向大小设置为100%或者一个你喜欢的宽度； 如果元素本身还有子元素，需要特别注意子元素的高度需要设置为100%。如果没有设置，则会导致子元素本身的高度不受限制，从而撑爆了元素本身。 特别需要注意的就是第4点：布局的时候经常使用到el-row/el-col，其最后生成的html代码就会出现嵌套的div组合，是一个典型的父子结构。这时就要注意在el-col上设置相应的高度为100%，否则就会出现撑爆了的结果。
下面是最终的代码，相关要点添加了注释：
1&amp;lt;div class=&amp;#34;app&amp;#34;&amp;gt; 2 &amp;lt;el-main class=&amp;#34;main&amp;#34;&amp;gt; 3 &amp;lt;div class=&amp;#34;title&amp;#34;&amp;gt;邮件预览&amp;lt;/div&amp;gt; 4 &amp;lt;el-row&amp;gt; 5 &amp;lt;el-col :span=&amp;#34;16&amp;#34;&amp;gt; 6 &amp;lt;div class=&amp;#34;mail-address&amp;#34;&amp;gt;收件人：{{ email }}&amp;lt;/div&amp;gt; 7 &amp;lt;/el-col&amp;gt; 8 &amp;lt;el-col :span=&amp;#34;8&amp;#34; style=&amp;#34;text-align: right; padding-right: 10px&amp;#34;&amp;gt; 9 &amp;lt;el-button type=&amp;#34;primary&amp;#34; @click=&amp;#34;sendMail&amp;#34; :disabled=&amp;#34;!sendEnabled&amp;#34;&amp;gt;发送邮件&amp;lt;/el-button&amp;gt; 10 &amp;lt;/el-col&amp;gt; 11 &amp;lt;/el-row&amp;gt; 12 13 &amp;lt;div class=&amp;#34;mail-content&amp;#34;&amp;gt; 14 &amp;lt;div class=&amp;#34;box-card&amp;#34;&amp;gt; 15 &amp;lt;div v-html=&amp;#34;mailContent&amp;#34;&amp;gt;&amp;lt;/div&amp;gt; 16 &amp;lt;/div&amp;gt; 17 &amp;lt;/div&amp;gt; 18 19 &amp;lt;div class=&amp;#34;title&amp;#34; v-if=&amp;#34;logVisible&amp;#34;&amp;gt;服务日志&amp;lt;/div&amp;gt; 20 &amp;lt;div class=&amp;#34;log-container&amp;#34; v-if=&amp;#34;logVisible&amp;#34;&amp;gt; 21 &amp;lt;div class=&amp;#34;box-card&amp;#34; ref=&amp;#34;logContainer&amp;#34;&amp;gt; 22 &amp;lt;pre&amp;gt;{{ serverLog }}&amp;lt;/pre&amp;gt; 23 &amp;lt;/div&amp;gt; 24 &amp;lt;/div&amp;gt; 25 &amp;lt;/el-main&amp;gt; 26&amp;lt;div&amp;gt; 对应的css代码：
1.app { 2 display: flex; 3 flex-direction: column; 4 height: 100vh; 5} 6 7.main { 8 display:flex; /* flex布局 */ 9 flex-direction: column; /* 垂直排列 */ 10} 11 12.title { 13 font-size: 16px; 14 font-weight: 400; 15 color: #1f2f3d; 16 line-height: 1; 17 position: relative; 18 padding: 10px 0 10px 20px; 19 box-sizing: border-box; 20 display: flex; 21 align-items: center; 22 background: #ffffff; 23} 24 25.box-card { 26 margin: 0 10px 10px; 27 height: 100%; /* 子元素的高度设置为100%，防止撑爆父元素 */ 28 overflow-y: scroll; 29 border: 1px solid #E0E0E0; 30 padding: 0 10px; 31 background: #f7f7f7; 32} 33 34.mail-address { 35 font-size: 14px; 36 padding: 10px 20px 10px 20px; 37 text-decoration:underline; 38} 39 40.mail-content { 41 flex: 3 0 auto; /* 邮件显示区与log区比例3：2 */ 42 font-size: 16px; 43 height: 0; /* height设置成0，让flex布局处理大小 */ 44 margin-bottom: 20px; 45} 46 47.log-container { 48 flex: 2 0 auto; /* 邮件显示区与log区比例3：2 */ 49 height: 0; /* height设置成0，让flex布局处理大小 */ 50 padding-bottom: 20px; /* 避免被footer覆盖 */ 51} 52 53.log-container pre { 54 font-size: 14px; 55} 附录、参考资料 弹性盒子Flex Box滚动条原理，避免被撑开，永不失效 </content>
    </entry>
    
     <entry>
        <title>RSA证书格式</title>
        <url>https://orchidflower.github.io/2021/11/26/RSA-certificate-format/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>证书</tag><tag>RSA</tag>
        </tags>
        <content type="html"> 1. TL;DR # -----BEGIN CERTIFICATE----- 开头的是证书。 # -----BEGIN RSA PRIVATE KEY----- 开头是遵循的PKCS#1规范，其内容只是一个RSA私钥。它本质上只是来自PKCS#8的关键对象，但前面没有版本或算法标识符。 # -----BEGIN PRIVATE KEY----- 开头遵循的是PKCS#8规范，并指示密钥类型包含在密钥数据本身中。 2. 更详细 下面内容摘自参考资料，供有需要的人参考。
2.1 RSA Public Key File (PKCS#1) The RSA Public key PEM file is specific for RSA keys.
It starts and ends with the tags:
1-----BEGIN RSA PUBLIC KEY----- 2BASE64 ENCODED DATA 3-----END RSA PUBLIC KEY----- Within the base64 encoded data the following DER structure is present:
1RSAPublicKey ::= SEQUENCE { 2 modulus INTEGER, -- n 3 publicExponent INTEGER -- e 4} 2.2 RSA Private Key File (PKCS#1) The RSA private key PEM file is specific for RSA keys.
It starts and ends with the tags:
1-----BEGIN RSA PRIVATE KEY----- 2BASE64 ENCODED DATA 3-----END RSA PRIVATE KEY----- Within the base64 encoded data the following DER structure is present:
1RSAPrivateKey ::= SEQUENCE { 2 version Version, 3 modulus INTEGER, -- n 4 publicExponent INTEGER, -- e 5 privateExponent INTEGER, -- d 6 prime1 INTEGER, -- p 7 prime2 INTEGER, -- q 8 exponent1 INTEGER, -- d mod (p-1) 9 exponent2 INTEGER, -- d mod (q-1) 10 coefficient INTEGER, -- (inverse of q) mod p 11 otherPrimeInfos OtherPrimeInfos OPTIONAL 12} 2.3 Public Key File (PKCS#8) Because RSA is not used exclusively inside X509 and SSL/TLS, a more generic key format is available in the form of PKCS#8, that identifies the type of public key and contains the relevant data.
It starts and ends with the tags:
1-----BEGIN PUBLIC KEY----- 2BASE64 ENCODED DATA 3-----END PUBLIC KEY----- Within the base64 encoded data the following DER structure is present:
1PublicKeyInfo ::= SEQUENCE { 2 algorithm AlgorithmIdentifier, 3 PublicKey BIT STRING 4} 5 6AlgorithmIdentifier ::= SEQUENCE { 7 algorithm OBJECT IDENTIFIER, 8 parameters ANY DEFINED BY algorithm OPTIONAL 9} So for an RSA public key, the OID is 1.2.840.113549.1.1.1 and there is a RSAPublicKey as the PublicKey key data bitstring.
2.4 Private Key File (PKCS#8) Because RSA is not used exclusively inside X509 and SSL/TLS, a more generic key format is available in the form of PKCS#8, that identifies the type of private key and contains the relevant data.
The unencrypted PKCS#8 encoded data starts and ends with the tags:
1-----BEGIN PRIVATE KEY----- 2BASE64 ENCODED DATA 3-----END PRIVATE KEY----- Within the base64 encoded data the following DER structure is present:
1PrivateKeyInfo ::= SEQUENCE { 2 version Version, 3 algorithm AlgorithmIdentifier, 4 PrivateKey OCTET STRING 5} 6 7AlgorithmIdentifier ::= SEQUENCE { 8 algorithm OBJECT IDENTIFIER, 9 parameters ANY DEFINED BY algorithm OPTIONAL 10} So for an RSA private key, the OID is 1.2.840.113549.1.1.1 and there is a RSAPrivateKey as the PrivateKey key data octet string.
The encrypted PKCS#8 encoded data start and ends with the tags:
1-----BEGIN ENCRYPTED PRIVATE KEY----- 2BASE64 ENCODED DATA 3-----END ENCRYPTED PRIVATE KEY----- Within the base64 encoded data the following DER structure is present:
1EncryptedPrivateKeyInfo ::= SEQUENCE { 2 encryptionAlgorithm EncryptionAlgorithmIdentifier, 3 encryptedData EncryptedData 4} 5 6EncryptionAlgorithmIdentifier ::= AlgorithmIdentifier 7 8EncryptedData ::= OCTET STRING 9The EncryptedData OCTET STRING is a PKCS#8 PrivateKeyInfo (see above). 附录、参考资料 openssl – “BEGIN RSA PRIVATE KEY”和“BEGIN PRIVATE KEY”之间的区别是什么？ ASN.1 key structures in DER and PEM </content>
    </entry>
    
     <entry>
        <title>Jenkins工作空间页面崩溃问题解决</title>
        <url>https://orchidflower.github.io/2021/10/22/Jenkins-crashed-in-workspace-page/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Jenkins</tag>
        </tags>
        <content type="html"> 1. 问题 最近发现一个问题：在 Jenkins 中打开某些项目的工作空间（WorkSpace）的时候，页面会崩溃，显示如下的错误信息： 查看 Jenkins 日志发现如下错误信息，提示的是路径无效错误（InvalidPathException），该目录应该是中文名字，猜测是编码转换出了错误。 2. 解决 由于是使用 Docker 运行的 Jenkins，登录进 Jenkins 容器内部，查看对应的目录： 发现在容器内部看到的目录就是乱码了。而在外部环境可以正常显示目录：
所以猜测应该是 Docker 容器加载目录过程中编码错误，导致转换出错。经过查找，修改如下即可：
1services: 2 jenkins: 3 image: jenkins/jenkins:2.303.1 4 environment: 5 # 注意，此处不能用en_US.UTF-8，因为该容器中没有该locale，只能用C.UTF-8 6 - LANG=C.UTF-8 需要注意的是不能够使用en_US.UTF-8。设置成这个没有解决问题，浪费了很多时间。
3. 备注 另外，网上还有说法要添加 JAVA_OPTS=&amp;quot;-Dsun.jnu.encoding=UTF-8 -Dfile.encoding=UTF-8&amp;quot;，但是经过实验发现没有用处。我这个问题原因在于 Docker 内部文件系统就编码不正确，Java 层面的修改不能够解决问题。
附录、参考资料 解决docker容器中文乱码，修改docker容器编码格式 【经验证无效】jenkins乱码问题 </content>
    </entry>
    
     <entry>
        <title>Vue进行条件编译发布</title>
        <url>https://orchidflower.github.io/2021/09/24/Vue-compile-on-condition/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Vue</tag><tag>脚手架</tag>
        </tags>
        <content type="html"> 最近碰到一个问题：公司新申请了一个公众号，这个新公众号的功能与之前一个公众号功能基本一致，只是两个公众号的用户协议有些区别，所以就会公用一份代码。现在需要解决发布的问题，需要确保发布到两个不同公众号的页面是正确的，不同公众号的用户看到正确的用户协议。
经过上网查找方案，发现 Vue 脚手架中提供的 vue-cli-service 内置了类似的功能，可以用来实现类似功能，这里简单说一下其涉及到的改动要点，更多细节可以参考vue-cli的文档模式和环境变量。
1. 官方方案解读 1.1 模式 模式（mode）是 Vue 脚手架项目的一个重要概念。默认情况下，一个脚手架项目会有三个模式：
development 模式用于 vue-cli-service serve test 模式用于 vue-cli-service test:unit production 模式用于 vue-cli-service build 和 vue-cli-service test:e2e 我们通常用的开发命令 yarn serve，yarn build 都是由 package.json 封装的 Vue 脚手架命令的简化版：
1{ 2 &amp;#34;name&amp;#34;: &amp;#34;mp-web&amp;#34;, 3 &amp;#34;version&amp;#34;: &amp;#34;0.1.0&amp;#34;, 4 &amp;#34;private&amp;#34;: true, 5 &amp;#34;scripts&amp;#34;: { 6 &amp;#34;serve&amp;#34;: &amp;#34;vue-cli-service serve&amp;#34;, 7 &amp;#34;build&amp;#34;: &amp;#34;vue-cli-service build&amp;#34;, 8 &amp;#34;lint&amp;#34;: &amp;#34;vue-cli-service lint&amp;#34; 9 }, 10} 可以看到，yarn serve 对应的就是 development 模式；yarn build 对应的是 production 模式。
1.2 环境变量 NodeJS 应用中有一个非常重要的环境变量 NODE_ENV。Vue脚手架中也使用了这个环境变量。NODE_ENV 决定应用运行的模式，是开发，生产还是测试，因此也决定了创建哪种 webpack 配置。文档中说明如下：
例如通过将 NODE_ENV 设置为 &amp;ldquo;test&amp;rdquo;，Vue CLI 会创建一个优化过后的，并且旨在用于单元测试的 webpack 配置，它并不会处理图片以及一些对单元测试非必需的其他资源。
同理，NODE_ENV=development 创建一个 webpack 配置，该配置启用热更新，不会对资源进行 hash 也不会打出 vendor bundles，目的是为了在开发的时候能够快速重新构建。
当你运行 vue-cli-service build 命令时，无论你要部署到哪个环境，应该始终把 NODE_ENV 设置为 &amp;ldquo;production&amp;rdquo; 来获取可用于部署的应用程序。
除了 NODE_ENV 外，还可以指定其他环境变量。在文档中提到可以在 .env 或 .env.[mode]文件中指定环境变量，起始还可以直接在命令行中通过 export 方式设置环境变量。需要特别注意的是，不是所有的本地环境变量都可以在代码中能够见到。按照文档的说明，只有如下几个可以：
NODE_ENV； BASE_URL； VUE_APP_开头的环境变量； 其他的环境变量，会被脚手架过滤掉，以防止关键信息泄露。 2. 改造项目 根据官方提供的功能，对项目进行了调整，这里记录一下调整的主要内容，以此记录一下。
2.1 用户协议 两份用户协议分别定义成了两个组件，然后在使用的页面根据情况选择显示。代码实例如下：
1&amp;lt;template&amp;gt; 2 &amp;lt;div&amp;gt; 3 &amp;lt;div class=&amp;#34;content&amp;#34;&amp;gt; 4 &amp;lt;!-- &amp;lt;div class=&amp;#34;title&amp;#34;&amp;gt;协议内容&amp;lt;/div&amp;gt; --&amp;gt; 5 &amp;lt;div class=&amp;#34;agreementCont&amp;#34; v-if=&amp;#34;site === &amp;#39;palytech&amp;#39;&amp;#34;&amp;gt; 6 &amp;lt;v-nycont&amp;gt;&amp;lt;/v-nycont&amp;gt; 7 &amp;lt;/div&amp;gt; 8 &amp;lt;div class=&amp;#34;agreementCont&amp;#34; v-else&amp;gt; 9 &amp;lt;v-cont&amp;gt;&amp;lt;/v-cont&amp;gt; 10 &amp;lt;/div&amp;gt; 11 &amp;lt;/div&amp;gt; 12&amp;lt;/template&amp;gt; 13&amp;lt;script lang=&amp;#34;ts&amp;#34;&amp;gt; 14import agreementCont from &amp;#39;@/components/agreementCont/content.vue&amp;#39;; 15import nyContent from &amp;#39;@/components/agreementCont/nyContent.vue&amp;#39;; 16@Component({ 17 components: { 18 &amp;#39;v-cont&amp;#39;: agreementCont, 19 &amp;#39;v-nycont&amp;#39;: nyContent 20 } 21}) 22export default class infoPerfection extends Vue { 23 site: string | null = &amp;#39;&amp;#39;; 24 async mounted() { 25 this.site = localStorage.getItem(&amp;#39;site&amp;#39;); 26 } 27... 页面中使用site这个变量来决定显示哪一个用户协议。而这个site参数是从localStorage中获取到的。下面会说到这个site参数是如何写到localStorage中的。
2.2 main.ts 在 Vue 代码入口的main.ts中，写入如下代码，这段代码会将site参数写入localStorage。注意这里用到了VUE_APP_SITE这个环境变量。
1import Vue from &amp;#39;vue&amp;#39;; 2import App from &amp;#39;./App.vue&amp;#39;; 3 4if (process.env.VUE_APP_SITE === &amp;#39;zhongbl&amp;#39;) { 5 console.log(&amp;#39;生产环境 zhongbl&amp;#39;); 6 localStorage.setItem(&amp;#39;site&amp;#39;, &amp;#39;zhongbl&amp;#39;); 7} else if (process.env.VUE_APP_SITE === &amp;#39;palytech&amp;#39;) { 8 console.log(&amp;#39;生产环境 palytech&amp;#39;); 9 localStorage.setItem(&amp;#39;site&amp;#39;, &amp;#39;palytech&amp;#39;); 10} else { 11 console.log(&amp;#39;开发环境 eveus&amp;#39;); 12 localStorage.setItem(&amp;#39;site&amp;#39;, &amp;#39;eveus&amp;#39;); 13} 2.3 环境变量设置 考虑到我们的发布脚本中硬编码了yarn build，所以环境变量VUE_APP_SITE我是采用export方式设置的。例如编译的时候用：
1export VUE_APP_SITE=zhongbl 2# 调用原先的发布脚本 3bash /opt/release/build-deploy-vue.sh -p $Project -s $Service 需要注意的是：必须使用export将环境变量设置出去，要不然在另一个shell脚本中会看不到这个变量。 另外，还可以在.env文件中设置一个默认值，当不在命令行中export的时候，就会用到.env文件中设置的值。
3. 其他的一些备忘 3.1 编译结果 2.2中的那段代码经过编译后，会根据环境变量的情况进行优化，去掉不需要的内容。例如，当VUE_APP_SITE设置成palytech的时候，最后生成的代码等效于：
1 console.log(&amp;#39;生产环境 palytech&amp;#39;); 2 localStorage.setItem(&amp;#39;site&amp;#39;, &amp;#39;palytech&amp;#39;); 其他两个条件中的内容根本不会在编译结果中存在！这点挺有意思的。
附录、参考资料 模式和环境变量 </content>
    </entry>
    
     <entry>
        <title>MySQL如何保存emoji字符</title>
        <url>https://orchidflower.github.io/2021/07/22/How-Could-MySQL-Save-emoji/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Java</tag><tag>MyBatis</tag><tag>MySQL</tag>
        </tags>
        <content type="html"> 1. 问题 1.1 发现问题 最近生产环境日志中报了一个异常：
12021-07-11 20:54:41.632 ERROR 26289 --- [XNIO-1 task-11] c.e.t.s.t.mp.WxMpMessageRouterService : 2### Error updating database. Cause: java.sql.SQLException: Incorrect string value: &amp;#39;\xF0\x9F\xA6\x84&amp;#39; for column &amp;#39;NICK_NAME&amp;#39; at row 1 3### The error may exist in com/eveus/tap/account/mapper/AccountMapper.java (best guess) 4### The error may involve com.eveus.tap.account.mapper.AccountMapper.insert-Inline 5### The error occurred while setting parameters 6### SQL: INSERT INTO tap_account ( open_id, avatar, nick_name, country, province, city, gender, secret, status, IS_DISABLED, is_subscribe, create_time, update_time ) VALUES 7 ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) 8### Cause: java.sql.SQLException: Incorrect string value: &amp;#39;\xF0\x9F\xA6\x84&amp;#39; for column &amp;#39;NICK_NAME&amp;#39; at row 1 9; uncategorized SQLException; SQL state [HY000]; error code [1366]; Incorrect string value: &amp;#39;\xF0\x9F\xA6\x84&amp;#39; for column &amp;#39;NICK_NAME&amp;#39; at row 1; nested exception is java.sql.SQLException: 10 Incorrect string value: &amp;#39;\xF0\x9F\xA6\x84&amp;#39; for column &amp;#39;NICK_NAME&amp;#39; at row 1 11 12org.springframework.jdbc.UncategorizedSQLException: 13### Error updating database. Cause: java.sql.SQLException: Incorrect string value: &amp;#39;\xF0\x9F\xA6\x84&amp;#39; for column &amp;#39;NICK_NAME&amp;#39; at row 1 14### The error may exist in com/eveus/tap/account/mapper/AccountMapper.java (best guess) 15### The error may involve com.eveus.tap.account.mapper.AccountMapper.insert-Inline 16### The error occurred while setting parameters 17### SQL: INSERT INTO tap_account ( open_id, avatar, nick_name, country, province, city, gender, secret, status, IS_DISABLED, is_subscribe, create_time, update_time ) VALUES 18 ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) 19### Cause: java.sql.SQLException: Incorrect string value: &amp;#39;\xF0\x9F\xA6\x84&amp;#39; for column &amp;#39;NICK_NAME&amp;#39; at row 1 20; uncategorized SQLException; SQL state [HY000]; error code [1366]; Incorrect string value: &amp;#39;\xF0\x9F\xA6\x84&amp;#39; for column &amp;#39;NICK_NAME&amp;#39; at row 1; nested exception is java.sql.SQLException: 21 Incorrect string value: &amp;#39;\xF0\x9F\xA6\x84&amp;#39; for column &amp;#39;NICK_NAME&amp;#39; at row 1 22 at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89) 23 at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) 24 at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81) 25 at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:88) 26 at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:440) 27 at com.sun.proxy.$Proxy134.insert(Unknown Source) 28 at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:271) 29 at com.baomidou.mybatisplus.core.override.MybatisMapperMethod.execute(MybatisMapperMethod.java:60) 30 at com.baomidou.mybatisplus.core.override.MybatisMapperProxy.invoke(MybatisMapperProxy.java:96) 31 at com.sun.proxy.$Proxy186.insert(Unknown Source) 32 at com.baomidou.mybatisplus.extension.service.IService.save(IService.java:59) 33 at com.eveus.tap.account.service.impl.AccountServiceImpl.addAccount(AccountServiceImpl.java:151) 34 at com.eveus.tap.account.service.impl.AccountServiceImpl.ensureLoad(AccountServiceImpl.java:226) 35 at com.eveus.tap.account.service.impl.AccountServiceImpl$$FastClassBySpringCGLIB$$34fe95c8.invoke(&amp;lt;generated&amp;gt;) 36 at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) 37 at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:769) 38 at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) 39 at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) 40 at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:95) 41 at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) 42 at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.proceed(CglibAopProxy.java:747) 43 at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:689) 44 at com.eveus.tap.account.service.impl.AccountServiceImpl$$EnhancerBySpringCGLIB$$cbb1e26b.ensureLoad(&amp;lt;generated&amp;gt;) 45 at com.eveus.tap.server.taxer.mp.handler.SubscribeHandler.handle(SubscribeHandler.java:54) 46 at me.chanjar.weixin.mp.api.WxMpMessageRouterRule.service(WxMpMessageRouterRule.java:226) 47 at me.chanjar.weixin.mp.api.WxMpMessageRouter.route(WxMpMessageRouter.java:203) 48 at me.chanjar.weixin.mp.api.WxMpMessageRouter.route(WxMpMessageRouter.java:154) 49 at me.chanjar.weixin.mp.api.WxMpMessageRouter.route(WxMpMessageRouter.java:233) 看错误信息是因为 MySQL 字符编码不正确导致无法保存特殊字符导致的。把字符还原一下，发现 \xF0\x9F\xA6\x84 代表的字符内容是：🦄，是一个 Emoji 字符。
当使用对 utf8 编码的时候，和一般汉字占用3个字节不同，Emoji 字符的编码会比较特殊一点，占用4个字节。而由于历史的原因，MySQL 使用的 utf8 编码最长支持3个字节，如果要保存4个字节的 unicode，则需要使用 utf8mb4 编码。上述错误应该是因此而出。
1.2 寻找原因 让我奇怪的是，这个问题应该不会出现才对啊，因为这个表需要存储从微信获取的用户昵称，当时已经考虑了可能存在 Emoji 字符，因此该表的编码已经被修改成了 utf8mb4 。查看一下表结构，现有的表结构定义如下：
1CREATE TABLE `tap_account` ( 2 `ID` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &amp;#39;主键&amp;#39;, 3 `AVATAR` varchar(256) DEFAULT NULL COMMENT &amp;#39;头像,微信授权,用户头像，最后一个数值代表正方形头像大小（有0、46、64、96、132数值可选，0代表640*640正方形头像）&amp;#39;, 4 `NICK_NAME` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci DEFAULT NULL, 5 ... 6 PRIMARY KEY (`ID`), 7 UNIQUE KEY `tap_account_OPEN_ID_uindex` (`OPEN_ID`) 8) ENGINE=InnoDB AUTO_INCREMENT=72 DEFAULT CHARSET=utf8mb4 COMMENT=&amp;#39;自然人账号表&amp;#39;; 可以看到目前的字符集已经配置成了 utf8mb4 ，按理说应该能够保存成功才对。
为了验证一下数据库是否修改正确，直接使用sql修改记录试试：
1update tap_account set nick_name=&amp;#39;千面怪🦄&amp;#39; where id=1; 发现更新确实可以成功，没有错误发生；而且也可以正常查询到的修改后的结果。这说明表方面应该没有问题。
因为之前考虑到其他表没有存储 Emoji 表情的需要，所以没有在数据库层面整体修改编码。也就是有一部分表还是使用 utf8 编码，只有这个表 tap_account 使用了 utf8mb4 编码。看一下 MySQL 的系统变量：
1MySQL [tap_admin]&amp;gt; show variables like &amp;#39;%character%&amp;#39;; 2&#43;--------------------------&#43;---------&#43; 3| Variable_name | Value | 4&#43;--------------------------&#43;---------&#43; 5| character_set_client | utf8mb4 | 6| character_set_connection | utf8mb4 | 7| character_set_database | utf8 | 8| character_set_filesystem | binary | 9| character_set_results | utf8mb4 | 10| character_set_server | utf8 | 11| character_set_system | utf8 | 12| character_sets_dir | | 13&#43;--------------------------&#43;---------&#43; 148 rows in set (0.001 sec) 可以看到服务器默认的编码（character_set_server）为 utf8 。
是不是因为这个原因导致的问题呢？
2. 关于编码自动检测 我使用的 MySQL 库为 mysql-connector-java，版本为 8.0.19。配置的连接字符串如下：
1spring: 2 datasource: 3 url: jdbc:mysql://rm-uecp.mysql.rds.aliyuncs.com:3306/tap_admin?useUnicode=true&amp;amp;serverTimezone=GMT%2b8:00 连接字符串中只是使用了useUnicode开启了unicode支持，并没有指定具体的字符编码。这时会用到 mysql-connector-java 的自动检测机制。根据 MySQL 官方文档的说明，这个检测机制会用到 character_set_server 这个参数。
The character encoding between client and server is automatically detected upon connection (provided that the Connector/J connection properties characterEncoding and connectionCollation are not set). You specify the encoding on the server using the system variable character_set_server (for more information, see Server Character Set and Collation). The driver automatically uses the encoding specified by the server. For example, to use the 4-byte UTF-8 character set with Connector/J, configure the MySQL server with character_set_server=utf8mb4, and leave characterEncoding and connectionCollation out of the Connector/J connection string. Connector/J will then autodetect the UTF-8 setting.
当在连接字符串中没有设置 charcterEncoding 的时候，将自动使用MySQL系统变量 character_set_server 中指定的字符集。如果需要覆盖以上检测机制，可以指定 characterEncoding 变量：
To override the automatically detected encoding on the client side, use the characterEncoding property in the connection URL to the server. Use Java-style names when specifying character encodings. The following table lists MySQL character set names and their corresponding Java-style names:
特别的对于 characterEncoding=utf8 ，不同版本的 mysql-connector-java 处理上是有些区别的： 简单来说：8.0.13及以上版本，会自动使用 utf8mb4；而之前版本使用的则是 utf8mb3（也就是通常的utf8编码）。
3. 原因分析 现在来看一下为什么数据库能够保存 Emoji 字符，但是通过 Java 却无法保存。
3.1 utf8mb4 支持条件 首先总结一下支持 utf8mb4 需要的前置条件。
3.1.1 数据库版本 utf8mb4 需要的最低mysql版本为 5.5.3&#43;，若不是，则需要升级。可以使用以下 SQL 查询一下当前的版本号：
1select version(); 3.1.2 修改数据库、表或字段的字符集 可以使用以下SQL修改数据库、表或字段支持 utf8mb4 编码：
1-- 修改数据库编码 2ALTER DATABASE database_name CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci; 3-- 修改表编码 4ALTER TABLE table_name CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; 5-- 修改字段编码 6ALTER TABLE table_name CHANGE column_name VARCHAR(191) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; 经过实验，确认可以只修改表支持 utf8mb4 即可，数据库层面可以保持 utf8 编码不用修改。
3.1.3 MySQL客户端 mysql connector需要至少大于5.1.13，否则无法支持 utf8mb4。另外还要注意8.0.13前后支持形式有所区别。
3.1.4 链接字符串 需要在 mysql-connector-java 链接字符串中增加 useUnicode=true&amp;amp;characterEncoding=utf8mb4 来开启 utf8mb4 支持。
3.2 结论 我用的mysql-connector-java版本是 8.0.19，大于8.0.13，所以使用 characterEncoding=utf8 就相当于支持了 utf8mb4 编码。
但是因为我没有将整个数据库的编码改为 utf8mb4 ，所以不指定该参数的时候会被自动检测为 utf8 编码，导致保存失败。
最后将连接字符串改成这样问题就解决了：
1spring: 2 datasource: 3 url: jdbc:mysql://rm-uecp.mysql.rds.aliyuncs.com:3306/tap_admin?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;serverTimezone=Asia/Shanghai 4. 总结 总结一下，这个问题出现的原因是因为没有更改数据库的字符编码，导致 mysql-connector-java 的自动检测机制做出了错误的假设，没有设置为需要的 utf8mb4 编码。
另外从网上查到的资料一般说的都是同时修改数据库、表的字符集，没有我这种只修改表的字符集，而数据库字符集没更改的情况。遇到这种特殊情况还是要自己多做实验，实践出真知。
附录、参考资料 mysql/Java服务端对emoji的支持 RDS MySQL字符集相关说明 Chapter 10 Character Sets, Collations, Unicode 6.7 Using Character Sets and Unicode </content>
    </entry>
    
     <entry>
        <title>MyBatis Plus中主键生成方式ASSIGN_ID的算法分析</title>
        <url>https://orchidflower.github.io/2021/07/02/MyBatis-ASSIGN_ID-Algorithm/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Java</tag><tag>MyBatis</tag>
        </tags>
        <content type="html"> MyBatis Plus 中提供了 ASSIGN_ID 这种方式生成主键，使用起来非常方便，只要在PO上定义一下就可以了，例如：
1public class Order extends Model&amp;lt;Order&amp;gt; { 2 3 @TableId(value = &amp;#34;id&amp;#34;, type = IdType.ASSIGN_ID) 4 private Long id; 5 6 //... 7} 这样在保存的时候，MyBatis Plus会负责生成主键值，自动设置到字段id中。 一直好奇这个主键是怎么生成的，抽时间查看了一下源码，特意记录一下。
1. MybatisDefaultParameterHandler 通过看MyBatis Plus的文档，发现这个主键生成过程应该是在ParameterHandler中进行处理的。在MyBatis Plus中ParameterHandler是用来设置参数规则的，当StatementHandler调用prepare方法之后，接下来就是调用它来进行设置参数。
对ASSIGN_ID进行处理的的地方是在MybatisDefaultParameterHandler中（在3.4.x版本中，该类改为MybatisParameterHandler），该类在包com.baomidou.mybatisplus.core中。对主键处理的代码在populateKeys这个方法中：
1 /** 2 * 填充主键 3 * 4 * @param tableInfo 数据库表反射信息 5 * @param metaObject 元数据对象 6 * @param entity 实体信息 7 */ 8 protected static void populateKeys(TableInfo tableInfo, MetaObject metaObject, Object entity) { 9 final IdType idType = tableInfo.getIdType(); 10 final String keyProperty = tableInfo.getKeyProperty(); 11 if (StringUtils.isNotBlank(keyProperty) &amp;amp;&amp;amp; null != idType &amp;amp;&amp;amp; idType.getKey() &amp;gt;= 3) { 12 final IdentifierGenerator identifierGenerator = GlobalConfigUtils.getGlobalConfig(tableInfo.getConfiguration()).getIdentifierGenerator(); 13 Object idValue = metaObject.getValue(keyProperty); 14 // 此处判断是否idValue是否存在，不存在的话就要根据类型进行计算赋值 15 if (StringUtils.checkValNull(idValue)) { 16 if (idType.getKey() == IdType.ASSIGN_ID.getKey()) { // 此处处理ASSIGN_ID类型的主键生成算法 17 if (Number.class.isAssignableFrom(tableInfo.getKeyType())) { 18 // 此处调用IdentitifierGenerator生成主键 19 metaObject.setValue(keyProperty, identifierGenerator.nextId(entity)); 20 } else { 21 metaObject.setValue(keyProperty, identifierGenerator.nextId(entity).toString()); 22 } 23 } else if (idType.getKey() == IdType.ASSIGN_UUID.getKey()) { // 此处处理ASSIGN_UUID类型的主键生成算法 24 metaObject.setValue(keyProperty, identifierGenerator.nextUUID(entity)); 25 } 26 } 27 } 28 } 2. DefaultIdentifierGenerator 此类在包com.baomidou.mybatisplus.core.incrementer中。代码如下：
1public class DefaultIdentifierGenerator implements IdentifierGenerator { 2 3 private final Sequence sequence; 4 5 public DefaultIdentifierGenerator() { 6 this.sequence = new Sequence(); 7 } 8 9 public DefaultIdentifierGenerator(long workerId, long dataCenterId) { 10 this.sequence = new Sequence(workerId, dataCenterId); 11 } 12 13 public DefaultIdentifierGenerator(Sequence sequence) { 14 this.sequence = sequence; 15 } 16 17 @Override 18 public Long nextId(Object entity) { 19 // 此处调用Sequence的nextId算法生成真正的主键值 20 return sequence.nextId(); 21 } 22} 3. Sequence 此类在包com.baomidou.mybatisplus.core.toolkit中。注意：以下代码进行了缩减。
1public class Sequence { 2 /** 3 * 时间起始标记点，作为基准，一般取系统的最近时间（一旦确定不能变动） 4 */ 5 private final long twepoch = 1288834974657L; 6 /** 7 * 机器标识位数 8 */ 9 private final long workerIdBits = 5L; 10 private final long datacenterIdBits = 5L; 11 private final long maxWorkerId = -1L ^ (-1L &amp;lt;&amp;lt; workerIdBits); 12 private final long maxDatacenterId = -1L ^ (-1L &amp;lt;&amp;lt; datacenterIdBits); 13 /** 14 * 毫秒内自增位 15 */ 16 private final long sequenceBits = 12L; 17 private final long workerIdShift = sequenceBits; 18 private final long datacenterIdShift = sequenceBits &#43; workerIdBits; 19 /** 20 * 时间戳左移动位 21 */ 22 private final long timestampLeftShift = sequenceBits &#43; workerIdBits &#43; datacenterIdBits; 23 private final long sequenceMask = -1L ^ (-1L &amp;lt;&amp;lt; sequenceBits); 24 25 26 public Sequence() { 27 this.datacenterId = getDatacenterId(maxDatacenterId); 28 this.workerId = getMaxWorkerId(datacenterId, maxWorkerId); 29 } 30 31 32 /** 33 * 数据标识id部分 34 */ 35 protected static long getDatacenterId(long maxDatacenterId) { 36 long id = 0L; 37 try { 38 InetAddress ip = InetAddress.getLocalHost(); 39 NetworkInterface network = NetworkInterface.getByInetAddress(ip); 40 if (network == null) { 41 id = 1L; 42 } else { 43 byte[] mac = network.getHardwareAddress(); 44 if (null != mac) { 45 // mac地址最后两节，例如对Mac地址00:15:5d:2d:0b:01，下面的结果是id=0x0b01 46 id = ((0x000000FF &amp;amp; (long) mac[mac.length - 1]) | (0x0000FF00 &amp;amp; (((long) mac[mac.length - 2]) &amp;lt;&amp;lt; 8))) &amp;gt;&amp;gt; 6; 47 // 这里是计算除以32后得到的余数 48 id = id % (maxDatacenterId &#43; 1); 49 } 50 } 51 } catch (Exception e) { 52 logger.warn(&amp;#34; getDatacenterId: &amp;#34; &#43; e.getMessage()); 53 } 54 return id; 55 } 56 57 /** 58 * 获取 maxWorkerId 59 */ 60 protected static long getMaxWorkerId(long datacenterId, long maxWorkerId) { 61 StringBuilder mpid = new StringBuilder(); 62 mpid.append(datacenterId); 63 // 此处返回的是the name representing the running Java virtual machine 64 String name = ManagementFactory.getRuntimeMXBean().getName(); 65 if (StringUtils.isNotBlank(name)) { 66 /* 67 * GET jvmPid 68 */ 69 mpid.append(name.split(StringPool.AT)[0]); 70 } 71 /* 72 * MAC &#43; PID 的 hashcode 获取16个低位 73 */ 74 return (mpid.toString().hashCode() &amp;amp; 0xffff) % (maxWorkerId &#43; 1); 75 } 76 77 /** 78 * 获取下一个 ID 79 * 80 * @return 下一个 ID 81 */ 82 public synchronized long nextId() { 83 long timestamp = timeGen(); 84 //闰秒 85 if (timestamp &amp;lt; lastTimestamp) { 86 long offset = lastTimestamp - timestamp; 87 if (offset &amp;lt;= 5) { 88 try { 89 wait(offset &amp;lt;&amp;lt; 1); 90 timestamp = timeGen(); 91 if (timestamp &amp;lt; lastTimestamp) { 92 throw new RuntimeException(String.format(&amp;#34;Clock moved backwards. Refusing to generate id for %d milliseconds&amp;#34;, offset)); 93 } 94 } catch (Exception e) { 95 throw new RuntimeException(e); 96 } 97 } else { 98 throw new RuntimeException(String.format(&amp;#34;Clock moved backwards. Refusing to generate id for %d milliseconds&amp;#34;, offset)); 99 } 100 } 101 102 if (lastTimestamp == timestamp) { 103 // 相同毫秒内，序列号自增 104 sequence = (sequence &#43; 1) &amp;amp; sequenceMask; 105 if (sequence == 0) { 106 // 同一毫秒的序列数已经达到最大 107 timestamp = tilNextMillis(lastTimestamp); 108 } 109 } else { 110 // 不同毫秒内，序列号置为 1 - 3 随机数 111 sequence = ThreadLocalRandom.current().nextLong(1, 3); 112 } 113 114 lastTimestamp = timestamp; 115 116 // 时间戳部分 | 数据中心部分 | 机器标识部分 | 序列号部分 117 return ((timestamp - twepoch) &amp;lt;&amp;lt; timestampLeftShift) 118 | (datacenterId &amp;lt;&amp;lt; datacenterIdShift) 119 | (workerId &amp;lt;&amp;lt; workerIdShift) 120 | sequence; 121 } 122} 跟踪到这里就可以看到具体的算法了。具体来说，该算法就是Twitter的雪花算法的变种。最后生成的主键值是一个64位长整数，其具体定义如下：
最高1位未用，总为0，这样能够保证生成的主键值永远为整数； 然后是41位时间戳，其值为UTC毫秒数减去一个固定值：1288834974657L； 然后是5位datacenterId，从上面的算法来看是从主机的mac地址后2段计算出来的； 紧接着是5位的workerId； 最后是12位顺序号。也就是一毫秒时间内最多能够生成4096个主键值。 与Twitter的雪花算法的唯一区别是其41位的时间戳值多减去了一个固定值：1288834974657L。
</content>
    </entry>
    
     <entry>
        <title>Linux常用命令介绍 05 - unzip</title>
        <url>https://orchidflower.github.io/2021/02/26/linux-command-introduction-05-unzip/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Linux</tag>
        </tags>
        <content type="html"> unzip命令可以用来解压zip文件。用法比较简单，但是有些不太常用的命令需要记录一下。
1. 查看文件列表 1unzip -l ShadowHunters.epub 2# 查看更详细信息，包括压缩率等 3unzip -lv ShadowHunters.epub 2. 解压文件 1unzip -d ./temp ShadowHunters.epub 3. 解压一个文件 使用-p命令，将文件内容输出到标准输出，然后使用重定向创建文件：
1unzip -p ShadowHunters.epub ops/xhtml/cover.html &amp;gt; cover.html 4. 更新文件 1zip -u ShadowHunters.epub ops/xhtml/cover.html </content>
    </entry>
    
     <entry>
        <title>如何在Ubuntu上静态编译Golang&#43;GoCV程序</title>
        <url>https://orchidflower.github.io/2020/12/18/How-to-build-static-binary-with-gocv/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Ubuntu</tag><tag>Golang</tag><tag>GoCV</tag><tag>静态编译</tag>
        </tags>
        <content type="html"> 最近做了一个图像增强程序，用到了OpenCV。为了方便发布，我将代码使用Golang&#43;GoCV重写，但是编译的时候发现比较麻烦，特别记录一下，以备后查。 本文对应版本如下：
Ubuntu 18.04.5 LTS Golang 1.15.6 OpenCV 4.5.0 GoCV 0.2.5 1. Golang环境准备 1.1 安装Golang 下载对应的包，然后解压，设置PATH路径即可，不多说了。
1.2 设置GOPATH 使用go get下载的包将下载到$GOPATH目录中。 这里设置成/home/ubuntu/.go。不设置的话将自动设置成~/go目录。
1cd /home/ubuntu/.go 2export GOPATH=/home/ubuntu/.go 1.3 下载GoCV源码 1# 设置代理翻墙，要不然下载不了 2git config --global http.proxy=http://127.0.0.1:12346 3git config --global https.proxy=http://127.0.0.1:12346 4export http_proxy=http://127.0.0.1:12346 5export https_proxy=http://127.0.0.1:12346 6go get -v -u -d gocv.io/x/gocv 2. 开始编译 在GoCV的源码中，有一个Makefile文件，使用该Makefile可以简化OpenCV的编译过程。我是以此文件为基础编译的。
2.1 安装依赖库 1# 切换到源码目录 2ubuntu@testserver:~$ cd $GOPATH/src/gocv.io/x/gocv 3# 安装依赖库 4ubuntu@testserver:~/.go/src/gocv.io/x/gocv$ make deps 5sudo apt-get -y update 6sudo apt-get -y install unzip wget build-essential cmake curl git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libdc1394-22-dev 2.2 下载相关源码 下载OpenCV相关源码。记得挂代理。
1ubuntu@testserver:~/.go/src/gocv.io/x/gocv$ make download 2rm -rf /tmp/opencv 3mkdir /tmp/opencv 4cd /tmp/opencv 5curl -Lo opencv.zip https://github.com/opencv/opencv/archive/4.5.0.zip 6unzip -q opencv.zip 7curl -Lo opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/4.5.0.zip 8unzip -q opencv_contrib.zip 9rm opencv.zip opencv_contrib.zip 10cd - 2.3 编译 在编译之前需要对Makefile进行一些修改。因为FFMpeg、GTK、DC1394这几个功能的依赖库特别复杂，要实现静态编译非常麻烦，可能需要自己手工裁减编译这几个库。因为目前程序没有用到窗口、视频等方面的功能，所以直接裁减掉这几个功能。 修改方法是修改$GOPATH/src/gocv.io/x/gocv/Makefile这个文件。添加-D WITH_FFMPEG=OFF -D WITH_GTK=OFF -D WITH_1394=OFF -D WITH_TIFF=OFF这几个参数到目标build里面的cmake命令中即可。
1# Build OpenCV. 2build: 3 cd $(TMP_DIR)opencv/opencv-$(OPENCV_VERSION) 4 mkdir build 5 cd build 6 rm -rf * 7 #cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=OFF -D BUILD_opencv_java=NO -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -D WITH_JASPER=OFF -DOPENCV_GENERATE_PKGCONFIG=ON .. 8 cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D BUILD_SHARED_LIBS=${BUILD_SHARED_LIBS} -D OPENCV_EXTRA_MODULES_PATH=$(TMP_DIR)opencv/opencv_contrib-$(OPENCV_VERSION)/modules -D BUILD_DOCS=OFF -D BUILD_EXAMPLES=OFF -D BUILD_TESTS=OFF -D BUILD_PERF_TESTS=OFF -D BUILD_opencv_java=NO -D BUILD_opencv_python=NO -D BUILD_opencv_python2=NO -D BUILD_opencv_python3=NO -D WITH_JASPER=OFF -D WITH_FFMPEG=OFF -D WITH_GTK=OFF -D WITH_1394=OFF -DOPENCV_GENERATE_PKGCONFIG=ON .. 9 $(MAKE) -j $(shell nproc --all) 10 $(MAKE) preinstall 11 cd - 注意WITH_TIFF=OFF这个参数也可以不添加，不过要修改后面提到的CGO_LDFLAGS。具体看下面的介绍。
然后可以执行编译了。这个编译耗费时间会比较长。我这边花了20&#43;分钟。
1# 默认方式编译，编译出来动态库。我不用这种方式。 2ubuntu@testserver:~/.go/src/gocv.io/x/gocv$ make build 3# 我要编译静态库，所以添加BUILD_SHARED_LIBS=OFF 4ubuntu@testserver:~/.go/src/gocv.io/x/gocv$ make build BUILD_SHARED_LIBS=OFF 漫长的等待。
2.4 安装 1# 将编译好的库安装到系统中 2ubuntu@testserver:~/.go/src/gocv.io/x/gocv$ make sudo_install 3cd /tmp/opencv/opencv-4.5.0/build 4sudo make install 5sudo ldconfig 6cd - 7[sudo] password for ubuntu: 2.5 编译Golang程序 直接编译是无法通过的，需要设置CGO_CPPFLAGS, CGO_LDFLAGS两个环境变量，然后使用go build -tags customenv编译。
CGO_CPPFLAGS这个环境变量用于指定include文件的路径；可以通过pkg-config --cflags这个命令获得其内容。 CGO_LDFLAGS这个环境变量用于连接时期，主要指定lib文件路径及需要连接的库。可以通过pkg-config --libs获得其主要内容。见下面的注释。
1# 使用`pkg-config --cflags opencv4`获得 2export CGO_CPPFLAGS=&amp;#34;-I/usr/local/include/opencv4&amp;#34; 3# 使用`pkg-config --libs --static opencv4`获得主要内容。然后添加上`--static`这个参数。 4export CGO_LDFLAGS=&amp;#34;--static -L/usr/local/lib -L/usr/local/lib/opencv4/3rdparty -L/tmp/opencv/opencv-4.5.0/build/lib -lopencv_gapi -lopencv_stitching -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dnn_objdetect -lopencv_dnn_superres -lopencv_dpm -lopencv_highgui -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hfs -lopencv_img_hash -lopencv_intensity_transform -lopencv_line_descriptor -lopencv_mcc -lopencv_quality -lopencv_rapid -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_datasets -lopencv_text -lopencv_dnn -lopencv_plot -lopencv_videostab -lopencv_videoio -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_video -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_imgcodecs -lopencv_features2d -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core -littnotify -llibprotobuf -llibwebp -llibopenjp2 -lIlmImf -lquirc -lippiw -lippicv -lade -ljpeg -lpng -lz -ltiff -lfreetype -lharfbuzz -ljbig -llzma -lm -lpthread -lrt -lc -ldl&amp;#34; 另外，如果要支持TIFF格式（前面Makefile中没有添加WITH_TIFF=OFF选项），则CPP_LDFLAGS中还要加上：-ljbig -llzma这两个参数，否则编译Go代码的时候会报错。
最后使用go build -v -tags customenv .命令就可以编译了。
3. 编译中碰到的一些错误 编译Go代码的时候经常碰到各种undefined reference to错误，这都是因为要链接的库没有在CPP_LDFLAGS中指定。找到对应的库，添加到参数中就好了。
3.1 jbg 1(.text&#43;0x45): undefined reference to `jbg_enc_init&amp;#39; 2(.text&#43;0x4d): undefined reference to `jbg_enc_out&amp;#39; 3(.text&#43;0x55): undefined reference to `jbg_enc_free&amp;#39; 以上错误是需要libjbig这个库，应该是TIFF格式需要的。如果关闭了TIFF格式支持，应该不会报上面的错误。添加-ljbig就可以了。
3.2 lzma 1(.text&#43;0x1a0): undefined reference to `lzma_code&amp;#39; 以上错误是需要liblzma这个库，应该也是TIFF格式需要的。添加上-llzma参数解决。
3.3 dlopen、getaddrinfo 1warning: Using &amp;#39;dlopen&amp;#39; in statically linked applications requires at runtime the shared libraries from the glibc version used for linking libc
1Using &amp;#39;getaddrinfo&amp;#39; in statically linked applications requires at runtime the shared libraries from the glibc version used for linking 这两个警告信息暂时找不到解决办法。
4. 其他一些CGO编译相关的指令 go clean -cache 可以清除已经编译的缓存。
附录、参考资料 GoCV Home GoCV @Github Building OpenCV as a static library leads to thousands of undefined references Pls add static link opencv #217 Golang 1.9 build warning : Using &amp;lsquo;getaddrinfo&amp;rsquo; in statically linked applications requires at runtime the shared libraries from the glibc version used for linking #21421 OpenCV configuration options reference ubuntu安装opencv无法下载IPPICV的问题 ippicv_2020_lnx_intel64_20191018_general.tgz How to build more compact OpenCV applications on Linux </content>
    </entry>
    
     <entry>
        <title>删除启动台Launchpad上无效的图标</title>
        <url>https://orchidflower.github.io/2020/12/04/Delete-Invalid-Icon-from-Lauchpad/</url>
        <categories>
          <category>技巧</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>Launchpad</tag>
        </tags>
        <content type="html"> 今天删除软件的时候碰到一个问题，软件虽然被删除了，但是图标依然在启动台上。怎么也删不掉。上网搜了搜，找到一个办法可以解决。特此记录一下。
1# 切换到目录 /private/var/folders 2cd /private/var/folders 3# 寻找 com.apple.dock.launchpad 目录，图标信息存在该目录中的一个sqlite3数据库中 4sudo find . | grep com.apple.dock.launchpad 5# 确定好目录，然后使用cd转入对应的目录。目录名不同机器上不一样 6# 使用sqlite3工具查询一下 7sqlite3 db &amp;#34;select * from apps where title like &amp;#39;eclipse%&amp;#39;;&amp;#34; 8# 确认之后可以使用delete语句删除 9sqlite3 db &amp;#34;delete from apps where title like &amp;#39;eclipse%&amp;#39;;&amp;#34; 10# 然后杀掉Dock进程，就好了 11killall Dock 附录、参考资料 删除mac启动台里删不掉的图标 </content>
    </entry>
    
     <entry>
        <title>禁用CleanMyMacX HealthMonitor</title>
        <url>https://orchidflower.github.io/2020/11/27/How-to-Disable-CleanMyMacX-HealthMonitor/</url>
        <categories>
          <category>技巧</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>CleanMyMacX</tag>
        </tags>
        <content type="html"> CleanMyMacX 是Mac平台上优秀的卸载工具。虽然Mac上的应用安装卸载比Windows上简单很多，AppStore上的软件采用的是沙盒模型，删除的时候会把相关的数据一并删除；但是大量的非AppStore软件在删除对应的app之后不会同时删除对应的数据。 CleanMyMacX 这种类型的软件会扫描这些相关的数据并一起删除。
最近发现 CleanMyMacX 会附带一个后台服务：CleanMyMacX HealthMonitor，即使软件本身退出这个后台服务还一直运行。这就有点360的味道了，让人不爽。最主要的是这个进程对资源的占用还是有的，没有到那种可以完全忽略的地步。因此想办法禁用它。
2020.12.03 补充：该方法不太好，请参考下面的说明。
尝试了很多网上提供的办法都不成功，最后发现了一个简单的办法，只要删除对应的执行文件即可，针对最新的4.6.15有效：
1rm &amp;#34;/Applications/CleanMyMac X.app/Contents/Library/LoginItems/CleanMyMac X Menu.app/Contents/Library/LoginItems/CleanMyMac X HealthMonitor.app/Contents/MacOS/*&amp;#34; 2020.12.03 补充： 以上方法有些后遗症，打开控制台程序，可以看到在system.log中定期出现异常信息：
1Dec 3 00:40:02 macBookPro com.apple.xpc.launchd[1] (com.macpaw.CleanMyMac4.HealthMonitor[7781]): Service exited with abnormal code: 78 2Dec 3 00:40:02 macBookPro com.apple.xpc.launchd[1] (com.macpaw.CleanMyMac4.HealthMonitor): Service only ran for 0 seconds. Pushing respawn out by 10 seconds. 3Dec 3 00:40:14 macBookPro com.apple.xpc.launchd[1] (com.macpaw.CleanMyMac4.HealthMonitor[7785]): Could not find and/or execute program specified by service: 45: Operation not supported: com.macpaw.CleanMyMac4.HealthMonitor 请使用以下方法：
经过试验，可以修改权限解决，不需要删除文件，也不会出现system.log中的异常日志。针对4.7.1有效：
1chmod 400 &amp;#34;/Applications/CleanMyMac X.app/Contents/Library/LoginItems/CleanMyMac X Menu.app/Contents/Library/LoginItems/CleanMyMac X HealthMonitor.app/Contents/MacOS/CleanMyMac X HealthMonitor&amp;#34; 2chmod 400 &amp;#34;/Applications/CleanMyMac X.app/Contents/Library/LoginItems/CleanMyMac X Menu.app/Contents/Library/LaunchServices/com.macpaw.CleanMyMac4.Agent&amp;#34; 3chmod 400 &amp;#34;/Applications/CleanMyMac X.app/Contents/Library/LaunchServices/com.macpaw.CleanMyMac4.Agent&amp;#34; 附录、参考资料 当下 如何禁用 流氓启动项 CleanMyMac X HealthMonitor </content>
    </entry>
    
     <entry>
        <title>使用MyBatis ResultHandler解决巨大结果集导出Excel引发的OOM</title>
        <url>https://orchidflower.github.io/2020/09/04/Using-MyBatis-ResultHandler-to-export-huge-resultset-avoiding-OOM/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Java</tag><tag>MyBatis</tag><tag>OOM</tag><tag>ResultHandler</tag><tag>内存溢出</tag>
        </tags>
        <content type="html"> 当一次要导出非常多数据的时候，例如100w条，如果使用MyBatis将全部结果都查询到list中，经常会导致内存溢出。这个时候，我们可以使用MyBatis的ResultHandler来使用游标方式访问数据，从而避免OOM。
ResultHandler是MyBatis提供的一个接口，通过该接口可以让MyBatis以流式的方式处理结果集，而不必等待整个结果集全部准备完毕，在准备好一条记录后就调用该接口中的handleResult方法：
1void handleResult(ResultContext&amp;lt;? extends T&amp;gt; resultContext); 要使用ResultHandler需要在Mapper层声明的时候做一定的处理。这里简单描述一下。
1. 基于注解 1public interface OrderMapper extends BaseMapper&amp;lt;Order&amp;gt; { 2 /** 3 * 导出订单功能 4 * @param wrapper 5 * @param handler 6 */ 7 @Select(&amp;#34;select * from tap_order ${ew.customSqlSegment}&amp;#34;) 8 @Options(resultSetType = ResultSetType.FORWARD_ONLY, fetchSize = Integer.MIN_VALUE) 9 @ResultType(Order.class) 10 void export(@Param(&amp;#34;ew&amp;#34;) Wrapper wrapper, ResultHandler&amp;lt;Order&amp;gt; handler); 11} 基于注解的声明方式看上去相当直观：
使用@Select注解声明sql语句； 使用@ResultType声明结果集的类型； 使用@Options声明了两个配置项，其目的是开启MySQL的客户端游标。如果不配置这两项，MySQL默认还是会把整个结果集返回客户端； 函数声明中增加一个ResultHandler类型的参数，返回值也改成了void类型。 2. 基于XML配置 基于XML的配置在XML文件中与之前的传统方式配置一个查询是一样的，只是需要增加fetchSize和resultSetType两个配置项以启用MySQL的客户端游标：
1&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; 2&amp;lt;!DOCTYPE mapper PUBLIC &amp;#34;-//mybatis.org//DTD Mapper 3.0//EN&amp;#34; &amp;#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd&amp;#34;&amp;gt; 3&amp;lt;mapper namespace=&amp;#34;com.eveus.tap.trade.mapper.OrderMapper&amp;#34;&amp;gt; 4 &amp;lt;select id=&amp;#34;export&amp;#34; fetchSize=&amp;#34;-2147483648&amp;#34; resultSetType=&amp;#34;FORWARD_ONLY&amp;#34; resultType=&amp;#34;com.eveus.tap.trade.po.Order&amp;#34;&amp;gt; 5 SELECT * FROM `tap_order` ${ew.customSqlSegment} 6 &amp;lt;/select&amp;gt; 7&amp;lt;/mapper&amp;gt; 在Mapper类中，定义函数接口和基于注解的一样，只是不需要注解声明。
1public interface OrderMapper extends BaseMapper&amp;lt;Order&amp;gt; { 2 /** 3 * 导出订单功能 4 * @param wrapper 5 * @param handler 6 */ 7 //@Select(&amp;#34;select * from tap_order ${ew.customSqlSegment}&amp;#34;) 8 //@Options(resultSetType = ResultSetType.FORWARD_ONLY, fetchSize = Integer.MIN_VALUE) 9 //@ResultType(Order.class) 10 void export(@Param(&amp;#34;ew&amp;#34;) Wrapper wrapper, ResultHandler&amp;lt;Order&amp;gt; handler); 11} 3. 使用方法 1class OrderServiceImpl { 2 public ServiceResult&amp;lt;ExcelByte&amp;gt; export(Wrapper&amp;lt;Order&amp;gt; wrapper) { 3 ExcelExporter exporter = new ExcelExporter(); 4 exporter.addColumn(&amp;#34;订单号&amp;#34;).withWidth(40); 5 // 此时使用的就是ResultHandler对结果集进行处理 6 this.getBaseMapper().export(wrapper, resultContext -&amp;gt; { 7 Order order = resultContext.getResultObject(); 8 List values = new ArrayList(); 9 values.add(order.getId()); 10 exporter.addRow(values); 11 }); 12 if (exporter.getTotalRows()==0) { 13 return ServiceResult.fail(ResultCode.EXCEL_NO_ROWS); 14 } 15 // 转化为byte数组 16 ExcelByte excelByte = new ExcelByte(); 17 excelByte.setContent(exporter.toBytes()); 18 exporter.dispose(); 19 return ServiceResult.ok(excelByte); 20 } 21} 附录、参考资料 Mybatis流式查询避免OOM ResultHandler的用法 mybatis ResultHandler vs ResultSetHandler及自定义扩展 MyBatis Plus条件构造器 </content>
    </entry>
    
     <entry>
        <title>使用Python写一个Alfred Workflow</title>
        <url>https://orchidflower.github.io/2020/08/21/Build-Alfred-workflow-using-python/</url>
        <categories>
          <category>技巧</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>Alfred</tag><tag>Workflow</tag>
        </tags>
        <content type="html"> 1. Alfred 和 Workflows 介绍 Alfred 号称是 Mac 上最强大的效率工具，一直在 Mac 平台的工具类中排名榜首。它在Spotlight （ Mac 自带的搜索和快速启动引擎）基础上优化了快速启动与搜索的功能，还引入了 Workflows 等强大的扩展功能，使之成为了一个拥有无限自动化潜力的「工具平台」软件，可以用它来实现近乎一切有关自动化的想法。
Worflows 是 Alfred 的高端应用方式，它以流的方式来进行工作，从输入 -&amp;gt; 动作 -&amp;gt; 输出，将各种工具串联在一起进行工作，非常开放，用来将各种功能串联起来执行，可以定制完成各种想要实现的功能，潜力无限。
虽然网上已经有很多别人写好的 Workflow，但总是不够用，毕竟各自的偷懒点不同，因此有必要学会 Workflow 的编写，可以更好的满足自己的要求。
2. 开始写一个Workflows 今天想写一个生成随机字符串的Workflow，可选接收一个长度参数，生成指定长度的字符串，这个字符串可以由数字、字符、数字&#43;字符等构成。下面说一下整个创建过程。
2.1 创建一个 Workflows 打开 Alfred 的 Preferences 窗口，选择 Workflows 菜单，点击下面的“[&#43;]”按钮，就能够创建新的 Workflows 了。Alfred 提供了多种模板可供参考，通常选择 Workflow Defaults... 就可以了。然后在弹出的窗口中填上必要的信息保存即可。这些信息在你发布这个 Workflow 的时候可以更好的描述它的作者、功能等信息，如果自己使用的话，随便填一下也无所谓：
2.2 一些概念 一个Workflow中可以添加多种类型的对象，例如Triggers, Inputs等等，他们的具体功能可以参考官网的帮助信息：
Triggers: Activate Alfred from a hotkey, another Alfred feature or an external source. 简单的说Triggers的用途就是通过热键或者其他方式启动Alfred，进而启动Workflow。
Inputs: Keyword-based objects used to perform an action, on its own or followed by a query. Inputs通过一个定义的关键字对象来执行一个action，这个关键字可以带查询参数也可以不带。例如你定义关键字mc，那么在Alfred搜索框中输入mc就可以启动这个功能。
Actions: The objects that do most of the work in your workflows; opening or revealing files and web searches, running scripts and performing commands. Actions对象在workflows中负责完成绝大多数的工作，例如可以打开文件，打开搜索，执行脚本等等。
Utilities: Utilities give you control over how your objects are connected together and how the arguments output by the previous object is passed on to the next object. Utilities可以让你控制你的对象如何连接在一起工作，控制参数如何在对象之间传递。这个对象我用的不多。
Outputs: Collect the information from the earlier objects in your workflow to pop up a Notification Centre message, show output in Large Type, copy to clipboard or run a script containing the result of your workflow. Outputs对象负责从你的Workflow中的前一个对象中收集信息，然后真正输出到系统中，这个输出可能是：弹出一个通托盘通知，拷贝到剪贴板，写一个文件，播放一个声音等等。
这些对象不是都要用到，常用的有Script Filter（Inputs），Keyword（Inputs）、Run Script（Actions）等几个。
这次要写一个生成随机字符串的功能，主要用到两个对象，分别是 Script Filter 和 Copy to Clipboard 。其中 Script Filter 负责生成随机数，Copy to Clipboard 负责将被选中的随机数拷贝到剪切板。
2.3 Script Filter的一些说明 Script Filter的输出结果需要符合特定的格式才能够被Alfred识别并解析出来。这个格式可以是xml，也可以是json。官方推荐用json格式。下面是一个例子：
1{ 2 &amp;#34;items&amp;#34;: [ 3 { 4 &amp;#34;arg&amp;#34;: &amp;#34;7RWa7SASoDVjuv45&amp;#34;, 5 &amp;#34;title&amp;#34;: &amp;#34;7RWa7SASoDVjuv45&amp;#34;, 6 &amp;#34;subtitle&amp;#34;: &amp;#34;字母加数字&amp;#34;, 7 &amp;#34;icon&amp;#34;: &amp;#34;&amp;#34; 8 }, 9 { 10 &amp;#34;arg&amp;#34;: &amp;#34;2550619258781486&amp;#34;, 11 &amp;#34;title&amp;#34;: &amp;#34;2550619258781486&amp;#34;, 12 &amp;#34;subtitle&amp;#34;: &amp;#34;数字&amp;#34;, 13 &amp;#34;icon&amp;#34;: &amp;#34;&amp;#34; 14 }, 15 ... 16 ] 17} 在这个结构中，items是个数组，其中的内容就是多条要被显示出来的记录。每条记录中，关键的几个字段为：
arg 这个值非常重要，被选中项目的arg值将被传递到后续的action中；官方的解释如下： The argument which is passed through the workflow to the connected output action. While the arg attribute is optional, it&amp;rsquo;s highly recommended that you populate this as it&amp;rsquo;s the string which is passed to your connected output actions. If excluded, you won&amp;rsquo;t know which result item the user has selected.
title 在Alfred结果栏中显示的内容，是必须的选项，通常这个值与arg相同，也就是显示的值也是要输出到下一个action中的值。官方解释如下： The title displayed in the result row. There are no options for this element and it is essential that this element is populated.
subtitle 对title的一个解释性信息，在主要内容下面以小字显示；官方说明如下： The subtitle displayed in the result row. This element is optional.
icon 是图标。为空的话就用workflow本身的图标代替。 上面的结果显示的效果图如下： 2.4 添加一个 Script Filter 在 Workflow 工作区中点右键，在弹出菜单中选择好 Script Filter 添加即可。Alfred 默认的Python 是2.7版本，因为要用到3.x版本，所以在 Language 中选择了 External Script，然后选择新建一个脚本即可。
2.5 添加一个Copy to Clipboard 最后添加一个 Copy to Clipboard 对象，配置如图即可，不需要自己编写任何代码就能够把选中的项目拷贝到剪贴板：
3. 最终代码 下面代码是Script Filter中的核心内容，负责生成随机字符串，并组装成特定格式的JSON字符串，输出到控制台中。代码比较直观，就不做过多解读了。
1#!/usr/bin/python3 2 3import sys 4import json 5import random 6from datetime import datetime, timezone 7#from workflow import Workflow 8 9TABLES = [ 10	&amp;#34;1234567890&amp;#34;, 11	&amp;#34;1234567890abcdef&amp;#34;, 12	&amp;#34;1234567890ABCDEF&amp;#34;, 13	&amp;#34;1234567890ABCDEFabcdef&amp;#34;, 14	&amp;#34;1234567890ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz&amp;#34; 15] 16 17def addItem(items, itemValue, itemTitle): 18	item = { 19	&amp;#39;arg&amp;#39;: itemValue, 20	&amp;#39;title&amp;#39;: itemValue, 21	&amp;#39;subtitle&amp;#39;: itemTitle, 22	&amp;#39;icon&amp;#39;: &amp;#39;&amp;#39; 23	} 24	items.append(item) 25 26def randString(tableStr, length): 27	ret = &amp;#39;&amp;#39; 28	for i in range(length): 29	ret &#43;= random.choice(tableStr) 30	return ret 31 32def main(): 33	randomLength = 16 34 35	if len(sys.argv)&amp;gt;1: 36	randomLength = int(sys.argv[1]) 37 38	items = [] 39 40	addItem(items, randString(TABLES[4], randomLength), &amp;#39;字母加数字&amp;#39;) 41	addItem(items, randString(TABLES[0], randomLength), &amp;#39;数字&amp;#39;) 42	addItem(items, randString(TABLES[1], randomLength), &amp;#39;小写16进制&amp;#39;) 43	addItem(items, randString(TABLES[2], randomLength), &amp;#39;大写16进制&amp;#39;) 44	addItem(items, randString(TABLES[3], randomLength), &amp;#39;16进制&amp;#39;) 45	46 47	print(json.dumps({&amp;#39;items&amp;#39;: items})) 48 49 50if __name__ == &amp;#39;__main__&amp;#39;: 51	#wf = Workflow() 52	#sys.exit(wf.run(main)) 53 54	main() 4. 调试及排错 刚开始写 Workflow 的时候难免会碰到问题，这时候就需要进行调试和排错了。首先可以找到 Workflow 的目录在哪里，这样就可以在命令行下执行自己写的脚本，看看结果怎么样。可以通过在Workflow上点右键选择Open in Finder，Open in Terminal等功能找到脚本所在的目录。
另外，Alfred执行的时候会把输入输出内容都显示出来，可以通过Alfred内置的控制台看到这些交互内容，方法是点击右上角的BUG图标，就能够在打开控制台了。这时执行结果包括错误信息之类的都会显示在里面。
</content>
    </entry>
    
     <entry>
        <title>Mac休眠模式调整</title>
        <url>https://orchidflower.github.io/2020/08/11/How-to-change-hibernate-mod-for-Mac/</url>
        <categories>
          <category>技巧</category>
        </categories>
        <tags>
          <tag>Mac</tag>
        </tags>
        <content type="html"> 手头的Mac已经用了三年了，之前合盖睡眠的时候感觉掉电还不明显，最近几次系统升级后感觉掉电的情况明显了，一个晚上会掉5%左右，虽然不多，但是还是不爽。 经过搜索，发现可以通过修改休眠模式，来解决这个问题，特此记录一下。
1. pmset及参数介绍 pmset是Mac的一个系统命令，可以用来修改和电源管理相关的参数。看man中的帮助：
pmset can modify the values of any of the power management settings defined below. You may specify one or more setting &amp;amp; value pairs on the command-line invocation of pmset. The -a, -b, -c, -u flags determine whether the settings apply to battery ( -b ), charger (wall power) ( -c ), UPS ( -u ) or all ( -a ).
简单来说就是可以通过pmset -b或pmset -c,pmset -a等命令修改电源配置参数。当然也可以通过pmset -g命令查询当前的配置参数或日志等。例如以下命令可以查看当前系统的电源相关配置：
1&amp;gt; pmset -g custom 2Battery Power: 3 lidwake 1 4 autopoweroff 1 5 standbydelayhigh 1800 6 autopoweroffdelay 28800 7 standbydelaylow 600 8 standby 1 9 proximitywake 0 10 ttyskeepawake 1 11 hibernatemode 3 12 powernap 0 13 gpuswitch 2 14 hibernatefile /var/vm/sleepimage 15 highstandbythreshold 95 16 displaysleep 2 17 sleep 1 18 acwake 0 19 halfdim 1 20 tcpkeepalive 1 21 lessbright 1 22 disksleep 10 23AC Power: 24 lidwake 1 25 autopoweroff 1 26 standbydelayhigh 86400 27 autopoweroffdelay 28800 28 standbydelaylow 10800 29 standby 1 30 proximitywake 1 31 ttyskeepawake 1 32 hibernatemode 3 33 powernap 1 34 gpuswitch 2 35 hibernatefile /var/vm/sleepimage 36 highstandbythreshold 50 37 displaysleep 10 38 womp 1 39 networkoversleep 0 40 sleep 10 41 tcpkeepalive 1 42 halfdim 1 43 acwake 0 44 disksleep 10 要修改Mac的休眠相关配置，需要用到pmset命令，其中与休眠相关的几个关键参数有：hibernatemode，standby，highstandbythreshold，standbydelayhigh，standbydelaylow。有关这几个参数的具体含义与用途，首先看一下man帮助中的描述。
1.1 SAFE SLEEP ARGUMENTS hibernatemode supports values of 0, 3, or 25. Whether or not a hibernation image gets written is also dependent on the values of standby and autopoweroff
For example, on desktops that support standby a hibernation image will be written after the specified standbydelay time. To disable hibernation images completely, ensure hibernatemode standby and autopoweroff are all set to 0.
hibernatemode = 0 by default on desktops. The system will not back memory up to persistent storage. The system must wake from the contents of memory; the system will lose context on power loss. This is, historically, plain old sleep.
hibernatemode = 3 by default on portables. The system will store a copy of memory to persistent storage (the disk), and will power memory during sleep. The system will wake from memory, unless a power loss forces it to restore from hibernate image.
hibernatemode = 25 is only settable via pmset. The system will store a copy of memory to persistent storage (the disk), and will remove power to memory. The system will restore from disk image. If you want &amp;ldquo;hibernation&amp;rdquo; - slower sleeps, slower wakes, and better battery life, you should use this setting.
Please note that hibernatefile may only point to a file located on the root volume.
1.2 STANDBY ARGUMENTS standby causes kernel power management to automatically hibernate a machine after it has slept for a specified time period. This saves power while asleep. This setting defaults to ON for supported hardware. The setting standby will be visible in pmset -g if the feature is supported on this machine.
standbydelayhigh and standbydelaylow specify the delay, in seconds, before writing the hibernation image to disk and powering off memory for Standby. standbydelayhigh is used when the remaining battery capacity is above highstandbythreshold , and standbydelaylow is used when the remaining battery capacity is below highstandbythreshold.
highstandbythreshold has a default value of 50 percent.
autopoweroff is enabled by default on supported platforms as an implementation of Lot 6 to the European Energy- related Products Directive. After sleeping for seconds, the system will write a hibernation image and go into a lower power chipset sleep. Wakeups from this state will take longer than wakeups from regular sleep.
autopoweroffdelay specifies the delay, in seconds, before entering autopoweroff mode.
2. 解释 根据官方文档，我们可以总结一下：
macOS 默认的睡眠，会关闭屏幕，但会维持对内存（RAM）的供电。这样一来，一旦打开盖子，macOS 就能立即恢复。若是电池电量低于某个预设阈值，则会将内存中的数据转储到硬盘，而后彻底断电。
对应的，macOS 的睡眠有两种状态：
不断电，数据存储在内存中，可以快速恢复。我们称这种状态为睡眠（Sleep）； 断电，数据存储在硬盘中，恢复得较慢。我们称这种状态为休眠（Hibernate/Stand-by）。 睡眠和休眠可以组合出三种模式，由 hibernatemode 控制
hibernatemode = 0，这是桌面设备的默认值。系统只睡眠，不休眠，不将数据存储在硬盘中； hibernatemode = 3，这是移动设备的默认值。系统默认睡眠，在一定时间后或电量低于阈值将数据存储在硬盘中，而后休眠。这是所谓的安全睡眠（Safe-Sleep）； hibernatemode = 25。只休眠，不睡眠。这种模式只能通过pmset进行设置。 无论是安全睡眠模式还是休眠模式，从磁盘上恢复时，都会需要一定的时间屏幕才会被点亮。
对于安全睡眠模式，又有几个参数可以来进行微调：
当剩余电量大于 highstandbythreshold（默认 50%）时，在 standbydelayhigh 秒（默认 86,400，即一整天）后进入休眠。 当剩余电量小于 highstandbythreshold 时，在 standbydelaylow 秒（默认 10,800，即三小时）后进入休眠。 3. 修改一下 我们来实际操作一下：
1# 使用-b限定只修改电池供电的情况下的配置，因为晚上睡眠的时候不插电源 2# hibernatemode设置为安全睡眠模式 3pmset -b hibernatemode 3 4# 电量阈值设置为95% 5pmset -b highstandbythreshold 95 6# 电量超过95%的时候休眠前等待30分钟 7pmset -b standbydelayhigh 1800 8# 电量低于95%的时候休眠前等待10分钟 9pmset -b standbydelaylow 600 10# 自动断电时间限定为30分钟 11pmset -b autopoweroffdelay 1800 </content>
    </entry>
    
     <entry>
        <title>使用KeepAlived配置Nginx高可用</title>
        <url>https://orchidflower.github.io/2020/07/20/Use-keepalived-for-high-availability-support-for-nginx/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Ubuntu</tag><tag>Nginx</tag><tag>KeepAlived</tag><tag>高可用</tag>
        </tags>
        <content type="html"> 1. 背景 最近为一个传统行业的客户开发了一个生产调度系统。但是他的生产环境是自己搭建的，不是购买的云服务，因此碰到了一些问题。
客户购买了多台高性能的物理机，在上面自行搭建虚拟机。但是只有虚拟机，没有提供类似负载均衡、数据库等基础服务。为了解决负载均衡问题，我们自行安装了 Nginx 。为了保证系统健壮和性能，安装 Nginx 的两台虚拟机（Ubuntu 18.04.3 LTS，172.16.45.22，172.16.45.26）分别部署在两台不同的物理机上（172.16.45.11， 172.168.45.12）。然后 DNS 解析到两台 Nginx 主机上。
现在的问题是：客户的要求是任何一台物理机出现问题都要能够保证系统可用，验证的方式是测试的时候会直接断开物理机的网线，这将导致通过 DNS 解析出来的 Nginx 主机必然有一台是无法使用的。访问显然会出问题。
经过考虑，最后选定解决办法是：使用 KeepAlived 做高可用，两台 Nginx 共同维护一个虚拟IP（172.16.45.50），DNS 解析到这个虚拟IP上。
这里简单记录一下安装 KeepAlived 的过程以及碰到的一些问题及解决方案。
2.安装KeepAlived 在 Ubuntu 上安装 KeepAlived 非常简单：
1apt install keepalived 安装的版本是1.3.9。不算新，但是应该够用。
3. 配置文件 配置文件名位置为：/etc/keepalived/keepalived.conf，如果文件不存在，KeepAlived 将不能够启动，请自行创建该文件。
1! Configuration File for keepalived 2# Global definitions configuration block 3global_defs { 4 # String identifying the machine (doesn&amp;#39;t have to be hostname). 5 # (default: local host name) 6 router_id server01 7} 8 9# A VRRP Instance is the VRRP protocol key feature. It defines and con- 10# figures VRRP behaviour to run on a specific interface. Each VRRP 11# Instances are related to a uniq interface. 12vrrp_instance VI_1 { 13 # Initial state, MASTER|BACKUP 14 # As soon as the other machine(s) come up, 15 # an election will be held and the machine 16 # with the highest priority will become MASTER. 17 # So the entry here doesn&amp;#39;t matter a whole lot. 18 state MASTER 19 # interface for inside_network, bound by vrrp 20 interface eth0 21 # arbitrary unique number from 1 to 255 22 # used to differentiate multiple instances of vrrpd 23 # running on the same NIC (and hence same socket). 24 virtual_router_id 50 25 # for electing MASTER, highest priority wins. 26 # to be MASTER, make this 50 more than on other machines. 27 priority 100 28 # VRRP Advert interval in seconds (e.g. 0.92) (use default) 29 advert_int 1 30 # Note: authentication was removed from the VRRPv2 specification by 31 # RFC3768 in 2004. 32 # Use of this option is non-compliant and can cause problems; avoid 33 # using if possible, except when using unicast, where it can be helpful. 34 authentication { 35 # PASS|AH 36 # PASS - Simple password (suggested) 37 # AH - IPSEC (not recommended)) 38 auth_type PASS 39 # Password for accessing vrrpd. 40 # should be the same on all machines. 41 # Only the first eight (8) characters are used. 42 auth_pass Password@123 43 } 44 # addresses add|del on change to MASTER, to BACKUP. 45 # With the same entries on other machines, 46 # the opposite transition will be occurring. 47 # For virutal_ipaddress, virtual_ipaddress_excluded, 48 # virtual_routes and virtual_rules most of the options 49 # match the options of the command ip address/route/rule add. 50 # The track_group option only applies to static addresses/routes/rules. 51 # no_track is specific to keepalived and means that the 52 # vrrp_instance will not transition out of master state 53 # if the address/route/rule is deleted and the address/route/rule 54 # will not be reinstated until the vrrp instance next transitions 55 # to master. 56 # &amp;lt;LABEL&amp;gt;: is optional and creates a name for the alias. 57 For compatibility with &amp;#34;ifconfig&amp;#34;, it should 58 be of the form &amp;lt;realdev&amp;gt;:&amp;lt;anytext&amp;gt;, for example 59 eth0:1 for an alias on eth0. 60 # &amp;lt;SCOPE&amp;gt;: (&amp;#34;site&amp;#34;|&amp;#34;link&amp;#34;|&amp;#34;host&amp;#34;|&amp;#34;nowhere&amp;#34;|&amp;#34;global&amp;#34;) 61 virtual_ipaddress { 62 172.16.45.50 63 } 64} 主要配置参数可以参考其中的注释说明。几个关键参数简单说一下：
state 用于指定当前主机的在 KeepAlived 中的初始状态。可以为 MASTER 和 BACKUP 。虚拟IP将绑定在 MASTER 上； interface 指定绑定的网卡； vrrp_instance 定义一个虚拟网络，这是 KeepAlived 定义的一个基本单位； virtual_ipaddress 指定绑定的虚拟IP。虚拟IP会根据网络情况在 MASTER 和 BACKUP 之间漂移； 改完配置文件之后使用命令：service keepalived restart重启服务即可。
4. 验证 使用ip addr show eth0查看网卡的IP地址。默认情况下，只有MASTER上面会有新增的虚拟IP。 使用service keepalived stop停掉主节点的 KeepAlived，然后就会发现虚拟IP出现在 BACKUP 节点上来。再次启动 MASTER 上的 KeepAlived ，虚拟IP又会出现在 MASTER 节点上。 日志如下： MASTER 节点：
1Jan 09 16:56:18 server01 systemd[1]: Stopping Keepalive Daemon (LVS and VRRP)... 2Jan 09 16:56:18 server01 Keepalived[2360]: Stopping 3Jan 09 16:56:18 server01 Keepalived_vrrp[2367]: VRRP_Instance(VI_1) sent 0 priority 4Jan 09 16:56:18 server01 Keepalived_healthcheckers[2366]: Stopped 5Jan 09 16:56:19 server01 Keepalived_vrrp[2367]: Stopped 6Jan 09 16:56:19 server01 Keepalived[2360]: Stopped Keepalived v1.3.9 (10/21,2017) 7Jan 09 16:56:19 server01 systemd[1]: Stopped Keepalive Daemon (LVS and VRRP). 8Jan 09 16:56:19 server01 systemd[1]: Starting Keepalive Daemon (LVS and VRRP)... 9Jan 09 16:56:19 server01 Keepalived[2408]: Starting Keepalived v1.3.9 (10/21,2017) 10Jan 09 16:56:19 server01 Keepalived[2408]: Opening file &amp;#39;/etc/keepalived/keepalived.conf&amp;#39;. 11Jan 09 16:56:19 server01 systemd[1]: Started Keepalive Daemon (LVS and VRRP). 12Jan 09 16:56:19 server01 Keepalived[2412]: Starting Healthcheck child process, pid=2416 13Jan 09 16:56:19 server01 Keepalived_healthcheckers[2416]: Opening file &amp;#39;/etc/keepalived/keepalived.conf&amp;#39;. 14Jan 09 16:56:19 server01 Keepalived[2412]: Starting VRRP child process, pid=2418 15Jan 09 16:56:19 server01 Keepalived_vrrp[2418]: Registering Kernel netlink reflector 16Jan 09 16:56:19 server01 Keepalived_vrrp[2418]: Registering Kernel netlink command channel 17Jan 09 16:56:19 server01 Keepalived_vrrp[2418]: Registering gratuitous ARP shared channel 18Jan 09 16:56:19 server01 Keepalived_vrrp[2418]: Opening file &amp;#39;/etc/keepalived/keepalived.conf&amp;#39;. 19Jan 09 16:56:19 server01 Keepalived_vrrp[2418]: Using LinkWatch kernel netlink reflector... 20Jan 09 16:56:19 server01 Keepalived_vrrp[2418]: VRRP_Instance(VI_1) Transition to MASTER STATE 21Jan 09 16:56:20 server01 Keepalived_vrrp[2418]: VRRP_Instance(VI_1) Entering MASTER STATE BACKUP 节点：
1Jan 09 16:55:16 server02 systemd[1]: Starting Keepalive Daemon (LVS and VRRP)... 2Jan 09 16:55:16 server02 Keepalived[96635]: Starting Keepalived v1.3.9 (10/21,2017) 3Jan 09 16:55:16 server02 Keepalived[96635]: Opening file &amp;#39;/etc/keepalived/keepalived.conf&amp;#39;. 4Jan 09 16:55:16 server02 systemd[1]: Started Keepalive Daemon (LVS and VRRP). 5Jan 09 16:55:16 server02 Keepalived[96644]: Starting Healthcheck child process, pid=96650 6Jan 09 16:55:16 server02 Keepalived_healthcheckers[96650]: Opening file &amp;#39;/etc/keepalived/keepalived.conf&amp;#39;. 7Jan 09 16:55:16 server02 Keepalived[96644]: Starting VRRP child process, pid=96651 8Jan 09 16:55:16 server02 Keepalived_vrrp[96651]: Registering Kernel netlink reflector 9Jan 09 16:55:16 server02 Keepalived_vrrp[96651]: Registering Kernel netlink command channel 10Jan 09 16:55:16 server02 Keepalived_vrrp[96651]: Registering gratuitous ARP shared channel 11Jan 09 16:55:16 server02 Keepalived_vrrp[96651]: Opening file &amp;#39;/etc/keepalived/keepalived.conf&amp;#39;. 12Jan 09 16:55:16 server02 Keepalived_vrrp[96651]: Truncating auth_pass to 8 characters 13Jan 09 16:55:16 server02 Keepalived_vrrp[96651]: Using LinkWatch kernel netlink reflector... 14Jan 09 16:55:16 server02 Keepalived_vrrp[96651]: VRRP_Instance(VI_1) Entering BACKUP STATE 15Jan 09 16:56:18 server02 Keepalived_vrrp[96651]: VRRP_Instance(VI_1) Transition to MASTER STATE 16Jan 09 16:56:19 server02 Keepalived_vrrp[96651]: VRRP_Instance(VI_1) Entering MASTER STATE 17Jan 09 16:56:19 server02 Keepalived_vrrp[96651]: VRRP_Instance(VI_1) Received advert with higher priority 100, ours 50 18Jan 09 16:56:19 server02 Keepalived_vrrp[96651]: VRRP_Instance(VI_1) Entering BACKUP STATE 5. 剩余问题 观察可以发现，上面方案实行后会导致只有一台 Nginx 生效，另一台上因为没有绑定虚拟IP，不会被访问到，这相当于将两台同等地位的 Nginx 变成了主从模式。
一个可行的解决办法是采用双主模式部署 KeepAlived。方法是配置两个vrrp_instance，两台主机分别作为两个vrrp_instance的 MASTER/BACKUP 。
例如：第一个vrrp_instance中 server01 作为 MASTER，server02 作为 BACKUP，第二个vrrp_instance中 server01 作为 BACKUP，server02 作为 MASTER.这样正常情况下，两个虚拟IP分别指向 server01 和 server02，达到了负载均衡的目的。当网络出现状况的时候 - 例如 server02 出现故障，server01 就变成了两个 vrrp_instance 的MASTER，接管了所有的网络通讯，从而实现了高可用。具体的配置就不贴了，可以自行阅读参考资料。
附录、参考资料 KeepAlived Homepage KeepAlived Documentation VRRP原理和分析 Keepalived原理 KeepAlived introduction How to Setup IP Failover with KeepAlived on Ubuntu &amp;amp; Debian How to setup a highly available load balancer with keepalived and HAProxy on Ubuntu 18.04 Linux Virtual Server技术 Nginx&#43;keepalived 高可用双机热备（主从模式/双主模式） Nginx-keepalived&#43;Nginx实现高可用集群 Keepalived之——Keepalived &#43; Nginx 实现高可用 Web 负载均衡 </content>
    </entry>
    
     <entry>
        <title>如何修改Ubuntu服务器上的DNS设置</title>
        <url>https://orchidflower.github.io/2020/07/10/How-to-Change-DNS-on-Ubuntu/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Ubuntu</tag><tag>DNS</tag>
        </tags>
        <content type="html"> 公司的几台服务器安装的时候设置了联通的DNS服务器，由于公司网络切换到了电信，最近经常出现解析服务器IP失败的情况。所以想着要更换一下DNS服务器，以提高网络访问速度。
因为历史原因，服务器操作系统主要有 Ubuntu 16.04 LTS 和 Ubuntu 18.04 LTS 两种。实际修改中发现，他们的配置方法是不一样的，特此记录一下。
1. Ubuntu 16.04 LTS 16.04 LTS上主要修改两个文件。
2.1 更新resolv.conf 首先修改文件：/etc/resolvconf/resolv.conf.d/base文件，内容如下：
1nameserver 114.114.114.114 2nameserver 223.5.5.5 然后执行：resolvconf -u命令就可以更新dns服务器了。
2.2 network/interfaces 然后修改文件：/etc/network/interfaces文件，删除其中的dns-nameservers配置项：
1# This file describes the network interfaces available on your system 2# and how to activate them. For more information, see interfaces(5). 3 4source /etc/network/interfaces.d/* 5 6# The loopback network interface 7auto lo 8iface lo inet loopback 9 10# The primary network interface 11auto ens33 12#iface ens33 inet dhcp 13iface ens33 inet static 14address 192.168.2.231 15netmask 255.255.255.0 16gateway 192.168.2.1 17#dns-nameservers 202.102.134.68 202.102.128.68 然后重启network服务：/etc/init.d/networking restart，这样就可以了。
实际修改中，大部分服务器修改第一个就可以起效了，只有个别的需要修改两个。为了防止歧义，推荐两个都修改。
2. Ubuntu 18.04 LTS 对 18.04 LTS 来说，配置文件变更为：/etc/netplan/*.yaml。例如：
1# This file is generated from information provided by 2# the datasource. Changes to it will not persist across an instance. 3# To disable cloud-init&amp;#39;s network configuration capabilities, write a file 4# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following: 5# network: {config: disabled} 6network: 7 ethernets: 8 ens160: 9 addresses: 10 - 192.168.2.237/24 11 dhcp4: false 12 gateway4: 192.168.2.1 13 nameservers: 14 addresses: 15# - 202.102.134.68 16# - 202.102.128.68 17 - 114.114.114.114 18 - 223.5.5.5 19 search: [] 20 version: 2 修改完成之后使用：sudo netplan apply生效。
</content>
    </entry>
    
     <entry>
        <title>在Mac上编译RedisDesktopManager（1）国际化处理</title>
        <url>https://orchidflower.github.io/2020/07/01/How-to-build-Redis-Desktop-Manager-on-Mac/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>Redis</tag><tag>RDM</tag><tag>RedisDesktopManager</tag>
        </tags>
        <content type="html"> 1. 概述 Redis Desktop Manager（RedisDesktopManager，RDM）是一个快速、简单、支持跨平台的 Redis 桌面管理工具，基于 Qt 5 开发，支持通过 SSH Tunnel 连接。
&amp;ndash; 开源中国上面对项目的介绍
RedisDesktopManager 是一款优秀的 Redis 客户端。最初是作为开源项目发布的，官方也会发布编译好的版本。后来，作者做了一些商业化处理，上架了App Store，从此不再发布编译后的版本，也在开源版本中阉割掉了 SSH Tunnel 功能。有鉴于此，网上有很多人写教程来说明如何从源码构建一个发行版本，但是目前见到的教程多多少少都有一些问题。最近花了一些时间尝试完善整个编译过程，目前进展不错。以后会陆续说明编译过程中碰到的问题以及对应的解决办法。
今天首先来说一下国际化的问题。
目前网上流行的 RedisDesktopManager 编译方法都没有对国际化文件进行处理，所以编译后的版本没有国际化功能，界面只显示英文，语言切换功能无效。经过对相关源码的分析，终于找到了正确的编译处理方法，现在可以完美切换语言。效果如图：
2. 源码分析 国际化有关的文件主要包括以下这些：
src/app/app.cpp src/rdm.pro src/resources/tr.qrc src/resources/translations/*.ts 下面逐个分析。
2.1 app.cpp app.cpp 是整个源码的起始，RedisDesktopManager启动相关的源码基本都在该文件中。里面与国际化有关的主要是 installTranslator 这个函数。
1void Application::installTranslator() { 2 QSettings settings; 3 QString preferredLocale = settings.value(&amp;#34;app/locale&amp;#34;, &amp;#34;system&amp;#34;).toString(); 4 5 QString locale; 6 7 // 如果首选语言是system，则从系统中获取当前语言。在中文版Mac上，获取到的值是 zh-Hans-CN 8 // 这导致了在中文版Mac上如果选择system，界面显示的还是英文，而不是中文。详细内容请看下面的介绍 9 if (preferredLocale == &amp;#34;system&amp;#34;) { 10 settings.setValue(&amp;#34;app/locale&amp;#34;, &amp;#34;system&amp;#34;); 11 locale = QLocale::system().uiLanguages().first().replace(&amp;#34;-&amp;#34;, &amp;#34;_&amp;#34;); 12 13 qDebug() &amp;lt;&amp;lt; QLocale::system().uiLanguages(); 14 15 if (locale.isEmpty() || locale == &amp;#34;C&amp;#34;) locale = &amp;#34;en_US&amp;#34;; 16 17 qDebug() &amp;lt;&amp;lt; &amp;#34;Detected locale:&amp;#34; &amp;lt;&amp;lt; locale; 18 } else { 19 locale = preferredLocale; 20 } 21 22 // 使用locale加载语言包。&amp;#34;:/translations/rdm_&amp;#34;中的&amp;#34;:&amp;#34;是QT中的用法，含义是从资源文件中加载 23 // 这个资源文件应该已经打包在可执行文件内部了。 24 QTranslator* translator = new QTranslator((QObject*)this); 25 if (translator-&amp;gt;load(QString(&amp;#34;:/translations/rdm_&amp;#34;) &#43; locale)) { 26 qDebug() &amp;lt;&amp;lt; &amp;#34;Load translations file for locale:&amp;#34; &amp;lt;&amp;lt; locale; 27 QCoreApplication::installTranslator(translator); 28 } else { 29 delete translator; 30 } 31} 2.2 rdm.pro rdm.pro 文件是 RedisDesktopManager 项目的主工程文件，里面定义了整个项目的结构。其中也定义了国际化相关的内容，主要内容节选如下：
1# 此处首先判断是否存在rdm.qm这个文件，如果存在，则添加tr.qrc文件为资源文件 2exists( $$PWD/resources/translations/rdm.qm ) { 3 message(&amp;#34;Translations found&amp;#34;) 4 RESOURCES &#43;= $$PWD/resources/tr.qrc 5} 6 7# 这里指定了相关的语言包文件 8TRANSLATIONS = \ 9 $$PWD/resources/translations/rdm.ts \ 10 $$PWD/resources/translations/rdm_zh_CN.ts \ 11 $$PWD/resources/translations/rdm_zh_TW.ts \ 12 $$PWD/resources/translations/rdm_ru_RU.ts \ 13 $$PWD/resources/translations/rdm_es_ES.ts \ 14 $$PWD/resources/translations/rdm_ja_JP.ts \ 2.3 tr.qrc .qrc 文件是 QT 的资源定义文件，在编译过程中，资源文件会被打包到可执行文件中（个人猜测，尚未确定，但应该准确）。
1&amp;lt;RCC&amp;gt; 2 &amp;lt;qresource prefix=&amp;#34;/&amp;#34;&amp;gt; 3 &amp;lt;file&amp;gt;translations/rdm_zh_CN.qm&amp;lt;/file&amp;gt; 4 &amp;lt;file&amp;gt;translations/rdm_zh_TW.qm&amp;lt;/file&amp;gt; 5 &amp;lt;file&amp;gt;translations/rdm_ru_RU.qm&amp;lt;/file&amp;gt; 6 &amp;lt;file&amp;gt;translations/rdm_es_ES.qm&amp;lt;/file&amp;gt; 7 &amp;lt;file&amp;gt;translations/rdm_ja_JP.qm&amp;lt;/file&amp;gt; 8 &amp;lt;/qresource&amp;gt; 9&amp;lt;/RCC&amp;gt; 可以看到在资源文件中定义了需要引入的qm文件列表。
2.4 translations 刚下载好的源码中 src/resources/translations 目录下面只有 .ts 文件，ts的含义是 translation source ，也就是翻译源码文件的意思。
3. 编译问题分析及解决 从 rdm.pro 文件中内容来看，编译时只有存在 src/resources/translations/rdm.qm 这个文件的时候才会把 tr.qrc 文件作为资源文件包含进来编译。而实际上下载的源码中目录 src/resources/translations 中只有 .ts 文件没有对应的 .qm 文件，这导致了编译过程中跳过了对语言包的处理，因此编译后的文件失去了国际化的功能。
解决办法就是在正式编译源码之前，首先将ts文件编译成qm文件。方法如下：
1cd src/resources/translations 2for file in `ls -1 *.ts` 3do 4	echo &amp;#34;Convert $file&amp;#34; 5 lconvert -i $file -o ${file%.*}.qm 6done 说明： lconvert是QT带的一个工具，用于在语言包相关各种格式之间转换。需要首先安装qt。（brew install qt）
4. 剩余问题 上面提到，如果语言选择system，在中文版Mac上面是不能够正确显示中文的。其原因是从系统获得的语言名称是zh-Hans-CN，由此期待的语言包文件名是：rdm_zh_Hans_CN.qm，而实际语言包文件名是 rdm_zh_CN.qm ，显然无法找到。
解决办法是多复制一份文件即可：
1cd src/resources/translations 2for file in `ls -1 *.ts` 3do 4	echo &amp;#34;Convert $file&amp;#34; 5 lconvert -i $file -o ${file%.*}.qm 6done 7cp rdm_zh_CN.qm rdm_zh_Hans_CN.qm 同时修改tr.qrc文件，添加这个qm文件：
1&amp;lt;RCC&amp;gt; 2 &amp;lt;qresource prefix=&amp;#34;/&amp;#34;&amp;gt; 3 &amp;lt;file&amp;gt;translations/rdm_zh_CN.qm&amp;lt;/file&amp;gt; 4 &amp;lt;file&amp;gt;translations/rdm_zh_Hans_CN.qm&amp;lt;/file&amp;gt; 5 &amp;lt;file&amp;gt;translations/rdm_zh_TW.qm&amp;lt;/file&amp;gt; 6 &amp;lt;file&amp;gt;translations/rdm_ru_RU.qm&amp;lt;/file&amp;gt; 7 &amp;lt;file&amp;gt;translations/rdm_es_ES.qm&amp;lt;/file&amp;gt; 8 &amp;lt;file&amp;gt;translations/rdm_ja_JP.qm&amp;lt;/file&amp;gt; 9 &amp;lt;/qresource&amp;gt; 10&amp;lt;/RCC&amp;gt; 附录、参考资料 RedisDesktopManager source on Github Mac下一键编译RedisDesktopManager How can I convert qm to ts file? Qt国际化多国语言和发布例子 </content>
    </entry>
    
     <entry>
        <title>如何在Mac上编译vcmi（续）-cpack打包后异常退出</title>
        <url>https://orchidflower.github.io/2020/06/26/How-to-build-vcmi-on-mac-part3/</url>
        <categories>
          <category>游戏</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>英雄无敌</tag><tag>Heroes2</tag><tag>HoMM</tag>
        </tags>
        <content type="html"> 1. 现象 VCMI编译之后可以使用cpack命令（cmake的一个功能）打包成dmg文件，以便于分发。打包过程中会把需要的依赖文件都打包到最后的.app文件中，这样就可以保证在其他机器上也可以正常运行编译后的VCMI。 按照之前的文档，编译之后直接执行没有问题，但是使用cpack打包之后运行缺会异常退出。经过观察基本上发生在第一次战斗中，玩家操作完毕，电脑AI获得控制权的时候就会崩溃退出。
2. 分析 最初怀疑是新版本代码有问题，所以切换到之前版本的代码编译，发现还是有同样的问题。后来经过分析退出的时间点，怀疑是vcmi的AI代码有问题，因为对代码部分不是很熟悉，所以很长时间没有进展。 后来经过查看cpack的工作原理，怀疑是AI库对应的依赖文件没有正确打包导致的。
使用otool -L分析动态库依赖，发现AI目录下的文件没有进行依赖库的处理。还是指向/usr/local/...下面的dylib文件。而vcmiclient/vcmiserver已经进行了处理。因此怀疑是因为引入了两份动态库导致的问题，vcmiclient已经加载了一份动态库，但是当执行到AI库的时候又要从其他位置加载另一份同名的动态库，可能是因为这个原因导致了崩溃。
3. 解决办法 经过查阅cpack的文档，cpack打包的时候使用fixup_bundle对依赖库进行处理。因此改造一下打包脚本，脚本文件是osx/CMakeLists.txt：
1	install(CODE &amp;#34; 2	set(BU_CHMOD_BUNDLE_ITEMS ON) 3	include(BundleUtilities) 4 # 原先的配置文件内容 5 # fixup_bundle(\&amp;#34;\${CMAKE_INSTALL_PREFIX}/${APP_BUNDLE_DIR}\&amp;#34; \&amp;#34;\&amp;#34; \&amp;#34;\&amp;#34;) 6 # 修改成如下的内容。注意：以上这三行不要复制到最后的文件中，只复制下面一行即可。 7	fixup_bundle(\&amp;#34;\${CMAKE_INSTALL_PREFIX}/${APP_BUNDLE_DIR}\&amp;#34; \&amp;#34;libVCAI.dylib;libStupidAI.dylib;libBattleAI.dylib;libEmptyAI.dylib\&amp;#34; \&amp;#34;\${CMAKE_INSTALL_PREFIX}/${BIN_DIR}/AI\&amp;#34;) 8	&amp;#34; COMPONENT Runtime) 说明：
fixup_bundle的用法是：fixup_bundle(&amp;lt;app&amp;gt; &amp;lt;libs&amp;gt; &amp;lt;dirs&amp;gt;)，通常指定.app文件路径即可，会自动修复其中的Contents/MacOS路径下的可执行文件。但是因为vcmi的AI库文件在单独的一个目录中（Contents/MacOS/AI），所以默认没有办法对AI文件进行处理； 修改办法是将AI相关动态库作为lib文件添加到libs参数中，然后使用dirs指定库文件所在的目录； libs 增加libVCAI.dylib;libStupidAI.dylib;libBattleAI.dylib;libEmptyAI.dylib这四个AI的文件。使用分割符 ; (分号)进行分隔； dirs 增加这四个文件所在的目录； 重新cpack即可。 附录、参考资料 Manual of BundleUtilities BundleUtilities source of cmake GetPrerequisites source of cmake cmake foreach manual </content>
    </entry>
    
     <entry>
        <title>如何在Mac上编译vcmi（续）-解决无法播放MP3的问题</title>
        <url>https://orchidflower.github.io/2020/06/21/How-to-build-vcmi-on-mac-part2/</url>
        <categories>
          <category>游戏</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>英雄无敌</tag><tag>Heroes2</tag><tag>HoMM</tag>
        </tags>
        <content type="html"> 1. 问题 按照上一篇文档的步骤编译之后，发现mp3格式的背景音乐无法播放。通过直接执行vcmiclient可以看到在控制台中输出如下信息：
1Warning: Cannot open Music/MainMenu: Unrecognized audio format 2Unable to play music (music parameter was NULL) 原因是我本地环境使用的sdl2_mixer是通过brew安装的，当时无法按照官方文档介绍通过brew install sdl2_mixer --with-smpeg2进行安装。 因为发现无法播放mp3音乐，所以我对这个库进行了一些了解，发现brew官方的版本屏蔽了mp3格式的支持。查看brew官方的源码可以看到：
1def install 2 inreplace &amp;#34;SDL2_mixer.pc.in&amp;#34;, &amp;#34;@prefix@&amp;#34;, HOMEBREW_PREFIX 3 4 args = %W[ 5 --prefix=#{prefix} 6 --disable-dependency-tracking 7 --disable-music-flac 8 --disable-music-flac-shared 9 --disable-music-midi-fluidsynth 10 --disable-music-midi-fluidsynth-shared 11 --disable-music-mod-mikmod-shared 12 --disable-music-mod-modplug-shared 13 --disable-music-mp3-mpg123 14 --disable-music-mp3-mpg123-shared 15 --disable-music-mp3-smpeg 16 --disable-music-ogg-shared 17 --enable-music-mod-mikmod 18 --enable-music-mod-modplug 19 --enable-music-ogg 20 ] 21 22 system &amp;#34;./configure&amp;#34;, *args 23 system &amp;#34;make&amp;#34;, &amp;#34;install&amp;#34; 24 end 可以看到有关mp3的选项都被disabled掉了。
2. 解决办法 brew官方的版本不支持mp3，而且也不提供定制参数。所以只能通过手工编译源码的方式解决。可以使用brew --build-from-source功能简化手工编译的过程。 下载上面的rb文件，编辑如下：
1... 2 # 经过验证，可以只增加 mpg123 这一个依赖库。 3 depends_on &amp;#34;mpg123&amp;#34; 4 # 经过验证，可以不添加smpeg2，但需要同时启用相应的disable选项 5 #depends_on &amp;#34;smpeg2&amp;#34; 6... 7# 屏蔽mp3有关的几个的几个disable选项，相当于启用mp3播放功能 8# 屏蔽mpg123选项，但是继续保留disable shared mpg123的选项，禁用动态链接 9# --disable-music-mp3-mpg123 10 --disable-music-mp3-mpg123-shared 11# 继续屏蔽smpeg2 12 --disable-music-mp3-smpeg 特别注意：
需要保留--disable-music-mp3-mpg123-shared这个选项，否则在libSDL2_mixer.dylib的依赖表中无法看到libmpg123，从而导致使用cpack打包的时候无法侦测到libmpg123这个依赖库； 猜测是因为屏蔽shared之后会使用动态加载动态库的方式，这种方式不会出现在依赖库列表中。 然后使用编译源码的方式安装：
1# 首先卸载已经安装的版本 2brew remove sdl2_mixer 3# 编译安装 4brew install --build-from-source ./sdl2_mixer 这样brew就会读取本地的sdl2_mixer.rb文件，并按照指定的参数进行编译安装了。安装成功之后的sdl2_mixer提供mp3的支持。 不需要重新编译vcmi，直接运行之前编译成功的版本就可以发现mp3格式的背景音乐可以正常播放了！
附录、参考资料 sdl2_mixer on github 更新记录 2020.07.06 明确只需要依赖mpg123这个库即可，明确编译方法。 </content>
    </entry>
    
     <entry>
        <title>如何在Mac上编译vcmi</title>
        <url>https://orchidflower.github.io/2020/05/09/How-to-build-vcmi-on-mac/</url>
        <categories>
          <category>游戏</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>英雄无敌</tag><tag>Heroes2</tag><tag>HoMM</tag>
        </tags>
        <content type="html"> vcmi是英雄无敌三的开源引擎。与fheroes2类似，它依托于英雄无敌3的游戏数据，使用完全重写、开源的引擎，实现了原版游戏的绝大多数功能。相比于原版游戏，对高清分辨率的支持也更好，譬如增加了宽屏分辨率的支持。vcmi使用c&#43;&#43;语言编写，依赖库主要包括：boost，ffmpeg；图形库使用的是SDL2。另外，图形启动工具依赖于QT5。vcmi支持平台包括Windows，MacOS，Android和Linux，算是全平台支持了。
不过官方的发布系统好像有点问题，MacOS版本最新到2019年9月，后面的版本没有构建成功。
英雄无敌3，全称《魔法门之英雄无敌Ⅲ》，是1999年由New World Computing在Windows平台上开发的回合制策略魔幻游戏，其出版商是3DO。在PC版发布之后，3DO和Loki Software分别推出了可在苹果机和Linux系统上运行的版本。
该作是魔法门之英雄无敌系列的第三代。游戏情节参照第一次贯穿了《魔法门VI：天堂之令》，并且部分作为了《魔法门VII：血统与荣耀》的前传。玩家可以选择六个战役之中的一个来进行情节模式，也可以选择场景来进行与电脑或其他玩家的对抗。之后，又陆续发布了《末日之刃》、《死亡阴影》两个资料片，后来又发布了《英雄无敌历代记》共计8个战役。
英雄无敌3历来被称为英雄无敌系列的经典之作，可以说是这个系列游戏的巅峰之作。
vcmi的官网有编译方法的说明，但是有些小的地方有些小问题。特此记录一下，以备后查。本次编译使用cmake在命令行下面完成。需要确保已经安装了xcode及brew。
1. 依赖库安装 1# 安装sdl2，cmake，ffmpeg等 2brew install git cmake sdl2 sdl2_ttf sdl2_image boost ffmpeg minizip 3# 官网安装sdl2_mixer指定了 --with-smpeg2参数，在最新版本上该参数无效 4brew install sdl2_mixer 5# 安装qt5 6brew install qt5 配置环境变量。我使用的是zsh，所以编辑~/.zshrc增加如下内容：
1export PATH=/usr/local/opt/qt/bin:$PATH 2export LDFLAGS=&amp;#34;-L/usr/local/opt/qt/lib&amp;#34; 3export CPPFLAGS=&amp;#34;-I/usr/local/opt/qt/include&amp;#34; 4export PKG_CONFIG_PATH=&amp;#34;/usr/local/opt/qt/lib/pkgconfig&amp;#34; 2. 下载源码 1# 创建工作目录 2mkdir -p ~/work/git/github &amp;amp;&amp;amp; cd ~/work/git/github 3# 下载源码。使用--recursive下载所有依赖的源码库 4git clone --recursive https://github.com/vcmi/vcmi.git 5# 创建一个编译用的工作目录 cmake 6mkdir cmake &amp;amp;&amp;amp; cd cmake 7# 生成make文件 8cmake ../vcmi -G &amp;#34;Unix Makefiles&amp;#34; -DCMAKE_BUILD_TYPE=Release -Wno-devc 请确保之前已经安装好了依赖库，并设置好了环境变量，否则会提示找不到qt5相关的编译信息。
3. 编译 生成make文件之后就可以开始编译了。
1cd ~/work/git/github/cmake 2# 使用cmake编译 3cmake --build . -- -j 4 4. 打包 编译成功后，使用cpack打包，直接生成安装用的dmg文件。
1cd ~/work/git/github/cmake 2# 打包生成dmg文件 3cpack 5. 疑难问题解决 编译过程中碰到的问题通常是因为依赖包引起的。如果出现错误，需要仔细查看提示信息，确认跟什么有关系。 如果确认跟某个依赖包有关系，可以尝试brew remove, brew install重装依赖包，并仔细查看安装记录，确认是否有需要特殊配置的地方，并安装提示进行配置。
附录、参考资料 vcmi官网 vcmi github Installation on MacOS Build on MacOS </content>
    </entry>
    
     <entry>
        <title>如何在Mac上编译fheroes2</title>
        <url>https://orchidflower.github.io/2020/05/08/How-to-build-fheroes2-on-mac/</url>
        <categories>
          <category>游戏</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>英雄无敌</tag><tag>Heroes2</tag><tag>HoMM</tag>
        </tags>
        <content type="html"> fheroes2是英雄无敌2的开源引擎，它基于英雄无敌2的游戏数据，采用完全重写的引擎实现了绝大多数原版游戏的功能。使用的图形引擎是SDL。
Free implementation of Heroes of the Might and Magic II engine. SDL is used.
fheroes2最初是在SourceForge上面开源的，不过最近两年基本停止更新了。最近在Github上偶然发现了有人在继续开发了，并且对图形引擎进行了更新，同时支持SDL2。
因为之前对英雄无敌系列玩得比较多，尤其是2代，而Mac上的Wine在升级到Catalina之后很长一段时间都无法工作（直到最近才有了一些进展），因此尝试着对游戏进行了编译，以在Mac上面可以玩英雄无敌2。下面简单记录一下编译过程，以备后用。
0. 下载源码 1git clone https://github.com/ihhub/fheroes2.git 1. 安装依赖库 依赖库安装需要首先安装brew，具体安装步骤可以参考其他资料。在Mac上面推荐使用SDL2引擎，而不使用SDL1，据说SDL1在Mac新版本上面支持有问题。
1# Uninstall SDL 1.2 2brew remove sdl_image 3brew remove sdl_mixer 4brew remove sdl_ttf 5brew remove sdl 6 7# Install SDL 2 8brew install sdl2 9brew install sdl2_ttf 10brew install sdl2_mixer 11brew install sdl2_image 执行上面的命令，或者直接执行源码中的script/install_sdl2.sh。
2. 编译用的游戏文件 编译fhereos2需要原版的游戏文件，单纯编译的话可以使用源码包中的script/demo/demo_macos.sh脚本下载一个demo版本的游戏文件包。如果速度慢，注意挂代理。
3. 编译 上面两步都执行成功后，在源码根目录执行：
1export WITH_SDL2=&amp;#34;ON&amp;#34; 2make 就可以编译了。尽情在Mac上进入英雄无敌的世界吧~~
附录、参考资料 fheroes2 sourceforge fheroes2 github fheroes2enh github </content>
    </entry>
    
     <entry>
        <title>使用HttpServletRequestWrapper解决无法多次获取request Body的问题</title>
        <url>https://orchidflower.github.io/2020/04/30/Using-HttpServletRequestWrapper-solve-getInputStream/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Java</tag><tag>Spring</tag>
        </tags>
        <content type="html"> 在使用AOP编程的时候，经常碰到需要多次获取整个请求的body的情况。例如：典型场景下我们要在AOP切面中做日志记录或权限校验，此时需要调用request.getInputStream获取输入流，从而读取整个请求的消息体。但是这通常会触发一个异常：java.lang.IllegalStateException: getInputStream() can&#39;t be called after getReader()。
出现这个问题的原因是默认的HttpServletRequest对象中的getInputStream,getReader函数式只允许调用一次。在一次请求中，除了我们在切面中调用getInputStream之外，Spring MVC框架在进行参数转换的时候还需要调用getInputStream方法读取整个请求的消息体，然后转回为请求参数，这违背了只调用一次的原则，从而触发了以异常，
为了解决这个问题，我们可以引入HttpServletRequestWrapper这个对象。这个类封装了HttpServletRequest的行为，我们可以继承这个类，从而使用一个新类模拟原始HttpServletRequest的行为。然后使用过滤器（filter）将原始的HttpServletRequest对象替换为HttpServletRequestWrapper对象。
最近在项目中有需求为API请求增加参数签名校验，使用了AOP切面功能，因此碰到了上面的问题：参数校验切面中需要在读取整个请求报文，然后对报文进行hmac算法从而计算签名值。下面说一下具体的解决办法，以代码为主。
1. 相关代码 1.1 RequestWrapper RequestWrapper继承了HttpServletRequestWrapper，初始化的时候读取Request的整个请求体。然后重载了getInputStream和getReader方法，这两个方法会从类变量body中读取内容。
1public class RequestWrapper extends HttpServletRequestWrapper { 2 private final String body; 3 4 public RequestWrapper(HttpServletRequest request) throws IOException 5 { 6 //So that other request method behave just like before 7 super(request); 8 9 StringBuilder stringBuilder = new StringBuilder(); 10 BufferedReader bufferedReader = null; 11 try { 12 InputStream inputStream = request.getInputStream(); 13 if (inputStream != null) { 14 bufferedReader = new BufferedReader(new InputStreamReader(inputStream)); 15 char[] charBuffer = new char[128]; 16 int bytesRead = -1; 17 while ((bytesRead = bufferedReader.read(charBuffer)) &amp;gt; 0) { 18 stringBuilder.append(charBuffer, 0, bytesRead); 19 } 20 } else { 21 stringBuilder.append(&amp;#34;&amp;#34;); 22 } 23 } catch (IOException ex) { 24 throw ex; 25 } finally { 26 if (bufferedReader != null) { 27 try { 28 bufferedReader.close(); 29 } catch (IOException ex) { 30 throw ex; 31 } 32 } 33 } 34 //Store request pody content in &amp;#39;body&amp;#39; variable 35 body = stringBuilder.toString(); 36 } 37 38 @Override 39 public ServletInputStream getInputStream() throws IOException { 40 final ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(body.getBytes()); 41 ServletInputStream servletInputStream = new ServletInputStream() { 42 @Override 43 public boolean isFinished() { 44 return false; 45 } 46 47 @Override 48 public boolean isReady() { 49 return true; 50 } 51 52 @Override 53 public void setReadListener(ReadListener readListener) { 54 throw new UnsupportedOperationException(); 55 } 56 57 public int read() throws IOException { 58 return byteArrayInputStream.read(); 59 } 60 }; 61 return servletInputStream; 62 } 63 64 @Override 65 public BufferedReader getReader() throws IOException { 66 return new BufferedReader(new InputStreamReader(this.getInputStream())); 67 } 68 69 //Use this method to read the request body N times 70 public String getBody() { 71 return this.body; 72 } 73} 1.2 RequestWrapperFilter RequestWrapperFilter是一个过滤器，它完成将普通的HttpServletRequest转化为RequestWrapper对象的工作。使用时需要使用该filter过滤需要添加校验的url。
1public class RequestWrapperFilter implements Filter { 2 private FilterConfig filterConfig = null; 3 4 @Override 5 public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { 6 servletRequest = new RequestWrapper((HttpServletRequest) servletRequest); 7 //Read request.getBody() as many time you need 8 filterChain.doFilter(servletRequest, servletResponse); 9 } 10 11 @Override 12 public void init(FilterConfig filterConfiguration) throws ServletException { 13 this.filterConfig = filterConfiguration; 14 } 15 16 @Override 17 public void destroy() { 18 this.filterConfig = null; 19 } 20} 1.3 Configuration 在配置类中需要使用FilterRegisterationBean对过滤器进行配置。这里配置过滤url为：/api/dpp/*。
1 @Bean(name=&amp;#34;apiAuthFilter&amp;#34;) 2 public RequestWrapperFilter apiAuthFilter() { 3 return new RequestWrapperFilter(); 4 } 5 6 @Bean(name=&amp;#34;apiAuthBean&amp;#34;) 7 public FilterRegistrationBean apiAuthBean() { 8 FilterRegistrationBean registration = new FilterRegistrationBean(apiAuthFilter()); 9 registration.setOrder(1); 10 registration.addUrlPatterns(&amp;#34;/api/dpp/*&amp;#34;); 11 return registration; 12 } 1.4 ApiAuthAspect ApiAuthAspect完成签名的校验功能。在该类中使用了Spring的RequestContextHolder类获取当前请求对应的HttpServletRequest。注意：这里获取到的对象中实际包含的对象是RequestWrapper对象。 因为是已经重新包装过的RequestWrapper对象，所以可以再次调用getReader,getInputStream方法以获取整个消息体。
需要注意的是：获取到的HttpServletRequest对象无法直接进行类型转换，转换为RequestWrapper，类型不匹配。猜测是容器封装了多次的原因。有时间再仔细研究。
1/** 2 * 获取当前请求的HttpServletRequest对象 3 * @return 4 */ 5 protected HttpServletRequest getHttpServletRequest() { 6 return ((ServletRequestAttributes) RequestContextHolder.currentRequestAttributes()).getRequest(); 7 } 8 9 protected String getRequestBody(HttpServletRequest request) { 10 StringBuffer sb = new StringBuffer(); 11 BufferedReader bufferedReader = null; 12 String content = &amp;#34;&amp;#34;; 13 14 try { 15 //InputStream inputStream = request.getInputStream(); 16 //inputStream.available(); 17 //if (inputStream != null) { 18 bufferedReader = request.getReader() ; //new BufferedReader(new InputStreamReader(inputStream)); 19 char[] charBuffer = new char[128]; 20 int bytesRead; 21 while ( (bytesRead = bufferedReader.read(charBuffer)) != -1 ) { 22 sb.append(charBuffer, 0, bytesRead); 23 } 24 //} else { 25 // sb.append(&amp;#34;&amp;#34;); 26 //} 27 28 } catch (IOException ex) { 29 logger.error(&amp;#34;Failed to getInputStream.&amp;#34;, ex); 30 } finally { 31 if (bufferedReader != null) { 32 try { 33 bufferedReader.close(); 34 } catch (IOException ex) { 35 logger.error(&amp;#34;Failed to getInputStream.&amp;#34;, ex); 36 } 37 } 38 } 39 40 return sb.toString(); 41 } 42 43 public Object apiAuthAround(ProceedingJoinPoint joinPoint) throws Throwable { 44 Object request = joinPoint.getArgs()[0]; 45 MethodSignature signature = ((MethodSignature) joinPoint.getSignature()); 46 47 HttpServletRequest httpRequest = getHttpServletRequest(); 48 String signatureType = httpRequest.getHeader(&amp;#34;x-signature-type&amp;#34;); 49 String signatureData = httpRequest.getHeader(&amp;#34;x-signature-data&amp;#34;); 50 String requestBody = getRequestBody(httpRequest); 51 52 // 校验 53 } 附录、参考资料 How to read request.getInputStream() multiple times HttpServletRequestWrapper example – read httpservletrequest twice </content>
    </entry>
    
     <entry>
        <title>Linux常用命令介绍 04 - journalctl</title>
        <url>https://orchidflower.github.io/2020/04/20/linux-command-introduction-04-journalctl/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Linux</tag>
        </tags>
        <content type="html"> journalctl命令是Systemd日志系统的一个命令，主要用途是用来查看通过Systemd日志系统记录的日志。在Systemd出现之前，Linux系统及各应用的日志都是分别管理的，Systemd开始统一管理了所有Unit的启动日志，这样带来的好处就是可以只用一个 journalctl命令，查看所有内核和应用的日志。
1. 基础用法 1.1 查看所有日志 不用添加任何任何参数运行可以查看本次启动以来的所有日志。
1# 显示本次启动以来的全部日志 2journalctl 1.2 查看内核日志 使用-k参数可以查看内核日志。
1# 显示内核日志 2journalctl -k 1.3 显示最后n行日志 使用-n参数可以显示最后n行日志，如果不指定行数，默认显示10行。
1# 显示最后10行日志 2journalctl -n 3# 显示最后100行日志 4journalctl -n 100 1.4 显示最近一段时间的日志 使用-S或--since参数：
1# 显示最近30分钟以来的日志 2journalctl --since=&amp;#34;30 minutes ago&amp;#34; 3journalctl --since=-30m 4# 显示自2020-04-21 00:00:00以来的日志 5journalctl --since=&amp;#34;2020-04-21&amp;#34; 6# 显示今天以来的日志 7journalctl --since=today 1.5 跟踪最近的日志 使用-f参数可以实现类型tail -f的功能，持续监控最新的日志：
1# 跟踪最近的日志 2journalctl -f 1.6 查看指定Unit的日志 使用-u参数，可以指定特定的unit（Systemd的概念，类似于服务）。例如：
1# 查看sshd的日志 2&amp;gt; journalctl -u sshd 3-- Logs begin at Tue 2019-11-12 20:18:40 CST, end at Fri 2020-04-17 17:45:01 CST. -- 4-- No entries -- 1.7 不进行分页显示 默认情况下，显示结果是进行分页显示的。可以使用-no-pager参数去掉分页功能。如果需要使用管道功能，去掉分页是非常有必要的。
2. 维护 2.1 查看日志占用的磁盘空间 使用--disk-usage参数。例如：
1# 查看日志占用的空间 2&amp;gt; journalctl --disk-usage 3Archived and active journals take up 560.0M in the file system. 2.2 按照占用空间清理日志 1&amp;gt; journalctl --disk-usage 2Archived and active journals take up 350.2M on disk. 3# 清理日志，保留300M的日志 4&amp;gt; journalctl --vacuum-size 200M 5Deleted archived journal /run/log/journal/f94ba353537a4b3f954e3e875225d5d1/system@3064ddfc68cd4fae887e5834914cdce8-000000000027a69c-0005a2067cb4d733.journal (48.8M). 6Deleted archived journal /run/log/journal/f94ba353537a4b3f954e3e875225d5d1/system@3064ddfc68cd4fae887e5834914cdce8-000000000028a54d-0005a21c57b95ba9.journal (48.8M). 7Deleted archived journal /run/log/journal/f94ba353537a4b3f954e3e875225d5d1/system@3064ddfc68cd4fae887e5834914cdce8-000000000029d3a2-0005a239670d6298.journal (48.8M). 8Vacuuming done, freed 146.6M of archived journals on disk. 2.3 按照日志时间清理日志 1# 清理一个周前的日志 2&amp;gt; journalctl --vacuum-time=1week 3Deleted archived journal /run/log/journal/f94ba353537a4b3f954e3e875225d5d1/system@3064ddfc68cd4fae887e5834914cdce8-00000000002b03ce-0005a258817ead63.journal (48.8M). 4Deleted archived journal /run/log/journal/f94ba353537a4b3f954e3e875225d5d1/system@3064ddfc68cd4fae887e5834914cdce8-00000000002c0f37-0005a2e4f7cb5b8f.journal (48.8M). 5Vacuuming done, freed 97.7M of archived journals on disk. 3. 配置 配置文件在/etc/systemd/journald.conf。可能会用到的配置项有：
1# 配置日志系统占用的最大空间。可以实现类似2.2的功能 2SystemMaxUse=500M 3# 定义单个日志文件的大小。最大128M 4SystemMaxFileSize=100M 5# 定义最大日志文件数目。最大100个 6SystemMaxFiles=5 7# 定义日志文件最多保存1个月 8MaxRetentionSec=1month </content>
    </entry>
    
     <entry>
        <title>Linux常用命令介绍 03 - tree</title>
        <url>https://orchidflower.github.io/2020/04/07/linux-command-introduction-03-tree/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Linux</tag>
        </tags>
        <content type="html"> tree命令的作用是以树状图的形式列出目录的内容。通常在写文档时需要列一下文件目录结构，这个时候tree命令就非常有用了
1. 安装&amp;amp;使用 我用的Ubuntu上默认没有安装tree命令。可以通过：sudo apt install tree命令安装。其他的发行版参考对应的命令。
直接使用tree命令或者tree [directory]命令即可列出目录中的内容。
2. 只列出目录 默认情况下，tree命令会同时列出目录中的文件。例如：
1# 列出全部内容 2tree . 3. 4├── Cargo.lock 5├── Cargo.toml 6└── src 7 └── main.rs 8 91 directory, 3 files 如果不想显示文件，则可以使用-d参数，只列出文件夹：
1# 只列出目录 2tree -d . 3. 4└── src 5 61 directory 3. 指定目录的层级 默认可以使用-L参数指定列出的最大目录层数。例如：
1# 只列出两层目录内的结构 2tree -L 2 4. 中文 我在Mac上面使用tree的时候，中文文件名是显示乱码的。可以使用-N参数解决。
1# 解决Mac上面的中文乱码问题。其他平台如果也碰到，也可以尝试 2tree -N 5. 参数介绍 -d List directories only. -L level Max display depth of the directory tree. -N Print non-printable characters as is instead of as escaped octal numbers. </content>
    </entry>
    
     <entry>
        <title>Linux常用命令介绍 02 - ssh</title>
        <url>https://orchidflower.github.io/2020/03/29/linux-command-introduction-02-ssh/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Linux</tag>
        </tags>
        <content type="html"> SSH在Linux中占有重要的地位。通常我们远程登录服务器都是通过ssh协议，但是ssh命令（或者SSH协议）能够实现的功能还有很多。我日常用到一些，但是肯定还有各种各样的用法，有兴趣的朋友可以自行搜索更多资料。
1. 防止掉线 使用SSH连接服务器时候，通常第一个要修改的选项就是防止掉线。总体上来说有两类方法来防止服务器掉线：
客户端/客户端工具发送心跳包； 服务器端发送心跳包。 如果有服务器的控制权，可以修改ssh的配置选项，推荐使用第二种方案，通常更有保障一些。如果没有服务器的控制权，那就只能用第一种了。 1.1 客户端工具SecureCRT 客户端工具配置因工具而异。我用的是SecureCRT，相应的配置可以在：Session Options - Terminal中，对应的选项为：Send protocol NO-OP，这里需要设置每个多少秒钟发送一个NO-OP指令给服务器以维持连接不断开。配置如下图： 1.2 Mac命令行客户端 如果使用Mac命令行中的ssh命令，可以在配置文件.ssh/config中增加如下配置：
1Host myhostshortcut 2 HostName myhost.com 3 User barthelemy 4 ServerAliveInterval 60 5 ServerAliveCountMax 10 1.3 服务器端配置 服务器端配置文件在：/etc/ssh/sshd_config，增加如下配置即可：
1ClientAliveInterval 30 2ClientAliveCountMax 86400 其中的参数说明如下：
ServerAliveInterval: number of seconds that the client will wait before sending a null packet to the server (to keep the connection alive).
ClientAliveInterval: number of seconds that the server will wait before sending a null packet to the client (to keep the connection alive).
Setting a value of 0 (the default) will disable these features so your connection could drop if it is idle for too long.
总结一下：ServerAliveInterval用在客户端配置上，让客户端每个一段时间发送NO_OP包以保持连接想；ClientAliveInterval用在服务器端配置，让服务器端每隔一段时间发送包以保持连接。 除了ServerAliveInterval,ClientAliveInterval外还有：ClientAliveCountMax,ServerAliveCountMax，默认值为3。保持连线的最大时长=Interval*CountMax。
2. 通过SSH映射远程服务器端口到本地 例如：我们在生产环境中有数据库服务器，但是不方便开放端口到外网。而本地的研发或者其他人员也想访问它。这时可以通过ssh协议将远程端口映射到本地网络中。
例如，环境信息如下：
数据库服务器IP为： 192.168.77.99:3306 跳板机地址为：taxfort.eveus.com 跳板机访问用户是ubuntu，访问方式是证书（/opt/apps/taxmyxql/id_rsa）； 映射到本地机器： 192.168.2.236:33306 我们可以使用如下的命令实现：
1#!/bin/bash 2ssh -o StrictHostKeyChecking=no -i /opt/apps/taxmysql/id_rsa -L 192.168.2.236:33306:192.168.77.99:3306 -N ubuntu@taxfort.eveus.com 相关参数介绍：
-o StrictHostKeyChecking=no 跳过服务器证书强制校验。也就是不需要在authorized_keys中存在也可以链接服务器； -i 指定连接用的证书 -L 指定端口映射的信息。格式是：[bind_address:]port:host:hostport -N 不执行远端的命令。 </content>
    </entry>
    
     <entry>
        <title>Mac上面的文件比较功能</title>
        <url>https://orchidflower.github.io/2020/03/20/How-to-compare-file-on-mac/</url>
        <categories>
          <category>技巧</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>FileMerge</tag><tag>ForkLift</tag><tag>file</tag>
        </tags>
        <content type="html"> 以前在Windows上一直使用TotalCmd，它的比较功能非常棒。不论是目录还是文件，只要按下F10，就能够比较，还能够同步，非常方便。切换到Mac也有好几年了，一直没有找到完全匹配上的替代品。现在用的是ForkLift，常用功能还可以，但是比较功能差距很大。目前正在想办法自己写一些脚本增强一下功能。
目前实现了一个脚本，通过ForkLift调用，可以满足基本的比较功能：
使用file判断文件类型，对文本类型调用FileMerge进行源码比较； 如果不是，则只用cmp功能比较内容是否相等； 后期考虑增加对目录类型的支持，引入目录比较工具。 1. 代码 1#!/bin/bash 2# error &amp;#34;Message&amp;#34; 3function error() { 4 osascript &amp;lt;&amp;lt;EOT 5 tell app &amp;#34;System Events&amp;#34; 6 display dialog &amp;#34;$1&amp;#34; buttons {&amp;#34;OK&amp;#34;} default button 1 with icon caution with title &amp;#34;$(basename $0)&amp;#34; 7 return -- Suppress result 8 end tell 9EOT 10} 11 12src=$1 13dst=$2 14 15if [ &amp;#34;$src&amp;#34; = &amp;#34;&amp;#34; -o &amp;#34;$dst&amp;#34; = &amp;#34;&amp;#34; ]; then 16	error &amp;#34;Please choose two files to compare...&amp;#34; 17	exit 1 18fi 19 20# 获取文件类型 21fi1=`file -I -b $src` 22fi2=`file -I -b $dst` 23 24# 只有在全是文本类型的时候使用FileMerge进行比较 25if [[ &amp;#34;$fi1&amp;#34; =~ ^text/.* &amp;amp;&amp;amp; &amp;#34;$fi2&amp;#34; =~ ^text/.* ]]; then 26	/Applications/Xcode.app/Contents/Applications/FileMerge.app/Contents/MacOS/FileMerge -left $1 -right $2 &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp; 27else 28	# 否则，使用cmp比较，直接显示结果 29	cmp -s &amp;#34;$1&amp;#34; &amp;#34;$2&amp;#34; 30	if [ $? -eq 0 ]; then 31	error &amp;#34;Same. Files: \n ${src##*/} \n ${dst##*/}&amp;#34; 32	else 33	error &amp;#34;Not same. Files: \n ${src##*/} \n ${dst##*/}&amp;#34; 34	fi 35fi	2. 用到的工具 2.1 file file命令可以用来获取文件的类型。例如：
1&amp;gt; file -I Application.java 2Application.java: text/x-c; charset=us-ascii 3 4&amp;gt; file -I soapui-settings.xml 5soapui-settings.xml: text/xml; charset=us-ascii 6 7&amp;gt; file -I *.jpg 8mmexport1576413628825.jpg: image/jpeg; charset=binary 9 10&amp;gt; file -I *.mkv 11[终结者：黑暗命运].Terminator.Dark.Fate.2019.BluRay.720p.x264.AC3-CMCT.mkv: video/x-matroska; charset=binary file命令通过多种分析来最终确定一个文件的类型（包括：filesystem tests, magic tests, language tests)，具体的可以看帮助。 常用的几个参数介绍一下：
-I, --mime 打印文件的mime类型编码。也就是打印诸如:text/plain; charset=us-ascii这种格式信息而不是ASCII text。这种返回的类型比较规范，例如上面代码中就是通过判断返回值是否以text开头来判断是否是一个文本文件。 -b, --brief 精简模式。不再输出结果中打印文件名。方便代码中处理。 2.2 cmp cmp命令是一个命令行比较工具，可以按字节比较两个文件是否相同。用到的参数介绍：
-s, --silent 静默比较方式，命令不输出任何内容。需要判断命令的返回值是否为0判断两个文件是否相等。 2.3 FileMerge FileMerge是XCode中自带的一个文件比较工具，可以用来比较源码，它支持命令行调用（通过-left, -right指定文件），而且比较功能也不错。当然，也可以替换成其他的商业软件以获得更强的比较功能。
附录、参考资料 How to Determine File Type &amp;amp; Encoding from Command Line in Mac OS X </content>
    </entry>
    
     <entry>
        <title>Linux常用命令介绍 01 - curl</title>
        <url>https://orchidflower.github.io/2020/03/13/linux-command-introduction-01-curl/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Linux</tag>
        </tags>
        <content type="html"> 很久没有更新博客了。之前一直用hexo，配置起来稍显复杂，单个的时间一长有些忘了，搞不起来了，于是荒废了很长时间。最近下定决心迁移到了Hugo上。总体感觉Hugo速度确实快，这一点非常喜欢。以后有时间可以介绍一下这次迁移的过程。
这几年一直不间断的与Linux打交道，但是Linux的命令一直没有深入研究过，所以碰到问题的时候还是要各种搜索，挺麻烦的。这次想整理一个常用命令的介绍系列，把平常用到的命令简单介绍一下。不会是详尽的帮助类介绍，更多的是基于场景的介绍：譬如要实现什么功能用什么参数之类的。作为以后的备查吧，就不用再到处搜索了。：）
第一个命令介绍curl。
1. 网站诊断 有时候碰到某个网站连接有问题，可以使用curl命令协助解决。例如可以用来排查证书是否正确、返回Header信息是否正确之类的。例如：
1&amp;gt; curl -v -I https://www.baidu.com 2* Trying 180.101.49.12... 3* TCP_NODELAY set 4* Connected to www.baidu.com (180.101.49.12) port 443 (#0) 5* ALPN, offering h2 6* ALPN, offering http/1.1 7* successfully set certificate verify locations: 8* CAfile: /etc/ssl/cert.pem 9 CApath: none 10* TLSv1.2 (OUT), TLS handshake, Client hello (1): 11* TLSv1.2 (IN), TLS handshake, Server hello (2): 12* TLSv1.2 (IN), TLS handshake, Certificate (11): 13* TLSv1.2 (IN), TLS handshake, Server key exchange (12): 14* TLSv1.2 (IN), TLS handshake, Server finished (14): 15* TLSv1.2 (OUT), TLS handshake, Client key exchange (16): 16* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1): 17* TLSv1.2 (OUT), TLS handshake, Finished (20): 18* TLSv1.2 (IN), TLS change cipher, Change cipher spec (1): 19* TLSv1.2 (IN), TLS handshake, Finished (20): 20* SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256 21* ALPN, server accepted to use http/1.1 22* Server certificate: 23* subject: C=CN; ST=beijing; L=beijing; OU=service operation department; O=Beijing Baidu Netcom Science Technology Co., Ltd; CN=baidu.com 24* start date: May 9 01:22:02 2019 GMT 25* expire date: Jun 25 05:31:02 2020 GMT 26* subjectAltName: host &amp;#34;www.baidu.com&amp;#34; matched cert&amp;#39;s &amp;#34;*.baidu.com&amp;#34; 27* issuer: C=BE; O=GlobalSign nv-sa; CN=GlobalSign Organization Validation CA - SHA256 - G2 28* SSL certificate verify ok. 29&amp;gt; HEAD / HTTP/1.1 30&amp;gt; Host: www.baidu.com 31&amp;gt; User-Agent: curl/7.64.1 32&amp;gt; Accept: */* 33&amp;gt; 34&amp;lt; HTTP/1.1 200 OK 35HTTP/1.1 200 OK 36&amp;lt; Accept-Ranges: bytes 37Accept-Ranges: bytes 38&amp;lt; Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform 39Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform 40&amp;lt; Connection: keep-alive 41Connection: keep-alive 42&amp;lt; Content-Length: 277 43Content-Length: 277 44&amp;lt; Content-Type: text/html 45Content-Type: text/html 46&amp;lt; Date: Fri, 13 Mar 2020 08:51:05 GMT 47Date: Fri, 13 Mar 2020 08:51:05 GMT 48&amp;lt; Etag: &amp;#34;575e1f60-115&amp;#34; 49Etag: &amp;#34;575e1f60-115&amp;#34; 50&amp;lt; Last-Modified: Mon, 13 Jun 2016 02:50:08 GMT 51Last-Modified: Mon, 13 Jun 2016 02:50:08 GMT 52&amp;lt; Pragma: no-cache 53Pragma: no-cache 54&amp;lt; Server: bfe/1.0.8.18 55Server: bfe/1.0.8.18 56 57&amp;lt; 58* Connection #0 to host www.baidu.com left intact 59* Closing connection 0 其中的参数介绍如下：
-v, &amp;ndash;verbose 显示详细的提示信息； -I, &amp;ndash;head 只获取请求头信息。在诊断链接的时候使用该参数忽略真正返回的内容比较方便排查原因。 2. 忽略证书 当访问一个自签名证书的网站的时候，可以忽略对证书的校验。例如：
1# 该网站是自签名证书，直接访问无法访问 2&amp;gt; curl https://192.168.2.241 3curl: (60) SSL certificate problem: self signed certificate in certificate chain 4More details here: https://curl.haxx.se/docs/sslcerts.html 5 6curl failed to verify the legitimacy of the server and therefore could not 7establish a secure connection to it. To learn more about this situation and 8how to fix it, please visit the web page mentioned above. 9 10# 加上-k参数，跳过证书检测 11&amp;gt; curl -k https://192.168.2.241 12&amp;lt;!DOCTYPE HTML PUBLIC &amp;#34;-//W3C//DTD HTML 4.01//EN&amp;#34; &amp;#34;http://www.w3.org/TR/html4/strict.dtd&amp;#34;&amp;gt; 13 14&amp;lt;html lang=&amp;#34;en&amp;#34;&amp;gt; 15&amp;lt;head&amp;gt; 16 &amp;lt;meta http-equiv=&amp;#34;content-type&amp;#34; content=&amp;#34;text/html; charset=utf8&amp;#34;&amp;gt; 17 &amp;lt;meta http-equiv=&amp;#34;refresh&amp;#34; content=&amp;#34;0;URL=&amp;#39;/ui&amp;#39;&amp;#34;/&amp;gt; 18&amp;lt;/head&amp;gt; 19&amp;lt;/html&amp;gt; 参数介绍：
-k, &amp;ndash;insecure 跳过对服务器端证书的检测。 3. 设置代理 可以通过-x参数设置代理服务器。例如：
1-x socks5://127.0.0.1:12345 2-x http://127.0.0.1:12346 参数介绍：
-x, --proxy [protocol://]host[:port] protocol可以为：socks4, socks4a, socks5, socks5h, http或者https。默认是http。 4. 发送json请求 可以通过curl直接模拟http访问发送json格式的请求。例如：
1curl -H &amp;#34;Content-Type: application/json&amp;#34; -X POST -d &amp;#39;{ &amp;#34;customerId&amp;#34;: 1, &amp;#34;customerName&amp;#34;: &amp;#34;青岛卓望信息技术有限公司&amp;#34;, &amp;#34;channelId&amp;#34;: 1, &amp;#34;channelName&amp;#34;: &amp;#34;青岛卓望信息技术有限公司&amp;#34;}&amp;#39; https://taxer.fxl.eveus.com/api/admin/qrcode -H 指定请求用的header。这里指定了Content-Type为application/json； -X 指定请求类型。默认是GET。可以是POST、PUT、OPTION等； -d 后面指定请求用的参数。 也可以从文件中读取消息内容，使用-d @filename方式。例如，我们有一个文件request.json，内容如下：
1{ &amp;#34;customerId&amp;#34;: 1, &amp;#34;customerName&amp;#34;: &amp;#34;青岛卓望信息技术有限公司&amp;#34;, &amp;#34;channelId&amp;#34;: 1, &amp;#34;channelName&amp;#34;: &amp;#34;青岛卓望信息技术有限公司&amp;#34;} 然后使用命令请求如下：
1curl -H &amp;#34;Content-Type: application/json&amp;#34; -X POST -d @request.json https://taxer.fxl.eveus.com/api/admin/qrcode 5. 使用个人证书 如果网站使用了双向https认证，则会提供一个客户端证书给访问者。curl也支持使用个人证书进行授权认证。方法是使用参数：--cert和--key。根据证书内容的不同，--key有时可以不使用（如果证书中已经包含了私钥）。 curl不支持p12格式的证书，如果收到的是p12格式的证书（Java程序常用），则可以使用openssl转换成需要的pem格式。方法如下：
1# 如果p12文件是密钥保护的，则需要输入密码 2# 提取证书，包含私钥 3openssl pkcs12 -in client.p12 -out cert&amp;amp;key.pem 4# 只保留证书，不包含私钥 5openssl pkcs12 -in client.p12 -nokeys -out cert.pem 6# 只提取私钥 7openssl pkcs12 -in client.p12 -nocerts -out key.pem -nodes 使用证书进行授权方法的命令如下：
1# 使用包含私钥的证书 2curl --cert cert&amp;amp;key.pem -H &amp;#34;Content-Type: application/json&amp;#34; -X POST -d &amp;#39;{ &amp;#34;customerId&amp;#34;: 1, &amp;#34;customerName&amp;#34;: &amp;#34;青岛卓望信息技术有限公司&amp;#34;, &amp;#34;channelId&amp;#34;: 1, &amp;#34;channelName&amp;#34;: &amp;#34;青岛卓望信息技术有限公司&amp;#34;}&amp;#39; https://taxer.fxl.eveus.com/api/admin/qrcode 3# 使用分开的证书和私钥 4curl --cert cert.pem --key key.pem -H &amp;#34;Content-Type: application/json&amp;#34; -X POST -d &amp;#39;{ &amp;#34;customerId&amp;#34;: 1, &amp;#34;customerName&amp;#34;: &amp;#34;青岛卓望信息技术有限公司&amp;#34;, &amp;#34;channelId&amp;#34;: 1, &amp;#34;channelName&amp;#34;: &amp;#34;青岛卓望信息技术有限公司&amp;#34;}&amp;#39; https://taxer.fxl.eveus.com/api/admin/qrcode </content>
    </entry>
    
     <entry>
        <title>iOS证书及推送相关概念</title>
        <url>https://orchidflower.github.io/2018/09/04/ios-push-and-certificate/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>ios</tag><tag>push</tag><tag>证书</tag><tag>推送</tag>
        </tags>
        <content type="html"> 1.i OS开发中碰到的概念 1.1 开发者账号 苹果对开发者账号分为如下几类：
个人 Individual （$99/year，可以上架Apple Store，最大UUID数目100） 组织 Organizations。又可以写分为两类： 组织 Organization （普通账号，$99/year，能够上传Apple Store，最大UUID数目100） 企业账号 Enterprise Program （企业账号，$299/year，能够进行企业发布，不能够发布到Apple Store，不限制UUID数目） 教育机构（Educational Institutions） 1.2 证书 Certificate 证书是对电脑开发资格的认证，每个开发者帐号有一套。开发者证书可以分为两种：
1.2.1 开发证书 Developer Certification 安装在电脑上提供权限：开发人员通过设备进行真机测试。 可以生成副本供多台电脑使用。
1.2.2 发布证书 Distribution Certification 安装在电脑上提供发布iOS程序的权限：开发人员可以制做测试版和发布版的程序。 不可生成副本，仅有配置该证书的电脑才可使用；
1.3 授权文件 Provisioning Profile 授权文件是对设备如iPod Touch、iPad、iPhone的授权，文件内记录了是设备的UDID和程序的App ID。 即：使被授权的设备可以安装或调试Bundle identifier与授权文件中记录的App ID对应的程序。 开发者帐号在创建授权文件时候会选择App ID，（开发者帐号下App ID中添加，单选）和UDID（开发者帐号下Devices中添加最多100个，多选）。
授权文件分为两种，对应相应的证书使用：
1.3.1 开发授权文件 Developer Provisioning Profile 功能：在装有开发证书或副本的电脑上使用，开发人员选择该授权文件通过电脑将程序安装到授权文件记录的设备中，即可进行真机测试。
注意：
确保电脑有权限真机调试，即安装了开发证书或副本； 在开发工具中程序的Bundle identifier和选中使用的授权文件的App ID要一致； 连接调试的设备的UDID在选中的授权文件中有记录。 1.3.2 发布授权文件 Distribution Provisioning Profile 功能：在装有发布证书的电脑上（即配置证书的电脑，只有一台）制做测试版和发布版的程序。
发布版就是发布到App Store上的程序文件，开发者帐号创建授权文件时选择store选项，选择App ID，无需选择UDID； 测试版就是在发布之前交给测试人员可同步到设备上的程序文件，开发者帐号创建授权文件时选择AdHoc，选择App ID和UDID；只有选中的UDID对应的设备才可能安装上通过该授权文件制做的程序。 1.4 AppID APPID代表了一个具体的APP。通过BundleID定义一个APP，理论上每个APP的BundleID都需要不同，因此在开发者账号中单独有个功能用来维护AppID，需要提供BundleID来创建一个AppID。
AppID会用于生成与APP有关的证书（例如推送证书）和授权文件。在创建这些内容的时候可以选择AppID。
1.5 UDID 每一台Apple设备都会有一个唯一标识符，这就是UDID。Apple会根据这个唯一标识符进行安装方面的限制：
对没有上架的应用，只有UDID包含在对应的授权文件的时候才能安装； 对于上架的应用，Apple应该也维护了一张UDID与AppID的对应表，下载过或购买过的用户会有一条记录（猜测）。 2. 极光推送 极光推送提供了两种推送方式：
红色部分是 APNs 推送，JPush 代理开发者的应用（需要基于开发者提供的应用证书），向苹果 APNs 服务器推送。由 APNs Server 推送到 iOS 设备上。 蓝色部分是 JPush 应用内推送部分，即 App 启动时，内嵌的 JPush SDK 会开启长连接到 JPush Server，从而 JPush Server 可以推送消息到 App 里。 他们的区别及应用场景： 附录、参考资料 【实用帖】苹果开发者账号证书详解 开发者账号类型 极光推送iOS SDK </content>
    </entry>
    
     <entry>
        <title>迁移到SpringBoot 08 - 日志</title>
        <url>https://orchidflower.github.io/2018/07/13/migrating-to-spring-boot-08-logging/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Springboot</tag>
        </tags>
        <content type="html"> SpringBoot默认的日志配置通常来说足够满足要求：日志记录到控制台，也能够配置日志的级别，样式等等。但是其也有些不足：没有了之前logback提供的热更新日志配置的功能。
logback有个非常好用的配置是“scan”，当“scan=true”的时候默认一分钟刷新一次配置。这样可以自动更新系统的日志级别。对于在线系统可以方便修改日志级别获取更加详细的日志，方便定位错误。这样可以保证服务不中断的情况下调整日志级别获取更多日志信息。但是默认的SpringBoot配置中不支持这种选项。
1. 多配置支持 改造方案是使用logback。但是有一点需要注意的是不能够使用通常用的 logback.xml这个文件名来进行配置。因为这个文件名被logback自动扫描，无法做到不同环境不同配置。可以使用logging.config这个配置项，来进行环境不同的设定：
在application.yaml中，如下配置：
1# Set logback configuration file 2logging: 3 config: classpath:logback-default.xml 2. 配置文件 下面是最后使用的配置文件的一个例子，可以供以后项目参考。
1&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; 2 3&amp;lt;configuration debug=&amp;#34;false&amp;#34; scan=&amp;#34;true&amp;#34; &amp;gt; 4 &amp;lt;!-- 定义全局的变量 //--&amp;gt; 5 &amp;lt;property name=&amp;#34;cap.logger.level&amp;#34; value=&amp;#34;info&amp;#34;/&amp;gt; 6 &amp;lt;property name=&amp;#34;cap.logger.level.server&amp;#34; value=&amp;#34;debug&amp;#34;/&amp;gt; 7 &amp;lt;property name=&amp;#34;cap.logger.outputdir&amp;#34; value=&amp;#34;/opt/cap/cap-uid-logs&amp;#34;/&amp;gt; 8 9 &amp;lt;!-- 定义一些converionRule --&amp;gt; 10 &amp;lt;!-- clr 定义色彩 --&amp;gt; 11 &amp;lt;conversionRule conversionWord=&amp;#34;clr&amp;#34; converterClass=&amp;#34;org.springframework.boot.logging.logback.ColorConverter&amp;#34; /&amp;gt; 12 &amp;lt;!-- wex 异常处理用的 --&amp;gt; 13 &amp;lt;conversionRule conversionWord=&amp;#34;wex&amp;#34; converterClass=&amp;#34;org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter&amp;#34; /&amp;gt; 14 &amp;lt;!-- wex 异常处理用的 --&amp;gt; 15 &amp;lt;conversionRule conversionWord=&amp;#34;wEx&amp;#34; converterClass=&amp;#34;org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter&amp;#34; /&amp;gt; 16 17 &amp;lt;jmxConfigurator /&amp;gt; 18 19 &amp;lt;contextListener class=&amp;#34;ch.qos.logback.classic.jul.LevelChangePropagator&amp;#34;&amp;gt; 20 &amp;lt;resetJUL&amp;gt;true&amp;lt;/resetJUL&amp;gt; 21 &amp;lt;/contextListener&amp;gt; 22 23 &amp;lt;!-- Standard syslog/console used by root appenders --&amp;gt; 24 &amp;lt;appender name=&amp;#34;syslog&amp;#34; class=&amp;#34;ch.qos.logback.classic.net.SyslogAppender&amp;#34;&amp;gt; 25 &amp;lt;syslogHost&amp;gt;${PUBLIC_IP}&amp;lt;/syslogHost&amp;gt; 26 &amp;lt;facility&amp;gt;LOCAL7&amp;lt;/facility&amp;gt; 27 &amp;lt;suffixPattern&amp;gt;[%-5level] [%logger{0}] - %msg%n&amp;lt;/suffixPattern&amp;gt; 28 &amp;lt;/appender&amp;gt; 29 30 &amp;lt;!-- console输出，有色彩支持的 //--&amp;gt; 31 &amp;lt;appender name=&amp;#34;console&amp;#34; class=&amp;#34;ch.qos.logback.core.ConsoleAppender&amp;#34;&amp;gt; 32 &amp;lt;!--&amp;lt;encoder class=&amp;#34;ch.qos.logback.classic.encoder.PatternLayoutEncoder&amp;#34;&amp;gt;--&amp;gt; 33 &amp;lt;!--&amp;lt;pattern&amp;gt;[%date] [%-5level] [%logger{0}] - %msg%n&amp;lt;/pattern&amp;gt;--&amp;gt; 34 &amp;lt;!--&amp;lt;/encoder&amp;gt;--&amp;gt; 35 &amp;lt;encoder&amp;gt; 36 &amp;lt;pattern&amp;gt;${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}&amp;lt;/pattern&amp;gt; 37 &amp;lt;/encoder&amp;gt; 38 &amp;lt;/appender&amp;gt; 39 40 &amp;lt;!-- accessFile。使用标准的springboot格式输出，方便阅读。 //--&amp;gt; 41 &amp;lt;appender name=&amp;#34;accessFile&amp;#34; class=&amp;#34;ch.qos.logback.core.rolling.RollingFileAppender&amp;#34;&amp;gt; 42 &amp;lt;rollingPolicy class=&amp;#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&amp;#34;&amp;gt; 43 &amp;lt;!-- daily rollover --&amp;gt; 44 &amp;lt;fileNamePattern&amp;gt;${cap.logger.outputdir}/access_%d{yyyy_MM_dd}.log&amp;lt;/fileNamePattern&amp;gt; 45 &amp;lt;!-- keep 30 days&amp;#39; worth of history capped at 3GB total size --&amp;gt; 46 &amp;lt;maxHistory&amp;gt;90&amp;lt;/maxHistory&amp;gt; 47 &amp;lt;/rollingPolicy&amp;gt; 48 &amp;lt;append&amp;gt;true&amp;lt;/append&amp;gt; 49 &amp;lt;encoder&amp;gt; 50 &amp;lt;pattern&amp;gt;${FILE_LOG_PATTERN:-%d{yyyy-MM-dd HH:mm:ss.SSS} ${LOG_LEVEL_PATTERN:-%5p} ${PID:- } --- [%t] %-40.40logger{39} : %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}&amp;lt;/pattern&amp;gt; 51 &amp;lt;/encoder&amp;gt; 52 &amp;lt;/appender&amp;gt; 53 54 &amp;lt;!-- 使用JSON格式。方便管理平台分析。Use JSONLayout, UID Admin may analysis it //--&amp;gt; 55 &amp;lt;appender name=&amp;#34;errorFile&amp;#34; class=&amp;#34;ch.qos.logback.core.rolling.RollingFileAppender&amp;#34;&amp;gt; 56 &amp;lt;filter class=&amp;#34;ch.qos.logback.classic.filter.ThresholdFilter&amp;#34;&amp;gt; 57 &amp;lt;level&amp;gt;ERROR&amp;lt;/level&amp;gt; 58 &amp;lt;/filter&amp;gt; 59 &amp;lt;rollingPolicy class=&amp;#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&amp;#34;&amp;gt; 60 &amp;lt;!-- daily rollover --&amp;gt; 61 &amp;lt;fileNamePattern&amp;gt;${cap.logger.outputdir}/error_%d{yyyy_MM_dd}.log&amp;lt;/fileNamePattern&amp;gt; 62 &amp;lt;!-- keep 30 days&amp;#39; worth of history capped at 3GB total size --&amp;gt; 63 &amp;lt;maxHistory&amp;gt;90&amp;lt;/maxHistory&amp;gt; 64 &amp;lt;/rollingPolicy&amp;gt; 65 &amp;lt;append&amp;gt;true&amp;lt;/append&amp;gt; 66 &amp;lt;encoder class=&amp;#34;ch.qos.logback.core.encoder.LayoutWrappingEncoder&amp;#34;&amp;gt; 67 &amp;lt;layout class=&amp;#34;com.eveus.common.logger.JSONLayout&amp;#34; /&amp;gt; 68 &amp;lt;/encoder&amp;gt; 69 &amp;lt;/appender&amp;gt; 70 71 &amp;lt;!-- 使用JSON格式。方便管理平台分析。Use JSONLayout, UID Admin may analysis it //--&amp;gt; 72 &amp;lt;appender name=&amp;#34;kafkaErrorFile&amp;#34; class=&amp;#34;ch.qos.logback.core.rolling.RollingFileAppender&amp;#34;&amp;gt; 73 &amp;lt;filter class=&amp;#34;ch.qos.logback.classic.filter.ThresholdFilter&amp;#34;&amp;gt; 74 &amp;lt;level&amp;gt;ERROR&amp;lt;/level&amp;gt; 75 &amp;lt;/filter&amp;gt; 76 &amp;lt;rollingPolicy class=&amp;#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&amp;#34;&amp;gt; 77 &amp;lt;!-- daily rollover --&amp;gt; 78 &amp;lt;fileNamePattern&amp;gt;${cap.logger.outputdir}/kafka_error_%d{yyyy_MM}.log&amp;lt;/fileNamePattern&amp;gt; 79 &amp;lt;!-- keep 30 days&amp;#39; worth of history capped at 3GB total size --&amp;gt; 80 &amp;lt;maxHistory&amp;gt;90&amp;lt;/maxHistory&amp;gt; 81 &amp;lt;/rollingPolicy&amp;gt; 82 &amp;lt;append&amp;gt;true&amp;lt;/append&amp;gt; 83 &amp;lt;encoder class=&amp;#34;ch.qos.logback.core.encoder.LayoutWrappingEncoder&amp;#34;&amp;gt; 84 &amp;lt;layout class=&amp;#34;com.eveus.common.logger.JSONLayout&amp;#34; /&amp;gt; 85 &amp;lt;/encoder&amp;gt; 86 &amp;lt;/appender&amp;gt; 87 88 &amp;lt;!-- third party library logger level --&amp;gt; 89 &amp;lt;logger name=&amp;#34;org.springframework&amp;#34; level=&amp;#34;${cap.logger.level}&amp;#34; /&amp;gt; 90 &amp;lt;logger name=&amp;#34;org.apache.cxf&amp;#34; level=&amp;#34;${cap.logger.level}&amp;#34; /&amp;gt; 91 &amp;lt;logger name=&amp;#34;ch.qos.logback&amp;#34; level=&amp;#34;${cap.logger.level}&amp;#34; /&amp;gt; 92 &amp;lt;logger name=&amp;#34;com.notnoop.apns&amp;#34; level=&amp;#34;${cap.logger.level}&amp;#34; /&amp;gt; 93 &amp;lt;logger name=&amp;#34;org.springframework.security&amp;#34; level=&amp;#34;${cap.logger.level}&amp;#34;/&amp;gt; 94 &amp;lt;logger name=&amp;#34;org.springframework.transaction&amp;#34; level=&amp;#34;${cap.logger.level}&amp;#34; /&amp;gt; 95 &amp;lt;logger name=&amp;#34;org.springframework.jdbc&amp;#34; level=&amp;#34;${cap.logger.level}&amp;#34; /&amp;gt; 96 97 &amp;lt;!-- UID server logger --&amp;gt; 98 &amp;lt;!-- change level to debug to show sql --&amp;gt; 99 &amp;lt;logger name=&amp;#34;com.eveus.cloudauth.dao&amp;#34; level=&amp;#34;info&amp;#34;/&amp;gt; 100 &amp;lt;!-- LoggerAspect, Used for API &amp;amp; Service logging --&amp;gt; 101 &amp;lt;logger name=&amp;#34;com.eveus.common.logger&amp;#34; level=&amp;#34;debug&amp;#34;/&amp;gt; 102 &amp;lt;!-- KafkaConsumer --&amp;gt; 103 &amp;lt;logger name=&amp;#34;com.eveus.common.kafka&amp;#34; level=&amp;#34;info&amp;#34;/&amp;gt; 104 &amp;lt;!-- AccessLogger --&amp;gt; 105 &amp;lt;logger name=&amp;#34;com.eveus.cloudauth.service.impl.jms.AccessLogService&amp;#34; level=&amp;#34;info&amp;#34;/&amp;gt; 106 107 &amp;lt;!-- The following needs detail log in development stage --&amp;gt; 108 &amp;lt;logger name=&amp;#34;com.eveus.cloudauth.api&amp;#34; level=&amp;#34;${cap.logger.level.server}&amp;#34;/&amp;gt; 109 &amp;lt;logger name=&amp;#34;com.eveus.cloudauth.service&amp;#34; level=&amp;#34;${cap.logger.level.server}&amp;#34;/&amp;gt; 110 &amp;lt;logger name=&amp;#34;com.eveus&amp;#34; level=&amp;#34;${cap.logger.level.server}&amp;#34; /&amp;gt; 111 112 &amp;lt;!-- kafka error logger --&amp;gt; 113 &amp;lt;logger name=&amp;#34;com.eveus.common.kafka.KafkaProducer&amp;#34; level=&amp;#34;error&amp;#34;&amp;gt; 114 &amp;lt;appender-ref ref=&amp;#34;kafkaErrorFile&amp;#34;/&amp;gt; 115 &amp;lt;/logger&amp;gt; 116 117 &amp;lt;root level=&amp;#34;${cap.logger.level}&amp;#34;&amp;gt; 118 &amp;lt;appender-ref ref=&amp;#34;console&amp;#34;/&amp;gt; 119 &amp;lt;appender-ref ref=&amp;#34;accessFile&amp;#34;/&amp;gt; 120 &amp;lt;appender-ref ref=&amp;#34;errorFile&amp;#34;/&amp;gt; 121 &amp;lt;/root&amp;gt; 122&amp;lt;/configuration&amp;gt; 3. 部署方式 SpringBoot项目打包的时候会把配置文件一同打包到jar文件中。 这样修改logback配置文件会比较麻烦。所以在部署的时候会把配置文件解压出来，和jar文件放到同一个目录中。这是利用了SpringBoot配置文件加载的一个特性。官方文档介绍如下：
SpringApplication will load properties from application.properties files in the following locations and add them to the Spring Environment（SpringBoot会按照顺序从下面的路径中加载配置文件）:
A /config subdirectory of the current directory. （当前目录内的/config目录） The current directory （当前目录） A classpath /config package （classpath中的/config文件夹） The classpath root （classpath根目录） The list is ordered by precedence (properties defined in locations higher in the list override those defined in lower locations). 利用这个特性，在部署的时候将配置文件解压出来，放到当前目录下（和jar文件统计目录），这样它的优先级高于在jar包中的配置文件。
最后还需要在启动命令中增加配置，指定logback的配置文件，方法是指定logging.config这个Java环境变量：
1-Dspring.profiles.active=chanpayprd -Dlogging.config=file:/opt/cap/cap-uid/logback-chanpayprd.xml 附录、参考资料 USING YAML IN SPRING BOOT TO CONFIGURE LOGBACK </content>
    </entry>
    
     <entry>
        <title>迁移到SpringBoot 07 - Redis发布订阅机制</title>
        <url>https://orchidflower.github.io/2018/07/09/migrating-to-spring-boot-07-Redis-Pub-Sub/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Springboot</tag>
        </tags>
        <content type="html"> Redis中的发布订阅机制（Pub/Sub）是基于channel这一概念的，这有些类似于Kafka中的基于topic的消息机制，只是不支持持久化。如果publish的消息，没有任何client处于&amp;quot;subscribe&amp;quot;状态，消息将会被丢弃。如果client在subcribe时，链接断开后重连，那么此期间的消息也将丢失。Redis server将会&amp;quot;尽力&amp;quot;将消息发送给处于subscribe状态的client，但是仍不会保证每条消息都能被正确接收。
为了解耦发布者(publisher)和订阅者(subscriber)之间的关系，Redis 使用了 channel (频道)作为两者的中介：发布者将信息直接发布给 channel ，而 channel 负责将信息发送给适当的订阅者，发布者和订阅者之间没有相互关系，也不知道对方的存在。
Spring Data Redis组件对Pub/Sub机制进行了抽象，提供了类似JMS的编程模式。Spring Data Redis使用了一个Container（RedisMessageListenerContainer）来解决发布订阅机制。这个Container使用一个Redis链接解决了多个topic订阅的问题。它把其他的订阅、发布者隔离成基本的POJO对象，而不用与Redis对象打交道。这简化了整个编程模型。
1. 使用方法 1.1 Container 首先定义一个Container。
1 @Bean 2 RedisMessageListenerContainer redisContainer() { 3 RedisMessageListenerContainer container = new RedisMessageListenerContainer(); 4 container.setConnectionFactory(redisConnectionFactory); // 注入RedisConnectionFactory 5 return container; 6 } 其中的redisConnectionFactory是通过AutoConfiguration自动创建的对象，按照实际的情况配置spring.redis.*相关配置参数即可创建。如有需要，可以按照自己的需要进行修改。
1.2 发布 发布使用redisTemplate的convertAndSend方法即可。
1 protected void publish(String channel, String message) { 2 try { 3 redisTemplate.convertAndSend(channel, message); 4 logger.info(&amp;#34;publish success! channel={},message={}&amp;#34;, channel, message); 5 } catch (Exception e) { 6 logger.error(&amp;#34;publish error! channel={},message={}, exception: {}&amp;#34;, channel, message, e); 7 } 8 } channel
1.3 订阅 订阅需要指定channel和对应的Handler即可。Handler需要实现MessageListener接口。下面是订阅函数的示例：
1 protected void subscribe(String channel, MessageListener handle) { 2 try { 3 container.addMessageListener(handle, new ChannelTopic(channel)); 4 logger.info(&amp;#34;subscribe success! channel={}&amp;#34;, channel); 5 } catch (Exception e) { 6 logger.error(&amp;#34;subscribe error! channel={}. Exception: {}&amp;#34;, channel, e); 7 } 8 } 一个实现MessageListener接口的例子如下：
1 public void onMessage(Message message, byte[] pattern) { 2 long begin = System.currentTimeMillis(); 3 listCardBin = bankcardBinDal.selectAll(); 4 long timeUsed = System.currentTimeMillis() - begin; 5 logger.info(&amp;#34;receive message &amp;amp; init cardBin success! timeUsed={}ms,[{}:{}]&amp;#34;, timeUsed, new String(pattern), message); 6 } 收到订阅消息后的处理可以在上面接口中实现。
附录、参考资料 PubSub Messaging with Spring Data Redis Spring Data Redis PubSub Documentation </content>
    </entry>
    
     <entry>
        <title>迁移到SpringBoot 06 - Swagger</title>
        <url>https://orchidflower.github.io/2018/07/06/migrating-to-spring-boot-06-swagger/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Springboot</tag>
        </tags>
        <content type="html"> 随着技术的发展，现在的Web系统架构基本都由原来的后端渲染（例如JSP），变成了：前端渲染、前后端分离的形态。前端和后端的唯一联系，变成了API接口。API文档变成了前后端开发人员联系的纽带，变得越来越重要，swagger就是一款让你更好的书写API文档的框架。没有API文档工具之前，大家都是手写API文档的，在什么地方书写的都有，有在Wiki上写的，有在Word里面写的，也有在对应的项目目录下readme.md上写的，每个公司都有每个公司的玩法，无所谓好坏。另外还有专门针对API文档开发的应用，例如showdoc之类的。
书写API文档的工具有很多，但是能称之为“框架”的，估计也只有swagger了。使用Swagger有个好处就是文档与代码结合紧密，更新代码的同时也会更新文档，不用担心同步的问题。而且在Java中使用Swagger也比较方便。
云认证平台提供的Restful接口是基于CXF实现的。网上现有的关于Swagger的文档多数是基于Spring MVC的，并不适用于CXF。下面我将针对CXF&#43;SpringBoot的组合如何使用Swagger进行介绍。
1. 集成方法 分成后端、前端两部分来介绍。Swagger框架包含前端和后端两部分。前端指的是Swagger中的网页和JS部分，它从后台获取一个json或yaml文件，文件中有接口相关的定义信息；后端则负责扫描代码，根据注解相关信息生成对应的json或yaml文件。
1.1 后端 后端指的是如何扫描代码中的swagger标记，生成对应的json格式元数据。这部分使用了CXF库的swagger2Feature这个特性。具体可以参考CXF库的帮助页面。 其原理是开启Swagger2Feature，由CXF库生成这个json元数据。方法就是JAXRSServerFactoryBean调用setFeatures方法，添加一个Swagger2Feature对象。代码如下（@Configuration类）：
1@Bean 2public ServletRegistrationBean cxfServlet() { 3 final ServletRegistrationBean servletRegistrationBean = new ServletRegistrationBean(new CXFServlet(), &amp;#34;/api/*&amp;#34;); 4 servletRegistrationBean.setLoadOnStartup(1); 5 return servletRegistrationBean; 6} 7 8@Bean(destroyMethod = &amp;#34;shutdown&amp;#34;) 9public SpringBus cxf() { 10 return new SpringBus(); 11} 12 13// 新增代码：定义一个SwaggerFeature 14public Swagger2Feature createSwaggerFeature() { 15 Swagger2Feature swagger2Feature = new Swagger2Feature(); 16 swagger2Feature.setPrettyPrint(true); 17 swagger2Feature.setTitle(&amp;#34;UID API&amp;#34;); 18 swagger2Feature.setContact(&amp;#34;limin.zhang&amp;#34;); 19 swagger2Feature.setDescription(&amp;#34;UID &amp;amp; Admin &amp;amp; CAP API&amp;#34;); 20 swagger2Feature.setVersion(&amp;#34;1.0.0&amp;#34;); 21 swagger2Feature.setBasePath(&amp;#34;/api&amp;#34;); 22 swagger2Feature.setResourcePackage(&amp;#34;com.eveus.cloudauth.api&amp;#34;); 23 return swagger2Feature; 24} 25 26 27@Bean(destroyMethod = &amp;#34;destroy&amp;#34;) 28@DependsOn(&amp;#34;cxf&amp;#34;) 29public Server jaxRsServer() throws Exception{ 30 JAXRSServerFactoryBean factory = new JAXRSServerFactoryBean(); 31 factory.setAddress(&amp;#34;/&amp;#34;); 32 factory.setServiceBeans(Arrays.asList(uidApiController, userIdentityApiService, uidAdminApiService)); 33 ArrayList providers = new ArrayList(); 34 providers.add(corsFilter()); 35 providers.add(fastJsonProvider()); 36 factory.setProviders(providers); 37 factory.setFeatures(Arrays.asList(createSwaggerFeature())); // 注入SwaggerFeature 38 return factory.create(); 39 40} 以上功能需要一个库支持，需要添加到pom.xml中：
1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;io.swagger&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;swagger-jaxrs&amp;lt;/artifactId&amp;gt; 4 &amp;lt;version&amp;gt;1.5.7&amp;lt;/version&amp;gt; 5&amp;lt;/dependency&amp;gt; 1.2 前端 前端依然使用springfox-swagger-ui。但是单纯的springfox-swagger-ui这个库只是一个前端文件包。其要工作，还需要后台接口配合（从中获取接口定义json文件）：
/swagger-resources/configuration/security Configuring swagger-ui security /swagger-resources/configuration/ui Configuring swagger-ui options 这些接口依赖于springfox其他库。 因此最终的项目依赖情况如下：
1&amp;lt;!-- Springfox Swagger --&amp;gt; 2&amp;lt;dependency&amp;gt; 3 &amp;lt;groupId&amp;gt;io.springfox&amp;lt;/groupId&amp;gt; 4 &amp;lt;artifactId&amp;gt;springfox-swagger2&amp;lt;/artifactId&amp;gt; 5&amp;lt;/dependency&amp;gt; 6&amp;lt;dependency&amp;gt; 7 &amp;lt;groupId&amp;gt;io.springfox&amp;lt;/groupId&amp;gt; 8 &amp;lt;artifactId&amp;gt;springfox-swagger-ui&amp;lt;/artifactId&amp;gt; 9&amp;lt;/dependency&amp;gt; 基本上配置完这些依赖项之后，Swagger就可以工作了。这里不需要再像Spring MVC使用Swagger一样，定义接口之类的。因为Swagger定义文件已经通过Swagger2Feature生成了。
最后一个问题是json文件的路径问题：springfox-swagger-ui默认访问的后台json地址是 /v2/api-docs，使用swagger2Feature生成的地址为/api/swagger.json（该地址基于CXF监听的地址，上面配置的监听地址是/api/*）。这个路径可以通过 springfox.documentation.swagger.v2.path参数进行配置。例如可以按照下面的方法修改成swagger2Feature生成的地址：
1springfox.documentation.swagger.v2.path: /api/swagger.json 至此可以工作了。访问：http://localhost:8080/swagger-ui.html即可打开swagger文档。
2. 多个JAXRSServerFactoryBean 2.1 更多思考 首先总结一下CXF发布Restful接口的流程： 要使用CXF发布Restful接口，在SpringBoot中首先要定义CXFServlet，这是一个标准的Servlet，一般通过定义：ServletRegistrationBean实现。这一步和之前在Spring中web.xml中的如下配置是一样的：
1	&amp;lt;servlet&amp;gt; 2	&amp;lt;servlet-name&amp;gt;CXFService&amp;lt;/servlet-name&amp;gt; 3	&amp;lt;servlet-class&amp;gt;org.apache.cxf.transport.servlet.CXFServlet&amp;lt;/servlet-class&amp;gt; 4	&amp;lt;/servlet&amp;gt; 5 6	&amp;lt;servlet-mapping&amp;gt; 7	&amp;lt;servlet-name&amp;gt;CXFService&amp;lt;/servlet-name&amp;gt; 8	&amp;lt;url-pattern&amp;gt;/api/*&amp;lt;/url-pattern&amp;gt; 9	&amp;lt;/servlet-mapping&amp;gt; 然后定义一个或多个JAXRSServerFactoryBean，它会创建JaxRsServer，以发布Restful接口。这和如下的xml配置功能类似：
1&amp;lt;jaxrs:server id=&amp;#34;didApiServiceJsonServer&amp;#34; address=&amp;#34;/rest&amp;#34;&amp;gt; 2 &amp;lt;jaxrs:serviceBeans&amp;gt; 3 &amp;lt;ref bean=&amp;#34;uidApiService&amp;#34; /&amp;gt; 4 &amp;lt;/jaxrs:serviceBeans&amp;gt; 5 &amp;lt;jaxrs:providers&amp;gt; 6 &amp;lt;ref bean=&amp;#34;jsonProvider&amp;#34; /&amp;gt; 7 &amp;lt;ref bean=&amp;#34;jsonExceptionMapper&amp;#34; /&amp;gt; 8 &amp;lt;/jaxrs:providers&amp;gt; 9&amp;lt;/jaxrs:server&amp;gt; 2.2 剩余问题 最初寻找用于CXF的Swagger方案的时候，一直无法解决的一个问题是多个JAXRSServerFactoryBean存在的时候如何管理管理API文档。上面的解决方案有投机取巧的地方：将所有需要发布的内容整合到一个JAXRSServerFactoryBean，通过一个JAXRSServerFactoryBean进行发布，这样就可以只生成一个json文件包含所有接口定义了。
但是这个方案是有缺陷的：
首先上述改造方案有个问题就是 /api/这个路径无法查看到CXF已经发布的api列表，会报错。按照传统的Spring中CXF的配置方法，/api/*这个地址是由CXFServlet监听的，这个Servlet可以列出所有使用CXF发布的接口列表，包括SOAP和Restful两种类型的API。但是使用前面的简化配置方案后，将JaxRSServer发布在/api/上。导致不是CXF本身拦截这个路径，而是 JaxRsServer拦截了。所以还是要改成每个Bean单独发布到不同的路径上，例如：/api/rest, /api/admin, /api/v1。
尝试着创建三个SwaggerFeature，配置到三个JAXRSServerFactoryBean中，却发现生成的三个json文件内容是相同的，都对应最后一个设置的JAXRSServerFactoryBean对应的接口定义。经过查找，原来是因为CXF的Swagger2Feature缓存特性导致的。具体看附录中的链接。
Right, those two approaches are very similar. The &amp;lsquo;basePath&amp;rsquo;-based one does implicit Swagger IDs manipulation (scanner / config / &amp;hellip;) by making base path a part of identifier (it triggers when usePathBasedConfig is set). So I think in this regards, we could make this property true by default and cover quite a large number of collisions (there is no need to set Swagger IDs). However, if I understand Łukasz Dywicki correctly, Swagger caching mechanism causing the issues when endpoints are loaded / unloaded dynamically (like in OSGi), in this case Swagger still exposes the API specs even if there are no running endpoints, the fix for this ticket does not address the issue yet but Łukasz Dywicki has a PR.
也就是说说，如果没有配置usePathBasedConfig参数，会以最后basePath为基准检查是否已经生成过，如果生成过则不再重新生成，直接采用缓存。解决办法是使用usePathBasedConfig这个参数，禁用这种错误的缓存策略。
2.3 最终修改方案 2.3.1 ApiConfig 1 @Bean(destroyMethod = &amp;#34;shutdown&amp;#34;) 2 public SpringBus cxf() { 3 return new SpringBus(); 4 } 5 6	// 创建SwaggerFeature，指定usePathBasedConfig为true 7 public Swagger2Feature createCapSwaggerFeature() { 8 Swagger2Feature swagger2Feature = new Swagger2Feature(); 9 swagger2Feature.setPrettyPrint(true); 10 swagger2Feature.setTitle(&amp;#34;CAP API&amp;#34;); 11 swagger2Feature.setContact(&amp;#34;limin.zhang&amp;#34;); 12 swagger2Feature.setDescription(&amp;#34;CAP API&amp;#34;); 13 swagger2Feature.setVersion(&amp;#34;1.0.0&amp;#34;); 14 swagger2Feature.setBasePath(&amp;#34;/api&amp;#34;); 15 // 关键代码：否则swagger2Feature会缓存，不认为这是创建了三个不同的对象 16 swagger2Feature.setUsePathBasedConfig(true); // 设置usePathBasedConfig参数 17 swagger2Feature.setResourcePackage(&amp;#34;com.eveus.cloudauth.api.cap&amp;#34;); 18 return swagger2Feature; 19 } 20 21 22 public Swagger2Feature createUidSwaggerFeature() { 23 Swagger2Feature swagger2Feature = new Swagger2Feature(); 24 swagger2Feature.setPrettyPrint(true); 25 swagger2Feature.setTitle(&amp;#34;UID API&amp;#34;); 26 swagger2Feature.setContact(&amp;#34;limin.zhang&amp;#34;); 27 swagger2Feature.setDescription(&amp;#34;UID API&amp;#34;); 28 swagger2Feature.setVersion(&amp;#34;1.0.0&amp;#34;); 29 swagger2Feature.setBasePath(&amp;#34;/api&amp;#34;); 30 swagger2Feature.setUsePathBasedConfig(true); // 设置usePathBasedConfig参数 31 swagger2Feature.setResourcePackage(&amp;#34;com.eveus.cloudauth.api.uid&amp;#34;); 32 return swagger2Feature; 33 } 34 35 public Swagger2Feature createAdminSwaggerFeature() { 36 Swagger2Feature swagger2Feature = new Swagger2Feature(); 37 swagger2Feature.setPrettyPrint(true); 38 swagger2Feature.setTitle(&amp;#34;Admin API&amp;#34;); 39 swagger2Feature.setContact(&amp;#34;limin.zhang&amp;#34;); 40 swagger2Feature.setDescription(&amp;#34;Admin API&amp;#34;); 41 swagger2Feature.setVersion(&amp;#34;1.0.0&amp;#34;); 42 swagger2Feature.setBasePath(&amp;#34;/api&amp;#34;); 43 swagger2Feature.setUsePathBasedConfig(true); // 设置usePathBasedConfig参数 44 swagger2Feature.setResourcePackage(&amp;#34;com.eveus.cloudauth.api.admin&amp;#34;); 45 return swagger2Feature; 46 } 47 48 49 @Bean(destroyMethod = &amp;#34;destroy&amp;#34;) 50 @DependsOn(&amp;#34;cxf&amp;#34;) 51 public Server capApiJaxRsServer() throws Exception{ 52 JAXRSServerFactoryBean factory = new JAXRSServerFactoryBean(); 53 factory.setAddress(&amp;#34;/v1&amp;#34;); 54 factory.setServiceBean(uidApiController); 55 ArrayList providers = new ArrayList(); 56 providers.add(corsFilter()); 57 providers.add(fastJsonProvider()); 58 factory.setProviders(providers); 59 factory.setFeatures(Arrays.asList(createUidSwaggerFeature())); // 指定一个SwaggerFeature 60 return factory.create(); 61 } 62 63 @Bean(destroyMethod = &amp;#34;destroy&amp;#34;) 64 @DependsOn(&amp;#34;cxf&amp;#34;) 65 public Server uidApiJaxRsServer() throws Exception{ 66 JAXRSServerFactoryBean factory = new JAXRSServerFactoryBean(); 67 factory.setAddress(&amp;#34;/rest&amp;#34;); 68 factory.setServiceBean(userIdentityApiService); 69 ArrayList providers = new ArrayList(); 70 providers.add(corsFilter()); 71 providers.add(fastJsonProvider()); 72 factory.setProviders(providers); 73 factory.setFeatures(Arrays.asList(createUidSwaggerFeature())); // 指定一个SwaggerFeature 74 return factory.create(); 75 } 76 77 @Bean(destroyMethod = &amp;#34;destroy&amp;#34;) 78 @DependsOn(&amp;#34;cxf&amp;#34;) 79 public Server adminApiJaxRsServer() throws Exception{ 80 JAXRSServerFactoryBean factory = new JAXRSServerFactoryBean(); 81 factory.setAddress(&amp;#34;/admin&amp;#34;); 82 factory.setServiceBean(uidAdminApiService); 83 ArrayList providers = new ArrayList(); 84 providers.add(corsFilter()); 85 providers.add(fastJsonProvider()); 86 factory.setProviders(providers); 87 factory.setFeatures(Arrays.asList(createAdminSwaggerFeature())); // 指定一个SwaggerFeature 88 return factory.create(); 89 } 2.3.2 SwaggerConfig 1 @Primary // 关键，否则报错 2 @Bean 3 public SwaggerResourcesProvider swaggerResourcesProvider(InMemorySwaggerResourcesProvider defaultResourcesProvider) { 4 return () -&amp;gt; { 5 // 定义不同的API文档及路径 6 SwaggerResource uidResource = new SwaggerResource(); 7 uidResource.setName(&amp;#34;UID Apis&amp;#34;); 8 uidResource.setSwaggerVersion(&amp;#34;2.0&amp;#34;); 9 uidResource.setLocation(&amp;#34;/api/rest/swagger.json&amp;#34;); 10 11 SwaggerResource adminResource = new SwaggerResource(); 12 adminResource.setName(&amp;#34;Admin Apis&amp;#34;); 13 adminResource.setSwaggerVersion(&amp;#34;2.0&amp;#34;); 14 adminResource.setLocation(&amp;#34;/api/admin/swagger.json&amp;#34;); 15 16 SwaggerResource capResource = new SwaggerResource(); 17 capResource.setName(&amp;#34;CAP Apis&amp;#34;); 18 capResource.setSwaggerVersion(&amp;#34;2.0&amp;#34;); 19 capResource.setLocation(&amp;#34;/api/v1/swagger.json&amp;#34;); 20 // 返回一个List 21 List&amp;lt;SwaggerResource&amp;gt; resources = new ArrayList&amp;lt;&amp;gt;(); 22 resources.add(uidResource); 23 resources.add(adminResource); 24 resources.add(capResource); 25 return resources; 26 }; 27 } 因为现在生成了多个接口定义json文件，通过springfox.documentation.swagger.v2.path参数无法配置多个路径让swagger-ui感知。这时就需要定义SwaggerResourcesProvider这个Bean，springfox-swagger-ui这个库中的js封装了对上述配置的逻辑，会自动获取多个接口定义。
至此，基于SpringBoot&#43;CXF的Swagger使用方案完美了。
附录、参考资料 SwaggerFeature / Swagger2Feature Question: what&amp;rsquo;s the preferred way to override the v2 path? Springboot CXF Swagger example Springfox documentation Multiple swagger JSON&amp;rsquo;s in swagger-ui.html Collision by Swagger2Feature in two OSGI bundles </content>
    </entry>
    
     <entry>
        <title>SpringBoot中使用Jackson导致Long型数据精度丢失问题</title>
        <url>https://orchidflower.github.io/2018/06/22/Handling-Bigint-using-Jackson-in-Springboot/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Springboot</tag><tag>Jackson</tag><tag>精度</tag>
        </tags>
        <content type="html"> 数据库中有一个bigint类型数据，对应java后台类型为Long型，在某个查询页面中碰到了问题：页面上显示的数据和数据库中的数据不一致。例如数据库中存储的是：1475797674679549851，显示出来却成了1475797674679550000，后面几位全变成了0，精度丢失了。
1. 原因 这是因为Javascript中数字的精度是有限的，bigint类型的的数字超出了Javascript的处理范围。JS 遵循 IEEE 754 规范，采用双精度存储（double precision），占用 64 bit。其结构如图：
各位的含义如下：
1位（s） 用来表示符号位 11位（e） 用来表示指数 52位（f） 表示尾数 尾数位最大是 52 位，因此 JS 中能精准表示的最大整数是 Math.pow(2, 53)，十进制即 9007199254740992。而Bigint类型的有效位数是63位（扣除一位符号位），其最大值为：Math.pow(2,63)。任何大于 9007199254740992 的就可能会丢失精度：
19007199254740992 &amp;gt;&amp;gt; 10000000000000...000 // 共计 53 个 0 29007199254740992 &#43; 1 &amp;gt;&amp;gt; 10000000000000...001 // 中间 52 个 0 39007199254740992 &#43; 2 &amp;gt;&amp;gt; 10000000000000...010 // 中间 51 个 0 实际上值却是：
19007199254740992 &#43; 1 // 丢失 29007199254740992 &#43; 2 // 未丢失 39007199254740992 &#43; 3 // 丢失 49007199254740992 &#43; 4 // 未丢失 2.解决方法 解决办法就是让Javascript把数字当成字符串进行处理。对Javascript来说，不进行运算，数字和字符串处理起来没有什么区别。当然如果需要进行运算，只能采用其他方法，例如使用JavaScript的一些开源库bignumber之类的处理了。Java进行JSON处理的时候是能够正确处理long型的，只需要将数字转化成字符串就可以了。例如：
1{ 2 ... 3 &amp;#34;bankcardHash&amp;#34;: 1475797674679549851, 4 ... 5} 变为：
1{ 2 ... 3 &amp;#34;bankcardHash&amp;#34;: &amp;#34;1475797674679549851&amp;#34;, 4 ... 5} 这样Javascript就可以按照字符串方式处理，不存在数字精度丢失了。在Springboot中处理方法基本上有以下几种：
2.1 配置参数write_numbers_as_strings Jackson有个配置参数WRITE_NUMBERS_AS_STRINGS，可以强制将所有数字全部转成字符串输出。其功能介绍为：Feature that forces all Java numbers to be written as JSON strings.。使用方法很简单，只需要配置参数即可：
1spring: 2 jackson: 3 generator: 4 write_numbers_as_strings: true 这种方式的优点是使用方便，不需要调整代码；缺点是颗粒度太大，所有的数字都被转成字符串输出了，包括按照timestamp格式输出的时间也是如此。
2.2 注解 另一个方式是使用注解JsonSerialize：
1 @JsonSerialize(using=ToStringSerializer.class) 2 private Long bankcardHash; 指定了ToStringSerializer进行序列化，将数字编码成字符串格式。这种方式的优点是颗粒度可以很精细；缺点同样是太精细，如果需要调整的字段比较多会比较麻烦。
2.3 自定义ObjectMapper 最后想到可以单独根据类型进行设置，只对Long型数据进行处理，转换成字符串，而对其他类型的数字不做处理。Jackson提供了这种支持。方法是对ObjectMapper进行定制。根据SpringBoot的官方帮助（https://docs.spring.io/spring-boot/docs/current/reference/html/howto-spring-mvc.html#howto-customize-the-jackson-objectmapper），找到一种相对简单的方法，只对ObjectMapper进行定制，而不是完全从头定制，方法如下：
1@Bean(&amp;#34;jackson2ObjectMapperBuilderCustomizer&amp;#34;) 2public Jackson2ObjectMapperBuilderCustomizer jackson2ObjectMapperBuilderCustomizer() { 3 Jackson2ObjectMapperBuilderCustomizer customizer = new Jackson2ObjectMapperBuilderCustomizer() { 4 @Override 5 public void customize(Jackson2ObjectMapperBuilder jacksonObjectMapperBuilder) { 6 jacksonObjectMapperBuilder.serializerByType(Long.class, ToStringSerializer.instance) 7 .serializerByType(Long.TYPE, ToStringSerializer.instance); 8 } 9 }; 10 return customizer; 11} 通过定义Jackson2ObjectMapperBuilderCustomizer，对Jackson2ObjectMapperBuilder对象进行定制，对Long型数据进行了定制，使用ToStringSerializer来进行序列化。问题终于完美解决。
附录、参考资料 Customize the Jackson ObjectMapper Java Code Examples for org.springframework.http.converter.json.Jackson2ObjectMapperBuilder Spring MVC自定义消息转换器(可解决Long类型数据传入前端精度丢失的问题) Jackson Annotation Examples What Every Computer Scientist Should Know About Floating-Point Arithmetic </content>
    </entry>
    
     <entry>
        <title>Spring使用POI导出Excel内存溢出问题的解决（续）</title>
        <url>https://orchidflower.github.io/2018/06/15/Solving-OutOfMemoryException-Happened-when-Exporting-Excel-using-POI-in-Spring-Part2/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>POI</tag><tag>导出Excel</tag>
        </tags>
        <content type="html"> 上篇文章介绍了一个方法，解决了导出Excel过程中内存溢出的问题。但是有些问题还没有搞明白，那就是为什么要这样打开数据库游标？为什么fetchSize必须为：-2147483648？这里面涉及到数据库游标的更多信息，这一篇文章将深入介绍这方面内容。
在数据库中，游标是一个十分重要的概念。游标提供了一种对从表中检索出的数据进行操作的灵活手段，就本质而言，游标实际上是一种能从包括多条数据记录的结果集中每次提取一条记录的机制。游标总是与一条SQL 选择语句相关联因为游标由结果集（可以是零条、一条或由相关的选择语句检索出的多条记录）和结果集中指向特定记录的游标位置组成。
MySQL数据库游标通常有两种形式：Client Side Cursor（客户端游标）和Server Side Cursor（服务器端游标）。默认情况下，客户端游标会把整个结果集获取到客户端内存中，如果结果集太大，就会引发Out Of Memory错误；而服务器端游标会将结果集缓存在服务器端，客户端从服务器端分批获得结果集。
MySQL默认是使用客户端游标的，因为通常情况下，程序处理的结果集不会特别大，对小结果集使用客户端游标效率更高：结果集一次性传输到客户端，客户端可以自行处理，服务器端也可以为其他客户端提供服务。但是针对大结果集，默认的客户端游标处理方式满足不了要求，针对这种情况，MySQL的Java客户端做了一个特殊的处理。下面参照官方帮助看一下。
1. 官方帮助说明 1.1 客户端游标 By default, ResultSets are completely retrieved and stored in memory. In most cases this is the most efficient way to operate and, due to the design of the MySQL network protocol, is easier to implement. If you are working with ResultSets that have a large number of rows or large values and cannot allocate heap space in your JVM for the memory required, you can tell the driver to stream the results back one row at a time. To enable this functionality, create a Statement instance in the following manner:
stmt = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY, java.sql.ResultSet.CONCUR_READ_ONLY); stmt.setFetchSize(Integer.MIN_VALUE);
1&amp;gt;The combination of a forward-only, read-only result set, with a fetch size of Integer.`MIN_VALUE` serves as a signal to the driver to stream result sets row-by-row. After this, any result sets created with the statement will be retrieved row-by-row. 2 3简单翻译一下： 4&amp;gt; 缺省情况下，结果集会被整个的拉取并保存到客户端内存中。通常情况下，这是这是最有效的方式，可以与MySQL的网络协议完美配合。如果你需要处理一个大数量级的结果集或者你无法在你的JVM中申请足够的Heap内存，你可以告诉驱动使用流方式返回结果集，一次返回一条记录。 5 6&amp;gt; 要开启这个功能，可以按照下面的代码方式创建结果Statement： 7 8&amp;gt; ```java 9stmt = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY, 10 java.sql.ResultSet.CONCUR_READ_ONLY); 11stmt.setFetchSize(Integer.MIN_VALUE); 使用TYPE_FORWARD_ONLY，CONCUR_READER_ONLY的组合创建一个Statement，并且指定fetchSize为Integer.MIN_VALUE，这会告诉MySQL的驱动使用流方式处理结果集，一次返回一条记录。
1.2 -2147483648的来历 那么Integer.MIN_VALUE是多少呢？看一下定义：
1@Native public static final int MIN_VALUE = 0x80000000; 计算一下，正好是：-2147483648。这就是之前提到的这个数字的来历，MySQL驱动需要这个数字来明确开启流处理方式。回忆一下之前博文说道的修改方式，其中的fetchSize, resultType都是按照上面帮助中提到的要求进行设置的：
1&amp;lt;select id=&amp;#34;exportByExample&amp;#34; fetchSize=&amp;#34;-2147483648&amp;#34; parameterType=&amp;#34;com.eveus.admin.po.logs.BankcardAuthNoOTPLogPOExample&amp;#34; resultSetType=&amp;#34;FORWARD_ONLY&amp;#34; resultMap=&amp;#34;BaseResultMap&amp;#34;&amp;gt; 2 select 3 &amp;lt;include refid=&amp;#34;Export_Column_List&amp;#34; /&amp;gt; 4 from UID_BANKCARD_AUTH_NO_OTP_LOG 5 &amp;lt;if test=&amp;#34;_parameter != null&amp;#34;&amp;gt; 6 &amp;lt;include refid=&amp;#34;Example_Where_Clause&amp;#34; /&amp;gt; 7 &amp;lt;/if&amp;gt; 8 &amp;lt;if test=&amp;#34;orderByClause != null&amp;#34;&amp;gt; 9 order by ${orderByClause} 10 &amp;lt;/if&amp;gt; 11&amp;lt;/select&amp;gt; 1.3 客户端游标的限制 客户端游标在使用中还是有一些限制或者不足的地方的。我们继续看官方帮助文档：
There are some caveats with this approach. You must read all of the rows in the result set (or close it) before you can issue any other queries on the connection, or an exception will be thrown.
The earliest the locks these statements hold can be released (whether they be MyISAM table-level locks or row-level locks in some other storage engine such as InnoDB) is when the statement completes.
If the statement is within scope of a transaction, then locks are released when the transaction completes (which implies that the statement needs to complete first). As with most other databases, statements are not complete until all the results pending on the statement are read or the active result set for the statement is closed.
Therefore, if using streaming results, process them as quickly as possible if you want to maintain concurrent access to the tables referenced by the statement producing the result set.
翻译一下：
使用这种机制有一些事情需要注意：使用同一个数据库链接，你必须读取结果集中的全部记录（或者关掉结果集）才能够执行新的查询语句，否则会有异常抛出。 只有当Statement执行完毕的时候，其持有的锁才能够被释放（无论是MyISAM的表级锁还是其他存储引擎，例如InnoDB，的行级锁）。 如果该Statement位于一个事务当中，只有当事务完成的时候，Statement持有的锁才会被释放。这同时意味着Statement必须先于事务完成。与大多数数据库一样，只有读取了Statement上的所有结果或关闭了语句的活动结果集，Statement才会关闭。 因此，如果要使用流方式处理结果集，一定要记住尽可能快的处理结果集，以保证对产生结果集的表的并发访问能力。
总结一下就是使用流方式的时候，结果集没有处理完或者Statement没有关闭的时候，是有锁存在的，因此处理速度一定要快，否则会影响并发性能。
1.3 服务器端游标 Another alternative is to use cursor-based streaming to retrieve a set number of rows each time. This can be done by setting the connection property useCursorFetch to true, and then calling setFetchSize(int) with int being the desired number of rows to be fetched each time: 另一个可行的方法是使用基于游标的流处理方式来每次获取指定数量的记录。可以通过在MySQL链接字符串中设置useCursorFetch=true这种参数，然后调用setFetchSize(int)函数来设置期望的每次返回的记录条数。
1conn = DriverManager.getConnection(&amp;#34;jdbc:mysql://localhost/?useCursorFetch=true&amp;#34;, &amp;#34;user&amp;#34;, &amp;#34;s3cr3t&amp;#34;); 2stmt = conn.createStatement(); 3stmt.setFetchSize(100); 4rs = stmt.executeQuery(&amp;#34;SELECT * FROM your_table_here&amp;#34;); 这就是服务器端游标的使用方法：在MySQL连接字符串中增加useCursorFetch=true参数，然后在Statement上执行setFetchSize设置期望每次处理的记录数。就这么简单。使用MyBatis的话，还是需要在Mapper XML文件中使用fetchSize参数来设置期望的记录条数。例如：
1&amp;lt;select id=&amp;#34;exportByExample&amp;#34; fetchSize=&amp;#34;100&amp;#34; parameterType=&amp;#34;com.eveus.admin.po.logs.BankcardAuthNoOTPLogPOExample&amp;#34; resultMap=&amp;#34;BaseResultMap&amp;#34;&amp;gt; 2. 性能测试 看过官方文档，针对大结果集，实际上有两种方式可以用来解决JVM内存溢出的问题：
使用客户端游标方式的流处理方式； 使用服务器端游标方式处理。 那究竟哪种方式效率更高，速度更快呢？写个测试跑一下就知道了：
1Date d1, d2, d3; 2 3BankcardAuthNoOTPLogPOExample example = new BankcardAuthNoOTPLogPOExample(); 4BankcardAuthNoOTPLogPOExample.Criteria criteria = example.createCriteria(); 5criteria.andIdGreaterThan(0L); 6Map&amp;lt;String, Object&amp;gt; readerParams = new HashMap&amp;lt;String, Object&amp;gt;(); 7readerParams.put(&amp;#34;oredCriteria&amp;#34;, example.getOredCriteria()); 8 9MyBatisCursorItemReader&amp;lt;BankcardAuthNoOTPLogPO&amp;gt; reader = new MyBatisCursorItemReader&amp;lt;&amp;gt;(); 10reader.setSqlSessionFactory(sqlSessionFactory); 11reader.setQueryId(&amp;#34;com.eveus.admin.mapper.logs.BankcardAuthNoOTPLogPOCustMapper.exportByExample&amp;#34;); 12reader.setParameterValues(readerParams); 13 14d1 = new Date(); 15reader.open(new ExecutionContext()); // 打开游标 16d2 = new Date(); 17BankcardAuthNoOTPLogPO logPO = null; 18int rows = 0; 19while (( logPO = reader.read()) != null) { 20 rows&#43;&#43;; 21 if (rows%10000==0) { 22 System.out.println(rows); 23 } 24} 25d3 = new Date(); 26System.out.printf(&amp;#34;Test Result:\n Open Cursor: %d, Read all records: %d\n&amp;#34;, d2.getTime()-d1.getTime(), d3.getTime()-d2.getTime()); 27System.out.println(&amp;#34;Done&amp;#34;); 上面的例子，分别记录了游标打开时间，所有记录全部遍历一遍的时间。下面是测试结果：
编号 fetchSize useCursorFetch 打开游标时间（ms) 遍历结果集时间(ms) 内存占用(G) 1 -2147483648 - 82 46466 1.53 2 - - 51641 24835 3.12 3 2000 - 51193 29519 3.09 4 - true 48955 23013 2.88 5 -2147483648 true 90 43334 1.37 6 1000 true 13162 65851 1.49 注1：以上结果基于一个总记录数为2954671的表进行测试所得； 注2：fetchSize参数在MyBatis Mapper文件中设置； 注3：useCursorFetch参数在MySQL链接字符串中设置；
通过结果可以简单分析出来：
fetchSize如果是Integer.MIN_VALUE，则强制进行客户端游标的流处理模式（无论是否指定useCursorFetch参数）； 要使用客户端游标的流处理模式，则fetchSize必须为Integer.MIN_VALUE； 要使用服务器端游标，则必须启用useCursorFetch参数，并指定fetchSize。 3. 如何选择？ 测试结果分析： 根据结果，我们实际上可以将六种测试场景情形归结成三种模式（猜测性质）：
a. 客户端游标的流处理模式，对应测试用例1，5； b. 服务器端游标处理模式，对应测试用例6； c. 传统客户端游标处理模式，对应其他三种测试用例。
游标打开速度：客户端游标的流处理模式耗时最短，不到100ms；其次是服务器端游标，10秒&#43;左右；而对传统的客户端游标处理方式，需要把整个结果集缓冲到客户端，不只是容易引起内存溢出，首次打开游标的时间也非常长，50&#43;秒左右。
记录集遍历速度：传统模式c速度最快，在20-30秒之间；而模式a次之，在40&#43;秒左右；而服务器端游标模式b最慢，65秒了。
内存耗用：内存好用则是模式a、b差不太多，模式c好用内存太多。
所以最终的结论是什么呢？还真是没有完美的方案，最好还是根据自己的场景进行抉择了。另外的方式就是自己也写个测试程序多测测，结合自己的场景才能够选择合适的方案了。
对认证云的问题来说（导出Excel），最终选择的是模式a（客户端游标的流处理方式）：其总体处理速度最快（打开游标和记录遍历时间相加之和最小），占用内存也不大，对我来说是最恰当的方案了。
附录、参考资料 JDBC API Implementation Notes How to set fetchSize for iBatis select statement JDBC performance tuning with optimal fetch size MySQL JDBC/MyBatis Stream方式读取SELECT超大结果集 select * causing &amp;quot; OutOfMemoryError: Java heap space&amp;quot; Streaming MySQL Results Using Java 8 Streams and Spring Data JPA MyBatis 源码解析：SQL 语句的执行机制 </content>
    </entry>
    
     <entry>
        <title>Spring使用POI导出Excel内存溢出问题的解决</title>
        <url>https://orchidflower.github.io/2018/06/11/Solving-OutOfMemoryException-Happened-when-Exporting-Excel-using-POI-in-Spring/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>POI</tag><tag>导出Excel</tag>
        </tags>
        <content type="html"> 云认证平台提供将认证记录导出为Excel的功能。但是当业务量慢慢发展起来以后，就碰到一个比较棘手的问题：需要导出的认证记录太多，导出Excel的时候经常碰到服务器内存溢出问题。例如当要导出30w条记录的时候，服务端内存占用会超过2G，继续增加Heap空间不是一个非常合适的方案，因为无法预知一共需要多少内存。
因此，这两天特意找了一下解决方案，终于有了解决方案。最终方案导出256w条记录的时候，服务器内战占用1.6G，不再继续增加。
1. POI项目简介 用Java导出Excel就无法绕过Apache POI项目。说起来，POI项目这个名字很有意思，它是“Poor Obfuscation Implementation”的缩写，翻译过来是“劣质的困惑的实现”。不过这个名字实际上已经被废弃掉了，只能在早期的文档中找到。这个名字起源于项目的早期，因为微软格式不开放，所以只能够通过反向工程猜测格式的含义，所以才有了这个幽默的称呼。到后来微软开放了OOXML规范，实际上格式已经是开源的标准了。另一个废弃的原因则是出于市场考虑（商业用户对这个名字可能会引起过多联想而不敢采用）。
有兴趣的可以到https://en.wikipedia.org/wiki/Apache_POI上了解一些历史。
POI项目提供了对Word、Excel、PowerPoint、Visio等文件的读写支持。提供了对Office 97到Office2007的格式支持。既支持OOXML标准的文档（.docx, .xlsx, .pptx），也支持旧格式（.doc, .xls, .ppt）。
1.1 Excel相关 POI项目中包含多个子项目，分别对应不同格式文件的读写，不同的读写机制等等。与Excel相关的，主要有两个子项目：
HSSF (Horrible SpreadSheet Format) 读写.xls文件。可以读写Excel 97及之后版本生成的文件。这个格式也被称为“BIFF 8 Format”。因为这个格式没有开源，因此有些特性没有被支持。 XSSF (XML SpreadSheet Format) 读写.xlsx格式。也就是Office Open XML格式。 SXSSF（Small XSSF）读写.xlsx格式。3.8-beta3新增，基于XSSF实现的一个低内存占用的API。这是一个基于流的API。通过限制API能够访问的记录行数来达到减少内存占用的目的。在这种API中，可以只有一部分行保存在内存中，其他的则保存在硬盘缓存中。所以会有一些限制，例如：不在内存中的行无法被访问；Sheet.clone()不被支持；Formula计算不被支持等。 下面是一个表格，列出了各个API的一些特性。 HSSF、XSSF都支持两种编程模型：eventmodel（类似于XML解析中的SAX，基于流的解析）；usermodel（类似于XML解析中的DOM模型）。
2. Excel导出 实际项目中已经使用了SXSSF项目（但是依然会溢出，原因不在Excel这部分，原因下面分析）。这里依然简单的介绍一下怎么使用SXSSF导出一个Excel。下面是一个简单的例子：
1// 创建一个Excel文件，在内存中保存100条记录，其余的会被flush到硬盘上 2Workbook workbook = new SXSSFWorkbook(100); 3// 创建一个Sheet 4Sheet workingSheet = workbook.createSheet(&amp;#34;sheet1&amp;#34;); 5// 创建第一行，用于显示每列标题 6Row row = workingSheet.createRow(0); 7// 创建单元格样式 8Font fontHeader = workbook.createFont(); 9fontHeader.setFontHeightInPoints((short) 10); 10fontHeader.setColor(IndexedColors.BLACK.getIndex()); 11fontHeader.setBoldweight(Font.BOLDWEIGHT_BOLD); 12CellStyle csHeader = workbook.createCellStyle(); 13csHeader.setFont(fontHeader); 14csHeader.setBorderLeft(CellStyle.BORDER_THIN); 15csHeader.setBorderRight(CellStyle.BORDER_THIN); 16csHeader.setBorderTop(CellStyle.BORDER_THIN); 17csHeader.setBorderBottom(CellStyle.BORDER_THIN); 18csHeader.setAlignment(CellStyle.ALIGN_CENTER); 19 20// 手动设置列宽。第一个参数表示要为第几列设置，第二个参数表示列的宽度，n为列高的像素数。 21workingSheet.setColumnWidth(0, (int)(35.7 * 150)); 22Cell cell = row.createCell(0); 23cell.setCellValue(&amp;#34;Title&amp;#34;); 24cell.setCellStyle(csHeader); 与使用XSSF的方法相比，唯一改变的就是创建Excel对象的地方：Workbook workbook = new SXSSFWorkbook(100);，SXSSF需要指定内存中可用的记录数，例如上面的例子中指定了100条记录。超出100条的记录将被写入磁盘，不能够直接访问。但是对于导出Excel这种场景来说，不会有随机访问数据的要求，这样的方式是没有影响的。
3. 使用数据库游标 因为以前已经在项目中使用了SXSSF项目，因此内存溢出问题应该不是POI项目带来的。经过调查，发现这是数据库方面的原因：
如果不适用游标，MySQL默认会将结果集整个都缓存的客户端，对于几十万上百万条记录，这个内存占用是巨大的； MyBatis返回结果集的时候是将JDBC的ResultSet转换成具体对象的List，在这个过程中，会将所有的数据库记录转换成Java对象，更加容易带来内存溢出的问题。 在结果集比较小的情况下，将结果集整体返回，会带来性能上的优势。但是当结果集变大的时候，内存占用和性能上都会碰到极大的问题。以上两个问题，都需要启用游标来解决。
3.1 数据库游标 在数据库中，游标是一个十分重要的概念。游标提供了一种对从表中检索出的数据进行操作的灵活手段，就本质而言，游标实际上是一种能从包括多条数据记录的结果集中每次提取一条记录的机制。游标总是与一条SQL选择语句相关联。因为游标由结果集（可以是零条、一条或由相关的选择语句检索出的多条记录）和结果集中指向特定记录的游标位置组成。当决定对结果集进行处理时，必须声明一个指向该结果集的游标。
通过MyBatis使用游标，有几种方法：SpringBatch项目带来的MyBatisCursorItemReader；MyBatis本身的SqlSession.selectCursor方法；以及MyBatis提供的ResultHandler接口。这几种方法的不同下一篇博文会涉及到。这里只说一下如何使用Spring Batch提供的MyBatisCursorItemReader。
MyBatisCursorItemReader是Spring Batch项目提供的一个Bean，提供了使用游标从数据库读取数据的功能。需要MyBatis 3.4.0或更新版本的支持。其本质还是对SqlSession.selectCursor的一个简单封装，有兴趣的可以看一下源码。
3.2 引入支持包 1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.apache.poi&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;poi-ooxml&amp;lt;/artifactId&amp;gt; 4 &amp;lt;version&amp;gt;3.9&amp;lt;/version&amp;gt; 5&amp;lt;/dependency&amp;gt; 6&amp;lt;!-- MyBatis --&amp;gt; 7&amp;lt;dependency&amp;gt; 8 &amp;lt;groupId&amp;gt;org.mybatis.spring.boot&amp;lt;/groupId&amp;gt; 9 &amp;lt;artifactId&amp;gt;mybatis-spring-boot-starter&amp;lt;/artifactId&amp;gt; 10 &amp;lt;version&amp;gt;1.3.1&amp;lt;/version&amp;gt; 11&amp;lt;/dependency&amp;gt; 12&amp;lt;!-- Spring Batch --&amp;gt; 13&amp;lt;dependency&amp;gt; 14 &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; 15 &amp;lt;artifactId&amp;gt;spring-boot-starter-batch&amp;lt;/artifactId&amp;gt; 16 &amp;lt;version&amp;gt;${springboot.version}&amp;lt;/version&amp;gt; 17&amp;lt;/dependency&amp;gt; 3.3 FetchSize 另一个要改的地方是MyBatis的Mapper文件：
1 &amp;lt;select id=&amp;#34;exportByExample&amp;#34; fetchSize=&amp;#34;-2147483648&amp;#34; parameterType=&amp;#34;com.eveus.admin.po.logs.BankcardAuthNoOTPLogPOExample&amp;#34; resultSetType=&amp;#34;FORWARD_ONLY&amp;#34; resultMap=&amp;#34;BaseResultMap&amp;#34;&amp;gt; 2 select 3 &amp;lt;include refid=&amp;#34;Export_Column_List&amp;#34; /&amp;gt; 4 from UID_BANKCARD_AUTH_NO_OTP_LOG 5 &amp;lt;if test=&amp;#34;_parameter != null&amp;#34;&amp;gt; 6 &amp;lt;include refid=&amp;#34;Example_Where_Clause&amp;#34; /&amp;gt; 7 &amp;lt;/if&amp;gt; 8 &amp;lt;if test=&amp;#34;orderByClause != null&amp;#34;&amp;gt; 9 order by ${orderByClause} 10 &amp;lt;/if&amp;gt; 11 &amp;lt;/select&amp;gt; 注意其中的fetchSize是新增的，其值必须为-2147483648（至于为什么，将在下一篇文章中介绍）。另外，还新增了配置项resultSetType，其值为：FORWARD_ONLY。
3.4 导出过程改造 1// 使用游标获取数据（避免结果集太大引起的OOM错误） 2MyBatisCursorItemReader&amp;lt;MatchCompanyLogPO&amp;gt; reader = new MyBatisCursorItemReader&amp;lt;&amp;gt;(); 3reader.setSqlSessionFactory(sqlSessionFactory); 4reader.setQueryId(&amp;#34;com.eveus.admin.mapper.logs.MatchCompanyLogPOCustMapper.exportByExample&amp;#34;); 5Map&amp;lt;String, Object&amp;gt; readerParams = new HashMap&amp;lt;String, Object&amp;gt;(); 6readerParams.put(&amp;#34;oredCriteria&amp;#34;, example.getOredCriteria()); 7// 设置参数 8reader.setParameterValues(readerParams); 9try { 10 reader.open(new ExecutionContext()); // 打开游标 11 MatchCompanyLogPO logPO; 12 while (( logPO = reader.read()) != null) { 13 // 写入Excel文件 14 ... 15 } 16 logger.info(&amp;#34;exportMatchCompany：文件名{}，共{}条&amp;#34;, fileName, exporter.getNumberOfRows()); 17 logger.info(&amp;#34;exportMatchCompany: Open Cursor: {}, Read all records: {}&amp;#34;, d2.getTime()-d1.getTime(), d3.getTime()-d2.getTime()); 18 ResponseWriteUtil.writeFileStream(exporter.getWorkbook(), fileName, response); 19} catch (Exception e) { 20 logger.error(&amp;#34;exportMatchCompany exception! &amp;#34;, e); 21} 4. 补充 改造的代码不多，但是整个探索的时间确实不少。这可能就是重构的魅力吧。
另外，在导出过程中还发现了一个有趣的事情：最开始导出Excel的时候，发现最多只能导出1048576条记录。最初甚至怀疑是不是数据库方面有什么限制。到最后才发现原来是Excel本身的限制：Excel中一个Sheet最多支持1048576条记录，行号范围为0-1048575。
附录、参考资料 Invalid row number (-32768) outside allowable range (0..1048575) POI操作Excel时最大行、列数的问题及写大量数据时Java heap space内存溢出解决 Mapper XML Files Mybatis 3.4.0 Cursor的使用 使用MySQL Server Side Cursor解决查询数据量过大造成OOM JDBC API Implementation Notes MyBatis中使用流式查询避免数据量过大导致OOM Mysql中使用流式查询避免数据量过大导致OOM-后续 Mybatis 3.4.0 Cursor的使用 </content>
    </entry>
    
     <entry>
        <title>迁移到SpringBoot 05 - 事务管理</title>
        <url>https://orchidflower.github.io/2018/06/01/migrating-to-spring-boot-05-transaction-management/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Springboot</tag>
        </tags>
        <content type="html"> Spring项目中使用数据库的方式多种多样，注入MyBatis、JDBC、Hibernate等等都是支持的。之前的系统是基于MyBatis的。
关于如何Spring Boot和MyBatis网上有很多文章，可以参考。有时间我也会专门写一篇介绍集成的过程。本文讲的就是MyBatis移植到Spring Boot方面碰到的一些问题，主要是事务控制方面的。
1. Spring原始配置 在Spring中，之前是通过XML方式进行的事务配置。通过tx:advice定义了事务的属性；然后通过aop:config将事务织入业务代码。
1&amp;lt;!-- from the file &amp;#39;context.xml&amp;#39; --&amp;gt; 2&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; 3&amp;lt;beans xmlns=&amp;#34;http://www.springframework.org/schema/beans&amp;#34; 4 xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; 5 xmlns:aop=&amp;#34;http://www.springframework.org/schema/aop&amp;#34; 6 xmlns:tx=&amp;#34;http://www.springframework.org/schema/tx&amp;#34; 7 xsi:schemaLocation=&amp;#34; 8 http://www.springframework.org/schema/beans 9 http://www.springframework.org/schema/beans/spring-beans.xsd 10 http://www.springframework.org/schema/tx 11 http://www.springframework.org/schema/tx/spring-tx.xsd 12 http://www.springframework.org/schema/aop 13 http://www.springframework.org/schema/aop/spring-aop.xsd&amp;#34;&amp;gt; 14 15 &amp;lt;!-- this is the service object that we want to make transactional --&amp;gt; 16 &amp;lt;bean id=&amp;#34;fooService&amp;#34; class=&amp;#34;x.y.service.DefaultFooService&amp;#34;/&amp;gt; 17 18 &amp;lt;!-- the transactional advice (what &amp;#39;happens&amp;#39;; see the &amp;lt;aop:advisor/&amp;gt; bean below) --&amp;gt; 19 &amp;lt;tx:advice id=&amp;#34;txAdvice&amp;#34; transaction-manager=&amp;#34;txManager&amp;#34;&amp;gt; 20 &amp;lt;!-- the transactional semantics... --&amp;gt; 21 &amp;lt;tx:attributes&amp;gt; 22 &amp;lt;!-- all methods starting with &amp;#39;get&amp;#39; are read-only --&amp;gt; 23 &amp;lt;tx:method name=&amp;#34;get*&amp;#34; read-only=&amp;#34;true&amp;#34;/&amp;gt; 24 &amp;lt;!-- other methods use the default transaction settings (see below) --&amp;gt; 25 &amp;lt;tx:method name=&amp;#34;*&amp;#34;/&amp;gt; 26 &amp;lt;/tx:attributes&amp;gt; 27 &amp;lt;/tx:advice&amp;gt; 28 29 &amp;lt;!-- ensure that the above transactional advice runs for any execution 30 of an operation defined by the FooService interface --&amp;gt; 31 &amp;lt;aop:config&amp;gt; 32 &amp;lt;aop:pointcut id=&amp;#34;fooServiceOperation&amp;#34; expression=&amp;#34;execution(* x.y.service.FooService.*(..))&amp;#34;/&amp;gt; 33 &amp;lt;aop:advisor advice-ref=&amp;#34;txAdvice&amp;#34; pointcut-ref=&amp;#34;fooServiceOperation&amp;#34;/&amp;gt; 34 &amp;lt;/aop:config&amp;gt; 35 36 &amp;lt;!-- don&amp;#39;t forget the DataSource --&amp;gt; 37 &amp;lt;bean id=&amp;#34;dataSource&amp;#34; class=&amp;#34;org.apache.commons.dbcp.BasicDataSource&amp;#34; destroy-method=&amp;#34;close&amp;#34;&amp;gt; 38 &amp;lt;property name=&amp;#34;driverClassName&amp;#34; value=&amp;#34;oracle.jdbc.driver.OracleDriver&amp;#34;/&amp;gt; 39 &amp;lt;property name=&amp;#34;url&amp;#34; value=&amp;#34;jdbc:oracle:thin:@rj-t42:1521:elvis&amp;#34;/&amp;gt; 40 &amp;lt;property name=&amp;#34;username&amp;#34; value=&amp;#34;scott&amp;#34;/&amp;gt; 41 &amp;lt;property name=&amp;#34;password&amp;#34; value=&amp;#34;tiger&amp;#34;/&amp;gt; 42 &amp;lt;/bean&amp;gt; 43 44 &amp;lt;!-- similarly, don&amp;#39;t forget the PlatformTransactionManager --&amp;gt; 45 &amp;lt;bean id=&amp;#34;txManager&amp;#34; class=&amp;#34;org.springframework.jdbc.datasource.DataSourceTransactionManager&amp;#34;&amp;gt; 46 &amp;lt;property name=&amp;#34;dataSource&amp;#34; ref=&amp;#34;dataSource&amp;#34;/&amp;gt; 47 &amp;lt;/bean&amp;gt; 48 49 &amp;lt;!-- other &amp;lt;bean/&amp;gt; definitions here --&amp;gt; 50 51&amp;lt;/beans&amp;gt; 2. 迁移到SpringBoot 迁移到SpringBoot还是倾向于使用基于Java的配置，因此最初的想法是完全跑起xml配置文件。但是在实践中发现了一些限制：&amp;lt;aop:config&amp;gt;标签无法完整准确的翻译成Java配置。
2.1 限制 通过上网搜索，发现解决方案并不完美：
The @Aspect model in AspectJ is designed for pure-Java configuration, and should be used in favor of aop:config when looking to create 100% java-based configuration using Spring&amp;rsquo;s @Configuration model. aop:config cannot properly be translated into the @Configuration model, largely because Java does not support method literals in the language. This leaves us resorting to String-based references to methods, which is not ideal. So the approach that users should consider are:
Continue using aop:config by including the relevant XML snippet using @ImportResource Convert any existing aop:config elmements to use @Aspect style. 上面推荐的方案有两种：
继续使用xml配置，然后通过 @ImportResource注解导入Java代码中； 转换&amp;lt;aop:config&amp;gt;配置成@Aspect注解。 2.2 最终方案 因为时间的原因，对@Aspect形式的配置没有做深入研究。另外从StackOverflow上查到的说法是，tx-advice并没有合适的Java配置方法，使用xml配置还是最方便的。只是xml配置通过@Configuration中的@ImportResource注解引入即可，这样还是比较优雅，比较符合Java配置的规范性的。因此最终方案是使用了部分xml配置，通过@ImportResource引入。
2.2.1 MasterDataSourceConfig 1@Configuration 2public class MasterDataSourceConfig { 3 static final String PACKAGE = &amp;#34;com.eveus.iot.shadow.mapper&amp;#34;; 4 static final String MAPPER_LOCATION = &amp;#34;classpath:mybatis/mapper/**/*.xml&amp;#34;; 5 6 @Bean 7 @Primary 8 @ConfigurationProperties(&amp;#34;spring.datasource&amp;#34;) 9 public DataSourceProperties firstDataSourceProperties() { 10 return new DataSourceProperties(); 11 } 12 13 @Bean(name = &amp;#34;masterDataSource&amp;#34;) 14 @Primary 15 @ConfigurationProperties(prefix = &amp;#34;spring.datasource&amp;#34;) 16 public DataSource dataSource() { 17 return firstDataSourceProperties().initializeDataSourceBuilder().build(); 18 } 19 20 @Bean(name = &amp;#34;masterTransactionManager&amp;#34;) 21 public DataSourceTransactionManager transactionManager() { 22 return new DataSourceTransactionManager(dataSource()); 23 } 24 25 26 @Bean(name = &amp;#34;masterSqlSessionFactory&amp;#34;) 27 public SqlSessionFactory sqlSessionFactory(@Qualifier(&amp;#34;masterDataSource&amp;#34;) DataSource masterDataSource) 28 throws Exception { 29 final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean(); 30 sessionFactory.setDataSource(masterDataSource); 31 sessionFactory.setMapperLocations(new PathMatchingResourcePatternResolver() 32 .getResources(MasterDataSourceConfig.MAPPER_LOCATION)); 33 return sessionFactory.getObject(); 34 } 35} 定义dataSource, transactionManager。
2.2.2 TransactionConfig 1... 2@Configuration 3@Aspect 4@ComponentScan(&amp;#34;com.eveus.cloudauth&amp;#34;) 5@ImportResource(&amp;#34;classpath:/spring/uid-tx.xml&amp;#34;) 6public class TransactionConfig { 7} 引入xml配置。
2.2.3 uid-tx.xml 1&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; 2&amp;lt;beans xmlns=&amp;#34;http://www.springframework.org/schema/beans&amp;#34; 3 xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; 4 xmlns:aop=&amp;#34;http://www.springframework.org/schema/aop&amp;#34; 5 xmlns:tx=&amp;#34;http://www.springframework.org/schema/tx&amp;#34; 6 xsi:schemaLocation=&amp;#34;http://www.springframework.org/schema/beans 7 http://www.springframework.org/schema/beans/spring-beans.xsd 8 9 http://www.springframework.org/schema/aop 10 http://www.springframework.org/schema/aop/spring-aop.xsd 11 http://www.springframework.org/schema/tx 12 http://www.springframework.org/schema/tx/spring-tx.xsd&amp;#34;&amp;gt; 13 14 &amp;lt;!-- AOP --&amp;gt; 15 &amp;lt;tx:advice id=&amp;#34;merchantTransactionAdvice&amp;#34; transaction-manager=&amp;#34;masterTransactionManager&amp;#34;&amp;gt; 16 &amp;lt;tx:attributes&amp;gt; 17 &amp;lt;tx:method name=&amp;#34;insert*&amp;#34; propagation=&amp;#34;REQUIRED&amp;#34; /&amp;gt; 18 &amp;lt;tx:method name=&amp;#34;update*&amp;#34; propagation=&amp;#34;REQUIRED&amp;#34; /&amp;gt; 19 &amp;lt;tx:method name=&amp;#34;delete*&amp;#34; propagation=&amp;#34;REQUIRED&amp;#34; /&amp;gt; 20 &amp;lt;tx:method name=&amp;#34;lock*&amp;#34; propagation=&amp;#34;REQUIRED&amp;#34; /&amp;gt; 21 &amp;lt;tx:method name=&amp;#34;unlock*&amp;#34; propagation=&amp;#34;REQUIRED&amp;#34; /&amp;gt; 22 23 &amp;lt;tx:method name=&amp;#34;select*&amp;#34; propagation=&amp;#34;SUPPORTS&amp;#34; /&amp;gt; 24 &amp;lt;tx:method name=&amp;#34;list*&amp;#34; propagation=&amp;#34;SUPPORTS&amp;#34; /&amp;gt; 25 26 &amp;lt;tx:method name=&amp;#34;*&amp;#34; propagation=&amp;#34;SUPPORTS&amp;#34; /&amp;gt; 27 &amp;lt;/tx:attributes&amp;gt; 28 &amp;lt;/tx:advice&amp;gt; 29 &amp;lt;aop:config&amp;gt; 30 &amp;lt;aop:pointcut id=&amp;#34;merchantTransactionPointcut&amp;#34; expression=&amp;#34;execution(* com.eveus.cloudauth.dal.mybatis.MerchantDalImpl.*(..))&amp;#34; /&amp;gt; 31 &amp;lt;aop:advisor pointcut-ref=&amp;#34;merchantTransactionPointcut&amp;#34; advice-ref=&amp;#34;merchantTransactionAdvice&amp;#34; /&amp;gt; 32 &amp;lt;/aop:config&amp;gt; 33	... 34&amp;lt;/beans&amp;gt; 如上配置中：transactionManager是在Java配置中定义的。其他的和原先的xml配置没有区别。
附录A. 参考资料 Introduce @Configuration-based equivalent to aop:config XML element JavaConfig: Replacing aop:advisor and tx:advice Aspect Oriented Programming with Spring Spring事务管理（详解&#43;实例） Spring Declarative Transaction Management Example Spring AOP : Replace XML with annotations for transaction management? 零xml配置Spring事务管理 </content>
    </entry>
    
     <entry>
        <title>迁移到SpringBoot 04 - Redis</title>
        <url>https://orchidflower.github.io/2018/05/24/migrating-to-spring-boot-04-Redis/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Springboot</tag>
        </tags>
        <content type="html"> 相比于Spring来说，在SpringBoot中使用Redis大幅简化了。通过使用spring-boot-starter-data-redis，使用Redis变得非常简单。
基本步骤如下：
添加依赖 1&amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;spring-boot-starter-data-redis&amp;lt;/artifactId&amp;gt; 4&amp;lt;/dependency&amp;gt; 配置application.properties/yaml 1spring: 2 redis: 3 host: 192.168.2.230 4 port: 6379 5 password: xxxxxx 6 database: 1 7 timeout: 3000ms 注入RedisTemplate使用 1 @Autowired 2 StringRedisTemplate stringRedisTemplate; 就是这么简单。
1. Redis自动注册 刚开始使用spring-boot-starter-data-redis的时候很奇怪在propertySource中的配置参数(spring.redis.*）是怎么起作用的？
最初怀疑是在包spring-boot-starter-data-redis中，但是查看源码发现这个包没有任何源码，只是一个pom文件，提供了对：spring-data-redis、jedis的依赖。
后来有怀疑是不是在spring-data-redis包中。上Github中看源码也没有。
最后才发现原来是在Spring-boot中的spring-boot-autoconfigure这个包里面的RedisAutoConfiguration这个类中。
1@Configuration 2@ConditionalOnClass({ JedisConnection.class, RedisOperations.class, Jedis.class }) 3@EnableConfigurationProperties(RedisProperties.class) 4public class RedisAutoConfiguration { 5	/** 6	* Redis connection configuration. 7	*/ 8	@Configuration 9	@ConditionalOnClass(GenericObjectPool.class) 10	protected static class RedisConnectionConfiguration {	private final RedisProperties properties; 11	public RedisConnectionConfiguration(RedisProperties properties, 12	ObjectProvider&amp;lt;RedisSentinelConfiguration&amp;gt; sentinelConfiguration, 13	ObjectProvider&amp;lt;RedisClusterConfiguration&amp;gt; clusterConfiguration) { 14	this.properties = properties; 15	this.sentinelConfiguration = sentinelConfiguration.getIfAvailable(); 16	this.clusterConfiguration = clusterConfiguration.getIfAvailable(); 17	} 18	19	@Bean 20	@ConditionalOnMissingBean(RedisConnectionFactory.class) 21	public JedisConnectionFactory redisConnectionFactory() 22	throws UnknownHostException { 23	return applyProperties(createJedisConnectionFactory()); 24	} 25	26	// 根据参数情况决定创建那种类型的Factory：可以是Cluster、Sentinel或者普通模式。 27	private JedisConnectionFactory createJedisConnectionFactory() { 28	JedisPoolConfig poolConfig = this.properties.getPool() != null 29	? jedisPoolConfig() : new JedisPoolConfig(); 30 31	if (getSentinelConfig() != null) { 32	return new JedisConnectionFactory(getSentinelConfig(), poolConfig); 33	} 34	if (getClusterConfiguration() != null) { 35	return new JedisConnectionFactory(getClusterConfiguration(), poolConfig); 36	} 37	return new JedisConnectionFactory(poolConfig); 38	} 39 ... 40 } 41 .... 42} 可以看到在AutoConfiguration中大量使用了Condition类型的注解。spring-boot会根据当前类路径上存在的类情况以及Bean是否已经创建的情况决定是否要创建Bean。
上面只是代码的一部分，展示了怎么根据配置创建RedisConnectionFactory对象。
真正与PropertySource有关的代码在RedisProperties这个类中：
1/** 2 * Configuration properties for Redis. 3 * 4 * @author Dave Syer 5 * @author Christoph Strobl 6 * @author Eddú Meléndez 7 * @author Marco Aust 8 */ 9@ConfigurationProperties(prefix = &amp;#34;spring.redis&amp;#34;) 10public class RedisProperties { 11	private int database = 0; 12	private String url; 13	.... 看代码，通过@ConfigurationProperties这个注解指定了prefix，从而可以从.properties或.yaml类型的配置文件直接读取redis相关的配置参数。
2. 自定义Bean 在RedisAutoConfiguration中会自动根据参数配置情况决定创建那种redis的链接池。这一点非常方便。可以直接在其他类中使用@Autowired注入：JedisConnectionFactory类型的变量。另外，该类还会自动创建两个Bean：
RedisTemplate&amp;lt;Object, Object&amp;gt; StringRedisTemplate 但是通常情况下这两个Bean不一定能够满足要求（例如其序列化支持方式可能不满足要求），这时可以手动创建者类Bean。像这样： 1@Configuration 2public class RedisConfig { 3 4 @SuppressWarnings(&amp;#34;SpringJavaInjectionPointsAutowiringInspection&amp;#34;) 5 @Autowired 6 RedisConnectionFactory redisConnectionFactory; 7 8 @Bean(name=&amp;#34;redisSerializer&amp;#34;) 9 public StringRedisSerializer redisSerializer() { 10 return new StringRedisSerializer(); 11 } 12 13 @Bean(name=&amp;#34;redisTemplate&amp;#34;) 14 public RedisTemplate&amp;lt;String, String&amp;gt; redisTemplate() { 15 RedisTemplate&amp;lt;String, String&amp;gt; redisTemplate = new RedisTemplate&amp;lt;String, String&amp;gt;(); 16 redisTemplate.setConnectionFactory(redisConnectionFactory); 17 redisTemplate.setDefaultSerializer(redisSerializer()); 18 return redisTemplate; 19 } 20} 你可以自己定义Serializer，达到完全的控制。上面只是个例子，实际调用的还是spring-data-redis中的StringRedisSerializer。
3. 关闭自动注册 当然，如果不需要Spring Boot自动注册这些Bean，可以禁用Redis的AutoConfiguration。比较常见的方式是通过@EnableAutoConfiguration注解中的exclude参数来解决，例如：
1@EnableAutoConfiguration(exclude = {RedisAutoConfiguration.class}) 更多方法可以参考附录。关闭自动注册以后就可以像以前一样自定义所有的Bean。
4. Intellij报错的问题 RedisAutoConfiguration会自动创建RedisConnectionFactory和RedisTemplate，但是在intellij idea中检测会有问题。只有当@Autowired写到Application类中的时候才不报错。添加到其他@Configuration类中则会报无法autowire错误：
Could not autowire bean &#39;RedisConnectionFactory&#39;....。
实际编译的时候不报错，说明是正确的，只是IDE检测的问题。这应该是idea的bug，或者支持还不完善。可以参考附录中的资料。
可以通过注解@SuppressWarnings这个注解解决这个问题，就如同上面的代码中显示的那样。
附录、参考资料 Autowiring for Bean Class inspection in Spring Boot project Disabling Redis Auto-configuration in Spring Boot applications Spring Data Redis示例 Spring Boot学习之旅：（六）springboot 整合 redis 以及 redis 通用工具类 spring-data-redis注册fastjson序列化工具 redis-10-spring-boot 如何使用RedisTemplate访问Redis数据结构 </content>
    </entry>
    
     <entry>
        <title>迁移到SpringBoot 03 - Servlet和Filter</title>
        <url>https://orchidflower.github.io/2018/05/18/migrating-to-spring-boot-03-Servlet-Filter/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Springboot</tag>
        </tags>
        <content type="html"> 原先云认证中有几个特殊加载的组件：
checkingServlet：一个Servlet，用于检查系统的状态，主要用于负载均衡LB检测服务是否正常使用。该Servlet定义了了一组URL，可以用来检查系统的状态，例如：/checking/database（检查数据库是否可以访问），/checking/version（返回系统版本号），/checking（总体检查系统状态）等。这些功能理论上不适用Servlet也能够实现，但是由于历史原因采用了Servlet，这次一直也不考虑重新编写。 ClientCertificateFromProxyFilter：一个Filter，用于检查负载均衡转发过来的客户端证书，配合Spring Security完成双向SSL的认证工作。 1. Spring中的处理 之前为了能够使用Spring的注入功能，将参数自动注入Servlet中，还特地写了一个辅助类，模仿Spring中的DelegatingFilterProxy实现的。有了这个辅助类，可以将Servlet定义成普通的Spring Bean，从而使用Spring带来的便利。这个类的代码大概如下：
1package com.eveus.website.servlet.support; 2 3import org.springframework.web.context.WebApplicationContext; 4import org.springframework.web.context.support.WebApplicationContextUtils; 5 6import javax.servlet.*; 7import java.io.IOException; 8 9/** 10 * Servlet代理。 11 * 将一个Spring管理的Bean作为Servlet的代理实现。该Bean需要extends HttpServlet，并实现相应的方法。 12 * 13 * @author limin.zhang 14 * @version $Id: $Id 15 */ 16public class DelegatingServletProxy extends GenericServlet { 17 18 private static final long serialVersionUID = 6485296276572157986L; 19 private String targetBean; 20 private Servlet proxy; 21 22 /** {@inheritDoc} */ 23 @Override 24 public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException { 25 proxy.service(req, res); 26 } 27 28 /** {@inheritDoc} */ 29 @Override 30 public void init() throws ServletException { 31 this.targetBean = getServletName(); 32 getServletBean(); 33 proxy.init(getServletConfig()); 34 } 35 36 private void getServletBean() { 37 WebApplicationContext wac = WebApplicationContextUtils.getRequiredWebApplicationContext(getServletContext()); 38 this.proxy = (Servlet) wac.getBean(targetBean); 39 } 40} DelegatingServletProxy的作用作为一个代理类，会自动通过WebApplicationContextUtils工具类获取同名的Spring对象。然后将请求代理给这个对象。 为了能够正常工作，需要初始化两个地方：
1.1 web.xml 1 &amp;lt;servlet&amp;gt; 2 &amp;lt;servlet-name&amp;gt;checkingServlet&amp;lt;/servlet-name&amp;gt; 3 &amp;lt;servlet-class&amp;gt;com.eveus.website.servlet.support.DelegatingServletProxy&amp;lt;/servlet-class&amp;gt; 4 &amp;lt;/servlet&amp;gt; 5 6 &amp;lt;servlet-mapping&amp;gt; 7 &amp;lt;servlet-name&amp;gt;checkingServlet&amp;lt;/servlet-name&amp;gt; 8 &amp;lt;url-pattern&amp;gt;/checking/*&amp;lt;/url-pattern&amp;gt; 9 &amp;lt;/servlet-mapping&amp;gt; 通过web.xml加载DelegatingServletProxy辅助类，然后做好mapping。
1.2 spring bean配置 1 &amp;lt;!-- Servlet Bean definition. Will be delegated by DelegatingServletProxy --&amp;gt; 2 &amp;lt;!-- CheckingServlet, used to show server version &amp;amp; check system status --&amp;gt; 3 &amp;lt;bean id=&amp;#34;checkingServlet&amp;#34; class=&amp;#34;com.eveus.website.servlet.CheckingServlet&amp;#34;&amp;gt; 4 &amp;lt;/bean&amp;gt; 然后把Bean定义成普通的Spring Bean就可以使用了。
2. SpringBoot改造 在Spring boot项目中，通常是不存在web.xml的。因此希望能够不使用web.xml完成配置。通过从网上搜索资料，找到了以下几个方案。
2.1 WebApplicationInitializer / SpringBootServletInitializer 最先找到的方法是WebApplicationInitializer，这是Servlet 3.0规范引入的扩展点。这是Spring 4之后新增的一个接口，其官方文档介绍如下：
Interface to be implemented in Servlet 3.0&#43; environments in order to configure the ServletContext programmatically – as opposed to (or possibly in conjunction with) the traditional web.xml-based approach. Implementations of this SPI will be detected automatically by SpringServletContainerInitializer, which itself is bootstrapped automatically by any Servlet 3.0 container.
简单来说，就是实现该接口可以在Servlet 3.0&#43;环境中以编程方式配置ServletContext，而不是(或结合)传统的基于web.xml文件配置。
通常的说法是通过实现WebApplicationInitializer接口的onStart方法，可以添加Filter、Servlet等的定义。类似这样：
1 // 注册Filter 2 @Override 3 public void onStartup(ServletContext servletContext) throws ServletException { 4 servletContext.addFilter(&amp;#34;clientCertificateFromProxyFilter&amp;#34;, new DelegatingFilterProxy(&amp;#34;clientCertificateFromProxyFilter&amp;#34;)) 5 .addMappingForUrlPatterns(null, true, &amp;#34;/api/*&amp;#34;); 6 } 但是经过测试发现这种方法在springboot中无效。SpringBootServletInitializer按照官方文档来说，是用于替代WebApplicationInitializer的，应该起到同样的作用。
后来经过查看官方文档，确认这个回调点在嵌入容器的模式下是无效的，被SpringBoot有意关闭了：
Embedded servlet containers do not directly execute the Servlet 3.0&#43; javax.servlet.ServletContainerInitializer interface or Spring’s org.springframework.web.WebApplicationInitializer interface. This is an intentional design decision intended to reduce the risk that third party libraries designed to run inside a war may break Spring Boot applications.
If you need to perform servlet context initialization in a Spring Boot application, you should register a bean that implements the org.springframework.boot.web.servlet.ServletContextInitializer interface. The single onStartup method provides access to the ServletContext and, if necessary, can easily be used as an adapter to an existing WebApplicationInitializer.
关闭的原因是防止第三方库实现这个接口后自动执行破坏打包后的SpringBoot应用的启动。当然这个接口对war包模式还是有效的。但是鉴于我们现在用的是嵌入容器的模式，打包成jar包，所以还必须找其他的方案解决。
2.2 直接声明Bean 实际上Spring boot针对Servlet、Filter类型的Bean进行了特殊处理。会自动进行注册：
To add a Servlet, Filter, or Servlet *Listener by using a Spring bean, you must provide a @Bean definition for it. Doing so can be very useful when you want to inject configuration or dependencies. However, you must be very careful that they do not cause eager initialization of too many other beans, because they have to be installed in the container very early in the application lifecycle. (For example, it is not a good idea to have them depend on your DataSource or JPA configuration.) You can work around such restrictions by initializing the beans lazily when first used instead of on initialization.
In the case of Filters and Servlets, you can also add mappings and init parameters by adding a FilterRegistrationBean or a ServletRegistrationBean instead of or in addition to the underlying component.
简单来说就是通过把Servlet, Filter, 或者Servelt *Listener顶一个成Java Bean，SpringBoot可以加载。当然也可以通过定义FilterRegistrationBean、ServletRegistrationBean来对Filter、Servlet进行一定的初始化。
所以最后的解决方案如下(使用ServletRegistrationBean、FilterRegistrationBean)：
1@Configuration 2public class BeanConfig{ 3 4 @Bean(name=&amp;#34;clientCertificateFromProxyFilter&amp;#34;) 5 public ClientCertificateFromProxyFilter clientCertificateFromProxyFilter() { 6 return new ClientCertificateFromProxyFilter(); 7 } 8 9 @Bean(name=&amp;#34;checkingServlet&amp;#34;) 10 public CheckingServlet checkingServlet() { 11 return new CheckingServlet(); 12 } 13 14 ///////////////////// Servlet //////////////////////// 15 @Bean 16 public ServletRegistrationBean cxfServlet() { 17 final ServletRegistrationBean servletRegistrationBean = new ServletRegistrationBean(new CXFServlet(), &amp;#34;/api/*&amp;#34;); 18 servletRegistrationBean.setLoadOnStartup(1); 19 return servletRegistrationBean; 20 } 21 22 @Bean(name=&amp;#34;checking&amp;#34;) 23 public ServletRegistrationBean checking() { 24 ServletRegistrationBean registration = new ServletRegistrationBean(checkingServlet()); 25 registration.addUrlMappings(&amp;#34;/checking/*&amp;#34;); 26 return registration; 27 } 28 29 ////////////////////// Filter /////////////////////////// 30 @Bean(name=&amp;#34;certProxy&amp;#34;) 31 public FilterRegistrationBean certProxy() { 32 FilterRegistrationBean registration = new FilterRegistrationBean(clientCertificateFromProxyFilter()); 33 registration.addUrlPatterns(&amp;#34;/api/*&amp;#34;); 34 return registration; 35 } 36} 附录、参考资料 How to use Spring&amp;rsquo;s WebApplicationInitializer Spring WebApplicationInitializer and ApplicationContextInitializer confusion SpringBoot初始教程之Servlet、Filter、Listener配置(七) SpringBoot Manual: Convert an Existing Application to Spring Boot </content>
    </entry>
    
     <entry>
        <title>迁移到SpringBoot 02 - 异常处理</title>
        <url>https://orchidflower.github.io/2018/05/15/migrating-to-spring-boot-02-Exception-Handler/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Springboot</tag><tag>AOP</tag>
        </tags>
        <content type="html"> 首先说一下背景信息。云认证平台是一个传统的Spring项目，从上到下可以分为：API层（对应Spring Controller）、Service层、DAO层（MyBatis）几层。为了方便处理，从开发规范上我们要求了Service层的异常在Service层自行处理。
为了实现这一点，在接口定义上，从API层调用Service层的请求会有统一的返回基类：CommonResult。其定义如下：
1public class CommonResult implements Serializable { 2 private static final long serialVersionUID = 1L; 3 4 /** 5 * success 请求成功与否的标志。 6 */ 7 protected boolean success = Boolean.FALSE; 8 /** 9 * resultCode 返回码。 10 */ 11 protected String resultCode = &amp;#34;&amp;#34;; 12 /** 13 * message 详细信息。 14 */ 15 protected String message = &amp;#34;&amp;#34;; 16 ... 17} 所有需要从API层调用到的Service层的返回值都是该类或者该类的子类。如果是Service层之间互相调用，则不受此限制。
本章的内容主要与AOP有关。
1. 传统Spring中的处理 基本的背景介绍完毕。为了在Service层处理异常，实现了一个ServiceExceptionHandler，专门拦截异常，并根据异常类型，设置返回值中的相应字段；然后通过AOP功能将功能织入整个流程。
1.1 ServiceExceptionHandler 1public class ServiceExceptionHandler { 2	private static Logger logger = LoggerFactory.getLogger(ServiceExceptionHandler.class); 3 4	/** 5	* 异常处理。使用aop:around进行拦截，当方法执行过程中出错的时候可以根据异常类型生成返回值。 6	* 7	* @param joinPoint a {@link org.aspectj.lang.ProceedingJoinPoint} object. 8	* @throws java.lang.ClassNotFoundException if any. 9	* @throws java.lang.IllegalAccessException if any. 10	* @throws java.lang.InstantiationException if any. 11	* @return a {@link java.lang.Object} object. 12	*/ 13	public Object processAndCatchException(ProceedingJoinPoint joinPoint) throws InstantiationException, IllegalAccessException, ClassNotFoundException { 14	Object result = null; 15	Signature signature = joinPoint.getSignature(); 16	@SuppressWarnings(&amp;#34;rawtypes&amp;#34;) 17	Class returnType = ((MethodSignature) signature).getReturnType(); 18	try { 19	result = joinPoint.proceed(); 20	} catch (DataAccessException e) { 21	logger.error(&amp;#34;Database exception occured: &amp;#34;, e); 22	result = prepareResult(returnType, ResultCode.DATABASE_ERROR); 23	} 24	catch (Exception e) { 25	logger.error(&amp;#34;Unknow exception occured:&amp;#34;, e); 26	result = prepareResult(returnType, ResultCode.UNKNOW_ERROR); 27	} catch (Throwable e) { 28	logger.error(&amp;#34;Unknown throwable occured:&amp;#34;, e); 29	result = prepareResult(returnType, ResultCode.UNKNOW_ERROR); 30	} 31	return result; 32	} 33	34	/** 35	* 准备返回值 36	* @param returnType 37	* @param errorCode 38	* @return 39	*/ 40	private Object prepareResult(@SuppressWarnings(&amp;#34;rawtypes&amp;#34;) Class returnType, ResultCode errorCode) { 41	Object result = null; 42	try { 43	result = Class.forName(returnType.getName()).newInstance(); 44	if (!(result instanceof CommonResult)) { 45	logger.error(&amp;#34;Return type is not subclass of CommonResult, please contact developer!!!&amp;#34;); 46	return null; 47	} 48	CommonResult ret = (CommonResult)result; 49	ret.setResultCode(errorCode.getCode()); 50	ret.setMessage(errorCode.getDesc()); 51	ret.setSuccess(false); 52	} catch (InstantiationException | IllegalAccessException | ClassNotFoundException e) { 53	logger.error(&amp;#34;prepareResult failed. &amp;#34;, e); 54	} 55	return result; 56	} 57} 1.2 AOP配置 然后通过Spring的AOP配置，将异常处理织入处理过程中：
1	&amp;lt;!-- Service Exception Handler --&amp;gt; 2 &amp;lt;bean id=&amp;#34;serviceExceptionHandlerAspect&amp;#34; class=&amp;#34;com.eveus.cloudauth.service.exception.ServiceExceptionHandler&amp;#34; /&amp;gt; 3 &amp;lt;aop:config&amp;gt; 4 &amp;lt;aop:aspect ref=&amp;#34;serviceExceptionHandlerAspect&amp;#34; order=&amp;#34;1&amp;#34;&amp;gt; 5 &amp;lt;aop:pointcut id=&amp;#34;capServicePointcut&amp;#34; expression=&amp;#34;execution(com.eveus.cloudauth.service.bean..* com.eveus.cloudauth.service.impl.*ServiceImpl..*(..))&amp;#34; /&amp;gt; 6 &amp;lt;aop:around pointcut-ref=&amp;#34;capServicePointcut&amp;#34; method=&amp;#34;processAndCatchException&amp;#34;/&amp;gt; 7 &amp;lt;aop:pointcut id=&amp;#34;uidServicePointCut&amp;#34; expression=&amp;#34;execution(com.eveus.cloudauth.service.bean..* com.eveus.cloudauth.service.impl.uid.*ServiceImpl..*(..))&amp;#34; /&amp;gt; 8 &amp;lt;aop:around pointcut-ref=&amp;#34;uidServicePointCut&amp;#34; method=&amp;#34;processAndCatchException&amp;#34;/&amp;gt; 9 &amp;lt;/aop:aspect&amp;gt; 10 &amp;lt;/aop:config&amp;gt; 2. SpringBoot中的处理 在SpringBoot中推荐的是基于Java的配置，不再推荐采用XML配置。因此需要稍微改写一下配置方法：
2.1 Bean配置 1@Configuration 2public class ServiceConfig { 3 // 生成ServiceExceptionHandler实例 4 @Bean(name=&amp;#34;serviceExceptionHandler&amp;#34;) 5 public ServiceExceptionHandler serviceExceptionHandler() throws Exception { 6 return new ServiceExceptionHandler(); 7 } 8} Bean配置比较简单，在一个@Configuration注解的类中生成返回一个类对象即可。
2.2 AOP配置 AOP相关的配置大部分可以通过注解完成，例如：aop:aspect使用@Aspect替代；aop:pointcut使用@Pointcut代替；aop:around使用@Around代替。这些注解可以直接写入ServiceExceptionHandler类。
经过修改，改写完的ServiceExceptionHandler如下：
1@Aspect 2@Order(1)	// 优先级数字越小优先级越高。优先级越高越先执行。执行堆栈如下：高-低-serviceProcess-低-高。 3public class ServiceExceptionHandler { 4	private static Logger logger = LoggerFactory.getLogger(ServiceExceptionHandler.class); 5 6	// 拦截点定义。只拦截返回值为 ServiceResult 的方法。 7	@Pointcut(&amp;#34;execution(com.eveus.cloudauth.service.bean..* com.eveus.cloudauth.service.impl.*ServiceImpl..*(..))&amp;#34;) 8	public void capServiceProcess() {}; 9 10	@Pointcut(&amp;#34;execution(com.eveus.cloudauth.service.bean..* com.eveus.cloudauth.service.impl.uid.*ServiceImpl..*(..))&amp;#34;) 11	public void uidServiceProcess() {}; 12 13 14	/** 15	* 异常处理。使用aop:around进行拦截，当方法执行过程中出错的时候可以根据异常类型生成返回值。 16	* 17	* @param joinPoint a {@link org.aspectj.lang.ProceedingJoinPoint} object. 18	* @throws java.lang.ClassNotFoundException if any. 19	* @throws java.lang.IllegalAccessException if any. 20	* @throws java.lang.InstantiationException if any. 21	* @return a {@link java.lang.Object} object. 22	*/ 23	@Around(&amp;#34;capServiceProcess() || uidServiceProcess()&amp;#34;) 24	public Object processAndCatchException(ProceedingJoinPoint joinPoint) throws InstantiationException, IllegalAccessException, ClassNotFoundException { 25	Object result = null; 26	Signature signature = joinPoint.getSignature(); 27	@SuppressWarnings(&amp;#34;rawtypes&amp;#34;) 28	Class returnType = ((MethodSignature) signature).getReturnType(); 29	try { 30	result = joinPoint.proceed(); 31	} catch (DataAccessException e) { 32	logger.error(&amp;#34;Database exception occured: &amp;#34;, e); 33	result = prepareResult(returnType, ResultCode.DATABASE_ERROR); 34	} 35	catch (Exception e) { 36	logger.error(&amp;#34;Unknow exception occured:&amp;#34;, e); 37	result = prepareResult(returnType, ResultCode.UNKNOW_ERROR); 38	} catch (Throwable e) { 39	logger.error(&amp;#34;Unknown throwable occured:&amp;#34;, e); 40	result = prepareResult(returnType, ResultCode.UNKNOW_ERROR); 41	} 42	return result; 43	} 44	45	/** 46	* 准备返回值 47	* @param returnType 48	* @param errorCode 49	* @return 50	*/ 51	private Object prepareResult(@SuppressWarnings(&amp;#34;rawtypes&amp;#34;) Class returnType, ResultCode errorCode) { 52	Object result = null; 53	try { 54	result = Class.forName(returnType.getName()).newInstance(); 55	if (!(result instanceof CommonResult)) { 56	logger.error(&amp;#34;Return type is not subclass of CommonResult, please contact developer!!!&amp;#34;); 57	return null; 58	} 59	CommonResult ret = (CommonResult)result; 60	ret.setResultCode(errorCode.getCode()); 61	ret.setMessage(errorCode.getDesc()); 62	ret.setSuccess(false); 63	} catch (InstantiationException | IllegalAccessException | ClassNotFoundException e) { 64	logger.error(&amp;#34;prepareResult failed. &amp;#34;, e); 65	} 66	return result; 67	} 68} 注意一下其中几个注解的使用方法。更多详细的内容可以参考：Spring Framework Core: AOP。
附录、参考资料 Spring Framework Core: AOP </content>
    </entry>
    
     <entry>
        <title>迁移到SpringBoot 01 - 插件加载</title>
        <url>https://orchidflower.github.io/2018/05/09/migrating-to-spring-boot-01-loading-plugin/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Springboot</tag>
        </tags>
        <content type="html"> 首先简单说一下云平台的业务功能：云平台上提供了多种多样的服务，这些服务可能来源于不同的供应商。也就是说对于某一种服务来说，可能会有多个供应商提供相同的服务；而对于某一个供应商来说，它可能提供多种服务。
之前的云平台中有一个插件机制，使用插件机制解决了供应商与系统的耦合度问题。系统抽象了服务层，服务层在合适的时机加载插件以调用供应商的服务。
加载相关的代码大概类似这样：
1... 2ClassLoader localClassLoader = Thread.currentThread().getContextClassLoader(); 3for (String str : providerClassNames) { 4 try { 5 Class&amp;lt;?&amp;gt; localClass = localClassLoader.loadClass(str); 6 XXXServiceProvider localProvider = (XXXServiceProvider) localClass.newInstance(); 7 localProvider.initial();// 初始化插件 8 } catch (Exception e) { 9	... 10 } 11} 12... providerClassNames是一个数组，其中并所有插件的主类名字。通过获取到的ClassLoader，对插件主类进行加载，从而获得插件对象。
但是上面这个加载机制没有解决Spring诸如的问题，使得插件代码中无法通过@Value这种形式注入配置，所以每个插件中必须自行读取配置文件，类似这样：
1private void initProperties() { 2 InputStream inputStream = getClass().getResourceAsStream(&amp;#34;/config.properties&amp;#34;); 3 try { 4 Properties prop = new Properties(); 5 prop.load(inputStream); 6 reqUrl = prop.getProperty(&amp;#34;xxx.reqUrl&amp;#34;).trim(); 7 userId = prop.getProperty(&amp;#34;xxx.userId&amp;#34;).trim(); 8	... 9 } catch (IOException e) { 10 logger.error(&amp;#34;init haoduo auth provider error! &amp;#34;, e); 11 } finally { 12 if (inputStream != null) { 13 try { 14 inputStream.close(); 15 } catch (IOException e) { 16 logger.warn(&amp;#34;close config.properties inputStream error! &amp;#34;, e); 17 } 18 } 19 } 20 } 这种方式用起来还是挺繁琐的，所以很希望改造成能够和普通Spring类一样使用注入方式。
1. 改造方案 要实现上述目标，合理的方案是将插件定义成Spring的Bean。但是考虑到插件的与系统的耦合度问题，所以也不太考虑直接将插件定义成Bean，写在Spring的配置文件中。那剩余的解决方案只能是将插件动态定义成Bean。通过在网上搜索解决方案，找到了两种方案。
1.1 BeanFactoryPostProcessor 最初找到的是BeanFactoryPostProcessor方案：BeanFactoryPostProcessor在BeanFactory创建成功、初始化之后、Bean真正创建之前执行。一般通过该回调函数中修改Bean定义或者定义新的Bean。
理论上讲可以在此节点创建新的Bean定义，例如根据插件列表创建对应的插件Bean。但是问题在于这个节点@Value是无效的（@Value也是由BeanFactory处理的），在这个节点Bean还没有创建，更加不可能注入配置值，因此也就无法从配置文件中拿到插件列表这一配置项信息。
方案失败。在此不做过多描述，具体可以参考网上的资料。
1.2 直接在动态加载的地方注册Bean 最后找到的方案是先动态注册Bean然后加载，代码大概如下：
1AutowireCapableBeanFactory bf = applicationContext.getAutowireCapableBeanFactory(); 2 for (String str : this.providers) { 3 try { 4 // 定义BeanDefinition，根据providers列表动态添加Bean定义 5 String beanName = getSimpleClassName(str); 6 GenericBeanDefinition bd = new GenericBeanDefinition(); 7 bd.setBeanClassName(str); 8 ((DefaultListableBeanFactory)bf).registerBeanDefinition(beanName, bd); 9 // 使用applicationContext加载刚刚定义的Bean，此时应该完成了@Autowired的注入工作 10 XXXServiceProvider localProvider = (XXXServiceProvider) applicationContext.getBean(beanName); 11 localProvider.initial();// 初始化插件 12 logger.info(&amp;#34;XXXServiceProvider {} is added to list.&amp;#34;, localProvider.getProviderName()); 13 } catch (Exception e) { 14	... 15 } 16 } 上面的代码使用applicationContext获取的autowireCapableBeanFactory，先创建Bean定义（registerBeanDefinition），然后获取该Bean（applicationContext.getBean）。这样处理之后，除了Bean定义是动态创建的意外，就和一个普通的Spring Bean表现一致了。
该方案工作正常。
附录A、参考资料 Spring - Dynamically register beans </content>
    </entry>
    
     <entry>
        <title>迁移到SpringBoot 00 - 背景介绍</title>
        <url>https://orchidflower.github.io/2018/05/08/migrating-to-spring-boot-00-background/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Springboot</tag>
        </tags>
        <content type="html"> 最近因为发布方面的原因，需要对项目进行一次改造，趁着这次机会，对云平台项目进行了彻底的重构，迁移到了Spring Boot上。改造过程中，从传统的Spring项目迁移到Spring Boot上，还是碰到了一些问题的，也因此留下了这个系列的笔记。其中的内容，应该对希望把传统的Spring项目迁移到Spring Boot的人会有所帮助。
在改造过程中碰到了很多问题。诸如：数据源（多数据源）、事务、Swagger、Redis、日志、CXF、Kafka等等。这将在后面的系列中分别介绍。
限于时间，有些方面可能介绍得不是非常充分。但是希望自己能够尽量的把问题、解决方案描述清楚，也算是以后的一个参考吧。
附录中是部分参考资料，后面每篇文章会有对应专题的参考资料，仅供参考。
附录. 参考资料 How to Configure Two DataSources Laziness at extreme: developing JAX-RS services with Spring Boot Spring Boot CXF JAX-WS Starter Spring Integration A Quick Guide to Spring @Value Spring Security的使用 Spring security Java Configuration Spring Boot如何使用Spring Security进行安全控制 </content>
    </entry>
    
     <entry>
        <title>Apache HttpClient 使用（上）</title>
        <url>https://orchidflower.github.io/2018/04/23/Apache-HttpClient-Manual/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Java</tag><tag>HttpClient</tag>
        </tags>
        <content type="html"> HttpClient是Apache Jakarta Common下的子项目，用来提供高效的、最新的、功能丰富的支持HTTP协议的客户端编程工具包，并且它支持HTTP协议最新的版本和建议。HttpClient已经应用在很多的项目中，比如Apache Jakarta上很著名的另外两个开源项目Cactus和HTMLUnit都使用了HttpClient。
目前最新的版本是4.5，支持HTTP 1.0/HTTP 1.1协议。正在开发中的5.0版本（还在Beta阶段）支持HTTP/2协议。
1. 特性 基于标准、纯净的java语言。实现了Http1.0和Http1.1 以可扩展的面向对象的结构实现了Http全部的方法（GET, POST, PUT, DELETE, HEAD, OPTIONS, and TRACE）。 支持HTTPS协议。 通过Http代理建立透明的连接。 利用CONNECT方法通过Http代理建立隧道的https连接。 Basic, Digest, NTLMv1, NTLMv2, NTLM2 Session, SNPNEGO/Kerberos认证方案。 插件式的自定义认证方案。 便携可靠的套接字工厂使它更容易的使用第三方解决方案。 连接管理器支持多线程应用。支持设置最大连接数，同时支持设置每个主机的最大连接数，发现并关闭过期的连接。 自动处理Set-Cookie中的Cookie。 插件式的自定义Cookie策略。 Request的输出流可以避免流中内容直接缓冲到socket服务器。 Response的输入流可以有效的从socket服务器直接读取相应内容。 在http1.0和http1.1中利用KeepAlive保持持久连接。 直接获取服务器发送的response code和 headers。 设置连接超时的能力。 实验性的支持http1.1 response caching。 源代码基于Apache License 可免费获取。 2. 使用方法 下面以一个简单的例子来说明一下HttpClient的使用方法。
2.1 pom 1 &amp;lt;dependency&amp;gt; 2 &amp;lt;groupId&amp;gt;org.apache.httpcomponents&amp;lt;/groupId&amp;gt; 3 &amp;lt;artifactId&amp;gt;httpclient&amp;lt;/artifactId&amp;gt; 4 &amp;lt;version&amp;gt;4.5.4&amp;lt;/version&amp;gt; 5 &amp;lt;/dependency&amp;gt; 首先引入相关的Maven库。
2.2 代码 1String url = &amp;#34;http://www.baidu.com&amp;#34;; 2// 1. 使用默认的配置的httpclient 3CloseableHttpClient client = HttpClients.createDefault(); 4// 2. 使用GET方法 5HttpGet httpGet = new HttpGet(url); 6InputStream inputStream = null; 7CloseableHttpResponse response = null; 8try { 9 //3.执行请求，获取响应 10 response = client.execute(httpGet); 11 //看请求是否成功，这儿打印的是http状态码 12 System.out.println(response.getStatusLine().getStatusCode()); 13 14 //4.获取响应的实体内容，就是我们所要抓取得网页内容 15 HttpEntity entity = response.getEntity(); 16 17 //5.将其打印到控制台上面 18 //方法一：使用EntityUtils 19 if (entity != null) { 20 System.out.println(EntityUtils.toString(entity, &amp;#34;utf-8&amp;#34;)); 21 } 22 EntityUtils.consume(entity); 23 24 //方法二：使用inputStream（不能同时使用） 25 if (entity != null) { 26 inputStream = entity.getContent(); 27 28 BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream)); 29 String line = &amp;#34;&amp;#34;; 30 while ((line = bufferedReader.readLine()) != null) { 31 System.out.println(line); 32 33 } 34 } 35 36} catch (ClientProtocolException e) { 37 e.printStackTrace(); 38} catch (IOException e) { 39 e.printStackTrace(); 40} finally { 41 if (inputStream != null) { 42 try { 43 inputStream.close(); 44 } catch (IOException e) { 45 e.printStackTrace(); 46 } 47 } 48 if (response != null) { 49 try { 50 response.close(); 51 } catch (IOException e) { 52 e.printStackTrace(); 53 } 54 } 55} 这段代码的用途是使用GET方法获取百度首页，并打印出来。
2.3 代码分析 使用HttpClient发送请求、接收响应很简单，一般需要如下几步即可。
创建HttpClient对象。 例子中使用的是org.apache.http.impl.client.CloseableHtttpClient，它是HttpClient接口的一个实例，创建该对象的最简单方法是：CloseableHttpClient client = HttpClients.createDefault();。 HttpClients是创建CloseableHttpClient的工厂，采用默认的配置来创建实例，一般情况下我们就用这个默认实例就可以了。以后我们会讨论如何自定义这个对象。
创建请求方法的实例，并指定请求URL。如果需要发送GET请求，创建HttpGet对象；如果需要发送POST请求，创建HttpPost对象。 其他的类型还有：HttpHead, HttpPut, HttpDelete, HttpTrace, HttpOptions等。分别对应不同的Http请求方法：
方法 描述 是否包含主体 GET 从服务器获取一份文档 否 HEAD 只从服务器获取文档的首部 否 POST 向服务器发送需要处理的数据 是 PUT 将请求的主体部分存储在服务器上 是 TRACE 对可能经过代理服务器传送到服务器上去的报文进行追踪 否 OPTIONS 决定可以在服务器上执行哪些方法 否 DELETE 从服务器上删除一份文档 否 如果需要发送请求参数，可调用HttpGet、HttpPost共同的setParams(HetpParams params)方法来添加请求参数；对于HttpPost对象而言，也可调用setEntity(HttpEntity entity)方法来设置请求参数。
调用HttpClient对象的execute(HttpUriRequest request)发送请求，该方法返回一个CloseableHttpResponse。
调用HttpResponse的getAllHeaders()、getHeaders(String name)等方法可获取服务器的响应头；调用HttpResponse getEntity()方法可获取HttpEntity对象，该对象包装了服务器的响应内容。对getEntity获取的结果，有两种处理方法： 方法一：使用EntityUtils工具类来处理。该类是官方提供的一个处理实体的工具类，toSting方法将返回的实体转换为字符串，但是官网不建议使用这个，除非响应实体从一个可信HTTP服务器发起和已知是有限长度的。 方法二：使用InputStream来读取。因为httpEntity.getContent方法返回的就是InputStream类型。这种方法是官网推荐的方式，需要记得要自己释放底层资源。
释放连接。无论执行方法是否成功，都必须释放连接 如果使用EntityUtils来处理返回值，则可以使用EntityUtils.consume(entity)来释放资源。
如果使用InputStream来处理返回值，则要关闭inputStream然后关闭response对象就行了。
1if (inputStream != null) { 2 try { 3 inputStream.close(); 4 } catch (IOException e) { 5 e.printStackTrace(); 6 } 7} 8if (response != null) { 9 try { 10 response.close(); 11 } catch (IOException e) { 12 e.printStackTrace(); 13 } 14} 2.4 关于资源释放 使用EntityUtils#consume这个方法会自动关闭底层的inputStream。如果不需要读取全部的实体，则可以直接关闭response，来种植对inputStream的读取。注意：关闭response会自动关闭对应的inputStream。
1CloseableHttpClient httpclient = HttpClients.createDefault(); 2HttpGet httpget = new HttpGet(&amp;#34;http://localhost/&amp;#34;); 3CloseableHttpResponse response = httpclient.execute(httpget); 4try { 5 HttpEntity entity = response.getEntity(); 6 if (entity != null) { 7 InputStream instream = entity.getContent(); 8 int byteOne = instream.read(); 9 int byteTwo = instream.read(); 10 // Do not need the rest 11 } 12} finally { 13 response.close(); // 直接关闭response 14} 不推荐使用EntityUtils#toString方法，如果确实需要，最好先自己判断长度：entity.getContentLength()。这是因为toString方法默认最大的长度是Integer.MAX_VALUE（0x7fffffff）。这个长度太大了，很容易导致缓冲区溢出。
如果希望重复使用Entity，可以使用：new BufferedHttpEntity(entity)创建一个新对象缓存起来。
2.5 Entity 用于生成请求的Entity的类主要有四种：StringEntity, ByteArrayEntity, InputStreamEntity和FileEntity。 例子：FileEntity：
1File file = new File(&amp;#34;somefile.txt&amp;#34;); 2FileEntity entity = new FileEntity(file, 3 ContentType.create(&amp;#34;text/plain&amp;#34;, &amp;#34;UTF-8&amp;#34;)); 4HttpPost httppost = new HttpPost(&amp;#34;http://localhost/action.do&amp;#34;); 5httppost.setEntity(entity); 例子：
1List&amp;lt;NameValuePair&amp;gt; formparams = new ArrayList&amp;lt;NameValuePair&amp;gt;(); 2formparams.add(new BasicNameValuePair(&amp;#34;param1&amp;#34;, &amp;#34;value1&amp;#34;)); 3formparams.add(new BasicNameValuePair(&amp;#34;param2&amp;#34;, &amp;#34;value2&amp;#34;)); 4UrlEncodedFormEntity entity = new UrlEncodedFormEntity(formparams, Consts.UTF_8); 5HttpPost httppost = new HttpPost(&amp;#34;http://localhost/handler.do&amp;#34;); 6httppost.setEntity(entity); 3. 实例代码 3.1 普通GET请求 1// 创建Httpclient对象 2CloseableHttpClient httpclient = HttpClients.createDefault(); 3// 创建http GET请求 4HttpGet httpGet = new HttpGet(&amp;#34;http://www.baidu.com/s?wd=java&amp;#34;); 5CloseableHttpResponse response = null; 6try { 7 // 执行请求 8 response = httpclient.execute(httpGet); 9 // 判断返回状态是否为200 10 if (response.getStatusLine().getStatusCode() == 200) { 11 ... 12 } 13} 3.2 带有参数的Get请求 1// 定义请求的参数 2URI uri = new URIBuilder(&amp;#34;http://www.baidu.com/s&amp;#34;).setParameter(&amp;#34;wd&amp;#34;, &amp;#34;java&amp;#34;).build(); 3// 创建http GET请求 4HttpGet httpGet = new HttpGet(uri); 3.3 普通的POST请求 1// 创建http POST请求 2HttpPost httpPost = new HttpPost(&amp;#34;http://www.oschina.net/&amp;#34;); 3 // 伪装浏览器请求 4httpPost.setHeader(&amp;#34;User-Agent&amp;#34;, 5 &amp;#34;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.118 Safari/537.36&amp;#34;); 6// 执行请求 7response = httpclient.execute(httpPost); 3.4 带有参数的Post请求 1// 创建http POST请求 2HttpPost httpPost = new HttpPost(&amp;#34;http://www.oschina.net/search&amp;#34;); 3 4// 设置2个post参数，一个是scope、一个是q 5List&amp;lt;NameValuePair&amp;gt; parameters = new ArrayList&amp;lt;NameValuePair&amp;gt;(); 6parameters.add(new BasicNameValuePair(&amp;#34;scope&amp;#34;, &amp;#34;project&amp;#34;)); 7parameters.add(new BasicNameValuePair(&amp;#34;q&amp;#34;, &amp;#34;java&amp;#34;)); 8// 构造一个form表单式的实体 9UrlEncodedFormEntity formEntity = new UrlEncodedFormEntity(parameters); 10// 将请求实体设置到httpPost对象中 11httpPost.setEntity(formEntity); 12// 伪装浏览器请求 13httpPost.setHeader( 14 &amp;#34;User-Agent&amp;#34;, 15 &amp;#34;Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.118 Safari/537.36&amp;#34;); 16 17// 执行请求 18response = httpclient.execute(httpPost); 3.5 配置超时时间等 1// 创建http GET请求 2HttpGet httpGet = new HttpGet(&amp;#34;http://www.baidu.com/&amp;#34;); 3 4// 构建请求配置信息 5RequestConfig config = RequestConfig.custom() 6 .setConnectTimeout(1000) // 创建连接的最长时间 7 .setConnectionRequestTimeout(500) // 从连接池中获取到连接的最长时间 8 .setSocketTimeout(10 * 1000) // 数据传输的最长时间 9 .setStaleConnectionCheckEnabled(true) // 提交请求前测试连接是否可用 10 .build(); 11// 设置请求配置信息 12httpGet.setConfig(config); 几个函数的含义：
setConnectionRequestTimeout 从链接池获取一个连接的最长等待时间； setConnectTimeout 创建链接的最长等待时间； setSocketTimeout 获取数据的最长等待时间； setStaleConnectionCheckEnabled 检查链接状态是否可用。这个选项会花费最长30ms时间已确定一个连接是否可用。对性能要求高的应用不要开启这个选项。 </content>
    </entry>
    
     <entry>
        <title>Apache HttpClient 使用（下）</title>
        <url>https://orchidflower.github.io/2018/04/23/Apache-HttpClient-Manual-Part2/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Java</tag><tag>HttpClient</tag>
        </tags>
        <content type="html"> 4. 链接池 通常我们可以使用PoolingHttpClientConnectionManager来创建一个链接池。
4.1 对于链接池的管理 1PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager(); 2// 设置最大连接数 3cm.setMaxTotal(200); 4// 设置每个主机地址的并发数 5cm.setDefaultMaxPerRoute(20); 6// 通过PoolingHttpClientConnectionManager，来获取CloseableHttpClient 7CloseableHttpClient httpClient = HttpClients.custom().setConnectionManager(cm).build(); 8 9// 创建http GET请求 10HttpGet httpGet = new HttpGet(&amp;#34;http://www.baidu.com/&amp;#34;); 11// 执行请求 12response = httpClient.execute(httpGet); 4.2 关闭链接池中失效的链接 1import org.apache.http.conn.HttpClientConnectionManager; 2import org.apache.http.impl.conn.PoolingHttpClientConnectionManager; 3 4//关闭连接池的无效链接 5public class ClientEvictExpiredConnections { 6 7 public static void main(String[] args) throws Exception { 8 PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager(); 9 // 设置最大连接数 10 cm.setMaxTotal(200); 11 // 设置每个主机地址的并发数 12 cm.setDefaultMaxPerRoute(20); 13 // 开启线程用于关闭失效的链接 14 new IdleConnectionEvictor(cm).start(); 15 } 16 17 public static class IdleConnectionEvictor extends Thread { 18 private final HttpClientConnectionManager connMgr; 19 private volatile boolean shutdown; 20 21 public IdleConnectionEvictor(HttpClientConnectionManager connMgr) { 22 this.connMgr = connMgr; 23 } 24 25 @Override 26 public void run() { 27 try { 28 while (!shutdown) { 29 synchronized (this) { 30 wait(5000); // 每隔5秒执行一个，关闭失效的http连接 31 connMgr.closeExpiredConnections(); // 关闭失效链接 32 connMgr.closeIdleConnections(30, TimeUnit.SECONDS); // 关闭空闲链接 33 } 34 } 35 } catch (InterruptedException ex) { 36 // 结束 37 shutdown(); 38 } 39 } 40 41 public void shutdown() { 42 shutdown = true; 43 synchronized (this) { 44 notifyAll(); 45 } 46 } 47 } 48} 4.4 关闭 一个连接可以优雅的关闭：清空发送缓冲区然后再进行关闭。也可以强制关闭，通过调用shutdown方法，此时发送缓冲区不会被清空。 要关闭一个机遇Pooling的HttpClient，按照下面的步骤：
消费并关闭返回的response对象 关闭HttpClient 关闭Connection Manager 例如：
1connManager = new PoolingHttpClientConnectionManager(); 2CloseableHttpClient client = HttpClients.custom().setConnectionManager(connManager).build(); 3HttpGet get = new HttpGet(&amp;#34;http://google.com&amp;#34;); 4CloseableHttpResponse response = client.execute(get); 5 6EntityUtils.consume(response.getEntity()); 7response.close(); 8client.close(); 9connManager.close(); // 关闭链接池 如果直接关闭connManager，那所有相关的链接都会被关闭，资源也会被释放，但是发送缓冲区不会被清空（flush）。
5. 访问双向SSL保护的资源 1	public static HttpClientConnectionManager CONNECTION_MANAGER = null; 2	3	public void init(String keyStoreFile, String keyStorePass, 4	String trustStoreFile, String trustStorePass) throws Exception { 5	System.out.println(&amp;#34;init conection pool...&amp;#34;); 6 7	InputStream ksis = new FileInputStream(new File(keyStoreFile)); 8	InputStream tsis = new FileInputStream(new File(trustStoreFile)); 9 10	KeyStore ks = KeyStore.getInstance(&amp;#34;PKCS12&amp;#34;); 11	ks.load(ksis, keyStorePass.toCharArray()); 12 13	KeyStore ts = KeyStore.getInstance(&amp;#34;JKS&amp;#34;); 14	ts.load(tsis, trustStorePass.toCharArray()); 15 16 // init SSLContext with keystore, truststore 17	SSLContext sslContext = SSLContexts.custom() 18	.loadKeyMaterial(ks, keyStorePass.toCharArray()) 19	.loadTrustMaterial(ts, new TrustSelfSignedStrategy()).build(); 20 21	// init SSLConnectionSocketFactory 22	SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory(sslContext, 23 new String[] { &amp;#34;TLSv1&amp;#34; }, 24 null, 25 NoopHostnameVerifier.INSTANCE); // not check common name 26 27	Registry&amp;lt;ConnectionSocketFactory&amp;gt; registry = RegistryBuilder 28	.&amp;lt;ConnectionSocketFactory&amp;gt; create() 29	.register(&amp;#34;http&amp;#34;, PlainConnectionSocketFactory.INSTANCE) 30	.register(&amp;#34;https&amp;#34;, sslsf).build(); 31	ksis.close(); 32	tsis.close(); 33	CONNECTION_MANAGER = new PoolingHttpClientConnectionManager(registry); 34	} 35	36	public String doPost(String url, String params) throws Exception { 37	if (CONNECTION_MANAGER == null) { 38	return null; 39	} 40	CloseableHttpClient httpClient = HttpClients.custom() 41	.setConnectionManager(CONNECTION_MANAGER).build(); 42	HttpPost httpPost = new HttpPost(url); 43 44	httpPost.setEntity(new StringEntity(params, 45	ContentType.APPLICATION_JSON)); 46 47	CloseableHttpResponse resp = httpClient.execute(httpPost); 48	System.out.println(resp.getStatusLine()); 49	InputStream respIs = resp.getEntity().getContent(); 50	String content = convertStreamToString(respIs); 51	EntityUtils.consume(resp.getEntity()); 52	return content; 53	}	54	55	// Get data from InputStream 56	public static String convertStreamToString(InputStream is) { 57	BufferedReader reader = new BufferedReader(new InputStreamReader(is)); 58	StringBuilder sb = new StringBuilder(); 59 60	String line = null; 61	try { 62	while ((line = reader.readLine()) != null) { 63	sb.append(line &#43; &amp;#34;\n&amp;#34;); 64	} 65	} catch (IOException e) { 66	e.printStackTrace(); 67	} finally { 68	try { 69	is.close(); 70	} catch (IOException e) { 71	e.printStackTrace(); 72	} 73	} 74	return sb.toString(); 75	}	上面的代码首先创建了一个PoolingHttpClientConnectionManager，然后定义了sendPost方法，可以用来发送Post请求。
附录、参考资料 Apache HttpClient Overview HttpClient Tutorial HttpClient Connection Management HttpClient4.3.x使用-基础篇 </content>
    </entry>
    
     <entry>
        <title>Spring应用因Session Timeout设置引起的GC问题</title>
        <url>https://orchidflower.github.io/2017/08/29/Spring-Session-Timeout-caused-GC-failure/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Java</tag><tag>Spring</tag>
        </tags>
        <content type="html"> 最近在客户的要求下，对系统进行了压测。自己压测的时候一切指标都挺正常。但是客户却反馈说压测的时候有时候会碰到性能衰减很厉害，不稳定。于是有了下面这次的排查过程。客户反馈说问题是发生在多次连续压测之后碰到的，所以进行了一系列的测试。
先说一下测试环境的一些信息：测试主机是阿里云的ECS，配置是2C &#43; 16G。为了方便，数据库采用的是Docker搭建的，版本是5.6.X。另外，这台机器上还安装了Zookeeper 3.4.X 和Kafka 1.0。系统本身是一个标准的Spring &#43; CXF的应用，提供给客户使用的服务是标准的Restful接口。
1. 重现问题 因为客户反馈是多次压测之后碰到的，因此首先尝试连续压测多次看看能不能重现问题。为了可能存在的数据库性能问题，临时申请了RDS作为数据库；另外为了尽快发现问题，将程序占用内存缩小到1G。这次测试测出了客户所说的问题，通过jconsole监控也发现了问题原因，应该是因为GC导致的。
看图表可以发现，压测5~6分钟之后，Java的GC占用了大量的CPU时间（左上图中的蓝色线），而且内存占用一直居高不下（右上图）。
2. 调整内存使用量 把内存占用调整到2G，发现问题还是同样存在，只是出现问题的时间晚了，压测开始15分钟之后才会出现问题。也就是说问题是同样存在的，只是内存大了之后，把出现问题的时间拖后了而已。
3. 问题根源 通过上面的测试发现了问题是GC导致的，也就是系统中有些内存无法给GC回收，当内存达到Java虚拟机可以申请的上限的时候，会出现频繁的GC操作，从而导致GC操作占用大量CPU时间，必然导致系统本身的TPS下降。
通过分析dump文件，以及上网搜索，最终确认问题可能出现在Session超时时间设置上： 在Java Web开发中，Session为我们提供了很多方便，Session是由浏览器和服务器之间维护的。Session超时理解为：浏览器和服务器之间创建了一个Session，由于客户端长时间（休眠时间）没有与服务器交互，服务器将此Session销毁，客户端再一次与服务器交互时之前的Session就不存在了。
这个Session长短是可以设置的。默认情况下，什么也不设置的话Session超时时间是30分钟。设置方法是修改项目中的web.xml，如下面的配置是设置session时间为1分钟：
1 &amp;lt;session-config&amp;gt; 2 &amp;lt;session-timeout&amp;gt;1&amp;lt;/session-timeout&amp;gt; 3 &amp;lt;/session-config&amp;gt; 之前项目中都没有对session时间进行设置，因此会有大量的session信息被缓存，不到时间是无法GC的。而项目本身的服务是不依赖于session的，完全可以将session时间设置的更短一些。
4. 调整session时间为1分钟 这一轮测试基本信息如下：
数据库使用RDS 内存占用使用2G Session设置为1分钟 压测结果如下： 这次总共压测了30分钟，GC占用的CPU时间也非常少，内存也表现良好，可以正常GC回收。
性能表现一直稳定。
5. 数据库切换回Docker 上一轮测试结果给了很大的信心，因此决定把数据库切换为本机的Docker中的MySQL，其他的不变：
GC表现正常，内存也回收良好。
TPS降低了不少，之前是1700&#43;，这次只有1250&#43;了。这个一方面是所有服务运行在一台主机上带来的性能损耗，另一方面应该是Docker本身带来了一些损耗。
6. 调整为1G内存 再把内存调整为1G，再测试一次。
GC占用时间略有上升，但是总体还是很稳定。
7. 结论 如果你的系统本身不依赖于Web的Session机制，请把Session时间调小一些，这样在高负载的情况下，GC才能够正常工作。
附录A. 参考资料 How to enable session and set session timeout in Spring Security Session的有效期设置 Possible Spring Boot or Spring Security Memory Leak server.sessionTimeout default #2084 </content>
    </entry>
    
     <entry>
        <title>使用Docker运行Jenkins（二）</title>
        <url>https://orchidflower.github.io/2017/08/20/Use-Webhook-between-Gogs-and-Jenkins/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>Jenkins</tag><tag>Gogs</tag><tag>Gitea</tag>
        </tags>
        <content type="html"> Gitea 是一款极易搭建的自助 Git 服务，最初是fork子Gogs项目（Gogs 的目标是打造一个最简单、最快速和最轻松的方式搭建自助 Git 服务）。Gitea使用 Go 语言开发。使用 Go 语言开发使得 Gitea 能够通过独立的二进制分发，并且支持 Go 语言支持的 所有平台，包括 Linux、Mac OS X、Windows 以及 ARM 平台。
Gitea占用资源小，比起Gitlab这种庞然大物来说简直是精致得要命。但是作为小团队的项目管理用来替代Gitlab还是基本能够满足需求的。而且Gitea（包括Gogs）社区还是挺活跃的，新功能也在逐渐增加中，个人很看好它的前景。
1. 怎么运行Gitea 1.1 使用Docker运行mysql 1version: &amp;#39;2&amp;#39; 2services: 3 mysql: 4 image: mysql:5.7.18 5 volumes: 6 - /opt/docker/gitbox/db:/var/lib/mysql 7 - /opt/docker/gitbox/config:/etc/mysql/conf.d 8 environment: 9 - TZ=Asia/Shanghai 10 - MYSQL_ROOT_PASSWORD=password 11 command: --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci 12 ports: 13 - 3307:3306 14 hostname: mysql 15 restart: unless-stopped Gitea支持MySQL、PostgreSQL或SQlite，上面是以MySQL为例。也可以安装其他数据库。
1.2 创建数据库 使用上面创建的root用户登录mysql，创建数据库：
1DROP DATABASE IF EXISTS gogs; 2CREATE DATABASE IF NOT EXISTS gogs CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci; 1.3 安装Gitea 1version: &amp;#39;2&amp;#39; 2services: 3 gogs: 4 image: gitea/gitea:1.4.0-rc2 5 volumes: 6 - /etc/localtime:/etc/localtime 7 - /opt/docker/gogs/data:/data 8 - /opt/docker/gogs/logs:/app/gogs/log 9 ports: 10 - &amp;#34;10080:3000&amp;#34; 11 - &amp;#34;10022:22&amp;#34; 12 hostname: gogs 通过volume配置，可以将log以及repository等数据保存到宿主机上。
1.4 配置 使用浏览器访问，会自动跳入设置界面。配置好数据库，做好必要的配置Gogs就安装好了。
2. Webhook的使用 到现在为止，我还不会使用Jenkins中的Gitea plugin，所以最终还是使用了Gogs的plugin。
2.1 Jenkins中安装插件 Gogs plugin。安装这个插件之后就可以使用Gogs类型的Webhook了。
2.2 项目配置 在Jenkins中针对要启用Webhook的项目选择&amp;quot;Use Gogs Secret&amp;quot;，设置一个Secret。这个Secret将保证通讯中的数据安全。
2.3 Gitea中配置 在Gitea中仓库设置 -&amp;gt; 管理Web钩子，选择添加一个Gogs类型的Webhook，其他参数如下：
推送地址为：{jenkins-server-address}/gogs-webhook/?job={job name} 数据格式为：application/json 密钥文本设置为上面的Secret。 希望触发Web钩子的事件：只推送即可。 经过以上配置之后，当推送了最新代码的时候，会自动触发Jenkins中的构建事件，对代码进行打包测试。
</content>
    </entry>
    
     <entry>
        <title>使用Docker运行Jenkins服务（一）</title>
        <url>https://orchidflower.github.io/2017/08/13/How-to-setup-Jenkins-in-Docker/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Jenkins</tag><tag>Docker</tag>
        </tags>
        <content type="html"> 1. Jenkins是什么？ 某百科的解释是：
Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具，用于监控持续重复的工作，旨在提供一个开放易用的软件平台，使软件的持续集成变成可能。
这个解释大体上是靠谱的，Jenkins的核心作用就是一个CI（持续集成）工具。CI的概念是：持续集成指的是，频繁地（一天多次）将代码集成到主干。持续集成的目的，就是让产品可以快速迭代，同时还能保持高质量。它的核心措施是，代码集成到主干之前，必须通过自动化测试。只要有一个测试用例失败，就不能集成。而Jenkins能够完成这些自动化构建、测试的大部分工作。
Jenkins的前身是Hudson。这其中的渊源涉及到Oracle收购Java引起的版权纷争。有兴趣的可以看附录里面的相关链接。
2. 为什么用Docker 为什么用Docker运行Jenkins？个人感觉Docker通过镜像封装，可以屏蔽大量的搭建运维环境的琐碎操作。运维人员可以将Jenkins看成一个独立软件，而不需要关心其中的细节，例如Java运行环境怎么配置、Jenkins目录放在哪儿等等问题。使用Docker可以简单的配置几个运行参数，就可以迅速的启用Jenkins，大大降低了搭建的难度。
3. 搭建目标 根据目前项目的需求，搭建这个Jenkins环境需要能够支持几个功能：
能够进行Docker镜像构建，运行； 能够支持Nodejs类型项目； 能够支持Java Maven类型项目； 4. 搭建步骤 根据上面的需求，直接先上最后的docker-compose脚本，后面会逐步解读：
1version: &amp;#39;2&amp;#39; 2services: 3 jenkins: 4 image: jenkins/jenkins:2.60.3 5 volumes: 6 # let container use same timezone as host 7 - /etc/localtime:/etc/localtime 8 - /etc/timezone:/etc/timezone 9 # jenkins home 10 - /opt/docker/jenkins/jenkins.home:/var/jenkins_home 11 # JDK used for compiling Java project 12 - /usr/local/jdk1.8.0:/usr/local/jdk1.8.0 13 # Maven used for compiling maven project 14 - /usr/local/maven:/usr/local/maven 15 # node.js 6 16 - /usr/local/nodejs6:/usr/local/nodejs6 17 # node.js 8 18 - /usr/local/nodejs8:/usr/local/nodejs8 19 20 # Maven cache directory 21 - /home/sinopoweradmin/.m2:/var/jenkins_home/.m2 22 # Map docker cmd on host to container. used for docker image building 23 #- /var/run/docker.sock:/var/run/docker.sock 24 - /usr/bin/docker:/usr/bin/docker 25 - /usr/lib/x86_64-linux-gnu/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7 26 # Map ssh config into docker 27 - /home/sinopoweradmin/.ssh:/var/jenkins_home/.ssh 28 ports: 29 # main port 30 - &amp;#34;8080:8080&amp;#34; 31 # used for cluster mode 32 - &amp;#34;50000:50000&amp;#34; 33 restart: always 4.1 Docker容器的时区 默认的Docker镜像中时区设置多数是UTC，与我们本地的时间（UTC&#43;8)不一致。这会导致在Jenkins中显示的时间与本地时间有8小时的时差。为了解决这个问题，可以通过将本地时区文件映射到容器中解决：
1 - /etc/localtime:/etc/localtime 2 - /etc/timezone:/etc/timezone 4.2 JDK 8 Jenkins镜像中有JDK（用来运行Jenkins本身）。但是这个版本的JDK是OpenJDK 1.8。而我一般使用的是Oracle的JDK1.8。因此选择了在本地安装JDK1.8，然后挂载到镜像中去。
1# JDK used for compiling Java project 2 - /usr/local/jdk1.8.0:/usr/local/jdk1.8.0 4.3 Maven 在Jenkins中可以直接安装Maven。但是因为GFW的原因，安装会比较慢，而且有可能失败。所以我选择和Java一样的方式在本地安装然后挂载到容器中。
1 # Maven used for compiling maven project 2 - /usr/local/maven:/usr/local/maven 4.4 Nodejs Node.js的安装方法类似：
1 # node.js 6 2 - /usr/local/nodejs6:/usr/local/nodejs6 3 # node.js 8 4 - /usr/local/nodejs8:/usr/local/nodejs8 这里挂载了两个版本的Node.js。
4.5 Jenkins Home和Maven Cache 通过挂载本地目录，将Jenkins Home和Maven Cache都映射到宿主机上，而不是让Jenkins在容器内部管理。这样就可以保证升级版本不会丢失数据了。
1 # jenkins home 2 - /opt/docker/jenkins/jenkins.home:/var/jenkins_home 3 # Maven cache directory 4 - /home/sinopoweradmin/.m2:/var/jenkins_home/.m2 4.6 Docker 要在Jenkins内部使用Docker构建镜像、运行docker命令，就需要将宿主机的docker命令映射到容器中。所幸docker是一个C/S架构的软件，docker命令本身并不实际执行工作，只是负责将命令发送到Docker的服务程序中执行。因此我们只需要将docker命令本身映射到容器中即可。然后通过添加-H参数指定宿主机作为Docker服务主机即可执行docker相关任务。具体的以后会讲解。
1 # Map docker cmd on host to container. used for docker image building 2 #- /var/run/docker.sock:/var/run/docker.sock 3 - /usr/bin/docker:/usr/bin/docker 4 - /usr/lib/x86_64-linux-gnu/libltdl.so.7:/usr/lib/x86_64-linux-gnu/libltdl.so.7 4.7 ssh 1 # Map ssh config into docker 2 - /home/sinopoweradmin/.ssh:/var/jenkins_home/.ssh 这一段关于ssh的配置是将运行docker用户主目录中的.ssh目录映射到Jenkins容器中。这样做的好处是两者共享了同样的ssh密钥以及known_hosts信息：只要能够在宿主机上通过SSH证书登录的主机也就可以在Jenkins容器中登录。（有关SSH证书无密码登录的内容请参考以前的文章）。
5. 运行 使用docker-compose运行就可以启动Jenkins了。
5.1 初始化密码 Jenkins第一次运行的时候会自动生成初始化密码。通过docker logs -f jenkins_jenkins_1查看日志可以找到这个密码。或者进入JENKINS_HOME中找到相关文件也可以找到这个密码。
6. 一些说明 Jenkins镜像推荐不要选用Alpine版本的镜像，有时候会出现一些兼容性问题。例如出现docker命令无法执行的问题。 关于如何在Jenkins中创建、执行Job以后会继续写博文说明。 附录A. 附录 持续集成，选Jenkins还是Hudson (Jenkins与Hudson的渊源) </content>
    </entry>
    
     <entry>
        <title>Shell脚本中的一些特殊变量</title>
        <url>https://orchidflower.github.io/2017/08/05/Some-special-parameters-in-Shell/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Linux</tag><tag>Shell</tag><tag>Bash</tag>
        </tags>
        <content type="html"> Shell脚本的一些参数总是感觉记不住，特此记录一下，以备后查。
1. 参数说明 参数 说明 $0 当前脚本的文件名 &amp;mdash; &amp;mdash; $n 传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。 $# 传递给脚本或函数的参数个数。 $* 传递给脚本或函数的所有参数。 $@ 传递给脚本或函数的所有参数。被双引号(&amp;quot; &amp;ldquo;)包含时，与 $* 稍有不同，下面将会讲到。 $? 上个命令的退出状态，或函数的返回值。 $$ 当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。 2. $*/$@的区别 $* 和 $@ 都表示传递给函数或脚本的所有参数，不被双引号(&amp;rdquo; &amp;ldquo;)包含时，都以&amp;rdquo;$1&amp;quot; &amp;ldquo;$2&amp;rdquo; … &amp;ldquo;$n&amp;rdquo; 的形式输出所有参数。
但是当它们被双引号(&amp;quot; &amp;ldquo;)包含时，&amp;quot;$*&amp;rdquo; 会将所有的参数作为一个整体，以&amp;quot;$1 $2 … $n&amp;quot;的形式输出所有参数；&amp;quot;$@&amp;quot; 会将各个参数分开，以&amp;quot;$1&amp;quot; &amp;ldquo;$2&amp;rdquo; … &amp;ldquo;$n&amp;rdquo; 的形式输出所有参数。
附录. 参考资料 Shell特殊变量：Shell $0, $#, $*, $@, $?, $$和命令行参数 </content>
    </entry>
    
     <entry>
        <title>xargs使用复杂参数</title>
        <url>https://orchidflower.github.io/2017/07/30/How-to-using-argument-in-xargs/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Linux</tag><tag>Shell</tag>
        </tags>
        <content type="html"> 一般情况下xargs只处理一个参数，因此可以这样使用，最后的rm会自动补齐一个参数：
1find . | grep hello | xargs rm 但是有时候需要多个参数才能够正常运行，这时候怎么办呢？可以这样：
1ls -1 2016*.log | xargs -I % -t tar czvf %.tar.gz % --remove-files 上述命令的意思是将当前目录中所有2016*.log文件使用tar打包成tar.gz文件，并删除源文件。其中：
xargs -I 参数指定了%作为占位符。它将指代ls命令返回的字符串作为参数。然后在后面的命令中，使用%代替了参数值； xargs -t 参数作用是打印命令行 其他参数说明：
tar &amp;ndash;remove-files 参数的作用是压缩完成之后删除源文件 附录. 参考资料 xargs 中处理多个参数的用法 </content>
    </entry>
    
     <entry>
        <title>如何无密码登录SSH</title>
        <url>https://orchidflower.github.io/2017/07/23/How-to-login-without-password-over-SSH/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Linux</tag><tag>SSH</tag>
        </tags>
        <content type="html"> 我们在用Jenkins做发布工具的时候，经常用到的功能是通过SSH通道完成各种功能。例如使用scp命令拷贝安装包到服务器上，通过ssh -t命令执行服务器上的脚本等。
这时就需要配置无密码登录，否则无法做到自动执行命令。如果每次都手动输入密码，想想都不现实。要实现无密码登录，需要配置好SSH允许证书登录。
其原理是使用了公钥体系，假设有服务器Server，用户在服务器Client上，用户在服务器Client上有私钥Private Key，在服务器Server上有对应的公钥Public Key。这样访问的时候Server就能够通过公钥体系进行验证：要求用户使用其私钥进行签名，从而确保用户拥有私钥，以此验证用户身份。如下图：
1. 服务器配置 默认SSH的配置已经允许通过证书登录。但是为了安全起见，有些配置可以修改一下（非必须，请根据需要修改）：
1PermitRootLogin # 默认yes，改成no（禁用root通过ssh登录） 2PasswordAuthentication # 默认yes，改为no（禁用使用密码认证登录，必须有证书才能登录） 2. 密钥生成 用户密钥的生成使用ssh-keygen命令即可。注意：该命令最好在Client端生成，因为私钥证书需要确保安全性，不要泄露，否则攻击者也就拥有了同样的权限。
1ssh-keygen -t rsa ssh-keygen可以生成多种算法类型的密钥，例如rsa, dsa等。一般选择rsa即可。其生成的证书路径保存在~/.ssh文件夹下。按照算法类型进行命名，如果使用RSA算法，则生成的两个文件为：
1id_rsa 私钥文件。确保其文件访问模式为600（只允许当前用户访问） 2id_rsa.pub 公钥文件 3. 公钥上传到服务器上 公钥需要上传到服务器上，并添加到Server上某个用户的~/.ssh/authorized_keys文件中。如果文件不存在，可以新建一个。
4. 使用 上述配置好后，就可以使用ssh相关的命令进行无密码操作了。例如：
1scp abc.tar.gz root@192.168.50.81:~ 2ssh -t root@192.168.50.81 bash /root/deploy.sh abc.tar.gz </content>
    </entry>
    
     <entry>
        <title>在alias命令中使用单引号</title>
        <url>https://orchidflower.github.io/2017/07/16/How-to-using-single-quota-in-alias-command/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Linux</tag><tag>Shell</tag>
        </tags>
        <content type="html"> Linux中的alias命令可以将一条复杂的命令缩短为一个简单的指令，实际工作中经常会用到。使用alias的时候命令本身需要使用单引号包括起来。但是如果命令本身中包含单引号怎么办呢？
例如，下面这条命令：
1ps -ef | grep shadowsocks/server.py | grep -v grep | awk &amp;#39;{print $2}&amp;#39; 其作用是获取任务的pid。其中用到的awk的参数需要用到单引号。alias也可以使用双引号，但是如果用双引号，其中的内容会被转义解释成具体获得的值。而不是命令本身。
这时可以使用 &#39;&amp;quot;&#39;&amp;quot;&#39; 替代单引号。解释一下：
&amp;rsquo; 使用单引号结束第一段； &amp;quot; 开启第二段，这里使用双引号； &amp;rsquo; 单引号本身； &amp;quot; 结束第二段，使用双引号； &amp;rsquo; 开启第三段，使用单引号。 所以最后的语句命令如下：
1alias stopssr=&amp;#39;pid=`ps -ef | grep shadowsocks/server.py | grep -v grep | awk &amp;#39;&amp;#34;&amp;#39;&amp;#34;&amp;#39;{print $2}&amp;#39;&amp;#34;&amp;#39;&amp;#34;&amp;#39;`;if [ -n &amp;#34;$pid&amp;#34; ]; then kill -9 $pid; fi&amp;#39; 附录A. 参考资料 How to escape single-quotes within single-quoted strings? </content>
    </entry>
    
     <entry>
        <title>如何在Mac上添加一个虚拟IP</title>
        <url>https://orchidflower.github.io/2017/07/09/How-to-add-one-virtual-IP-on-Mac/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Mac</tag>
        </tags>
        <content type="html"> 最近忙着系统重构，因为经常处于移动办公的状态，访问公司的服务器不是很方便，所以一些基础服务都是搭建在本机上。但是使用的时候碰到了一些问题，最大的问题是网络地址切换导致的：IP地址总是不固定。有些服务（例如FastDFS）需要有明确的IP地址来绑定服务。不固定的IP地址会给这些服务带来麻烦，需要修改配置重启服务。 这种情况下，最好的解决办法是能够给Mac分配一个固定的IP，不管怎么切换网络一直存在。幸好这个是可以解决的，而且并不复杂。方法如下：
1ifconfig lo0 alias 192.168.255.199 其原理是给网络设备loopback增加一个alias。loopback设备一直存在，而且与en0设备独立，可以一直存在。
删除方法也很简单：
1ifconfig lo0 -alias 192.168.255.199 这样终于可以有个固定IP用来绑定服务了。
附录A. 参考资料 Virtual network interface in Mac OS X </content>
    </entry>
    
     <entry>
        <title>Let&#39;s Encrypt免费证书的使用</title>
        <url>https://orchidflower.github.io/2017/07/02/How-to-use-Let-s-Encrypt/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>免费证书</tag><tag>Linux</tag>
        </tags>
        <content type="html"> 1. 背景 因为云认证服务的商户认证体系是基于双向SSL的，如果服务器端没有启用SSL证书，则整个认证体系必须重构。目前的现状是申请SSL证书费用比较高（一年2-3w），而且周期比较长，赶不上目前的测试进度。所以只能使用免费证书来支撑一下了。
免费证书服务提供商据我所知有几个：Let&#39;s Encrypt, StartSSL, StarCom。但是StartSSL, StarCom前一阵子被Chrome、Firefox等设置为不可信（签名流程不规范，不符合安全监管要求之类的原因），因此目前可选的只有let&#39;s encrypt。
Let&#39;s Encrypt是国外一个公共的免费 SSL 项目，由 Linux 基金会托管，它的来头不小，由Mozilla、思科、Akamai、IdenTrust和EFF等组织发起，目的就是向网站自动签发和管理免费证书，以便加速互联网由 HTTP 过渡到 HTTPS。
2. 自动化申请原理 Let&#39;s Encrypt 每次申请的证书有效期虽然只有90天，但是它支持自动化的申请：整个申请过程不像传统的CA有很长的审批过程，可以做到自动化的申请部署，所以完全能够满足使用的需求。Let&#39;s Encrypt 定义了规范ACME（Automatic Certificate Management Environment）。只要按照规范定义，用户完全可以自己编写程序或脚本实现整个证书申请的过程，成为Agent。官方有自己的实现：Certbot。另外还有大量的开源实现，具体可以参考官网。
Let&#39;s Encrypt和ACME规范的设计目标是能够自动化申请证书，完全不用人工参与。这是通过一个符合ACME规范Agent来完成的。
2.1 域名验证 Let&#39;s Encrypt是通过证书来识别一个域名管理者的。第一次运行Agent的时候，Agent会生成密钥对，并将公钥提交给Let&#39;s Encrypt。这个过程类似于传统CA中的在CA创建商户的过程。
然后通过一些方法，Agent向Let&#39;s Encrypt证书这个证书的拥有者拥有对指定域名的控制权。这是通过挑战应答方式实现：针对指定域名Let&#39;s Encrypt生成一个挑战值，然后ACME Client将这个值部署到指定位置，Let&#39;s Encrypt验证部署的值是否正确。ACME规范中定义了几种验证方法，分别是：
http-01 将应答值保存成文件，并能够通过特定的URL访问到； dns-01 将应答值配置到TXT类型的DNS记录中； 在这个过程中，Agent会使用管理者的私钥对挑战值进行签名，并把签名值存放到指定的位置（文件或DNS记录中）。完成之后Agent通知Let&amp;rsquo;s Encrypt进行验证。验证之后就可以确认指定证书拥有对指定域名的控制权。这个证书和私钥被称为授权密钥对（authorized key pair）。
2.2 域名申请或吊销 有了授权密钥对之后，具体的申请过程就简单了，只要发送对应的消息给Let&amp;rsquo;s Encrypt即可。
证书申请时，Agent生成密钥对，并且生成一个PKCS#10 CSR，同时用授权密钥对中的私钥对CSR进行签名，以此证明这次申请是被授权的。Let&amp;rsquo;s Encrypt收到请求之后验证签名，如果没有问题，就签发证书： 证书吊销与上面类似。Agent对吊销请求进行签名，然后发送请求给Let&amp;rsquo;s Encrypt完成请求。 3. 申请过程 在实际使用中，我没有使用官方的客户端Certbot，因为它集成度太高，会自动启动一个服务占用80端口，在实际的生产环境中很难做到这一点。我实际使用过的有两个：acme-tiny.py和le-dns。
3.1 acme-tiny.py acme-tiny.py 是一个Python的脚本。它使用的是http-01的验证方式，不需要占用端口，通过与http服务器（例如nginx、apache等）协同工作完成验证工作。具体用法可以参考其说明文件。简单说一下优缺点。
优点是脚本很小，完成的功能也足够单一，因此自由度比较高。当你的网站使用Apache或Nginx发布的时候，通过简单的配置就可以使用起来。但是如果你的网站架构比较复杂，例如分布在多台服务器上时，需要负载均衡时，使用acme-tiny就不同合适了。
3.2 le-dns 因为我的网站部署在多台服务器上，需要进行负载均衡，因此使用http-01的验证方法很难完成（需要部署到多台服务器上去）。因此比较合适的验证方法是使用dns-01验证。
要实现自动化的dns-01验证，就需要能够程序化的操控DNS记录，也就需要脚本能够访问DNS服务商的服务，这就需要根据不同的DNS服务商进行定制开发。我一直使用DNSPod的域名服务，而le-dns也支持DNSPod，所以最后选定了它。
3.2.1 安装 le-dns是基于letsencrypt.sh的，是纯粹的bash脚本，没有其他依赖项。安装起来很简单：
1wget https://github.com/xdtianyu/scripts/raw/master/le-dns/le-dnspod.sh 2wget https://github.com/xdtianyu/scripts/raw/master/le-dns/dnspod.conf 3chmod &#43;x le-dnspod.sh 3.2.2 修改配置 然后修改配置文件dnspod.conf：
1TOKEN=&amp;#34;YOUR_TOKEN_ID,YOUR_API_TOKEN&amp;#34; 2RECORD_LINE=&amp;#34;默认&amp;#34; 3DOMAIN=&amp;#34;example.com&amp;#34; 4CERT_DOMAINS=&amp;#34;example.com www.example.com im.example.com&amp;#34; 5#ECC=TRUE 其中的TOKEN是在DNSPod中申请到的API Token（https://www.dnspod.cn/console/user/security)，注意格式上分为两部分。 DOMAIN为要申请证书的根域名；CERT_DOMAINS是要申请的域名，可以有多个。
3.2.3 获取证书 运行./le-dnspod.sh dnspod.conf就可以生成证书了。生成的证书在certs目录下对应的域名目录中。
3.2.4 几点心得 3.2.4.1 证书长度 默认情况下，申请的证书密钥长度为4096，如果想修改成2048，可以修改le-dnspod.sh同目录下的letsencrypt.sh中的KEYSIZE参数。
3.2.4.2 在Nginx中的相关配置参考 1server { 2 listen 443; 3 ssl_certificate /etc/nginx/keys/cap.eveus.com/fullchain.pem; 4 ssl_certificate_key /etc/nginx/keys/cap.eveus.com/privkey.pem; 5 ... 6} 注意：ssl_certificate使用的fullchain.pem。如果使用cert.pem，在某些平台上（例如手机上）会报证书不受信任。
3.2.4.3 授权密钥对 授权密钥对是可以重新生成的。如果以前的密钥对丢失了，可以重新通过工具生成，只要通过了域名控制权验证，那就成为新的授权密钥对了。
附录. 参考资料 Automatic Certificate Management Environment (ACME) protocol ACME Client Implementations Let&amp;rsquo;s Encrypt: How It Works acme-tiny.py on Github le-dns on Github lesencrypt.sh o Github </content>
    </entry>
    
     <entry>
        <title>Kafka介绍与使用</title>
        <url>https://orchidflower.github.io/2017/06/25/How-to-use-Kafka/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Java</tag><tag>Kafka</tag><tag>Zookeeper</tag>
        </tags>
        <content type="html"> Apache Kafka是分布式发布-订阅消息系统。它最初由LinkedIn公司开发，之后成为Apache项目的一部分。Kafka是一种快速、可扩展的、设计内在就是分布式的，分区的和可复制的提交日志服务。 Apache Kafka与传统消息系统相比，有以下不同：
它被设计为一个分布式系统，易于向外扩展； 它同时为发布和订阅提供高吞吐量； 它支持多订阅者，当失败时能自动平衡消费者； 它将消息持久化到磁盘，因此可用于批量消费，例如ETL，以及实时应用程序。 关于Kafka的介绍网上有很多，这里不展开，主要说明一下如何搭建集群。下面以搭建三台节点的集群为例子。三台服务器的IP为：192.168.50.76, 192.168.50.77, 192.168.50.78。
1. Zookeeper搭建 以下操作在zookeeper主目录下。
1.1 配置文件 修改配置文件./conf/zoo.cfg（可以在./conf/zoo_sample.conf基础上修改）：
1tickTime=2000 2initLimit=10 3syncLimit=5 4# 修改成合适的路径 5dataDir=/opt/tools/zookeeper_data 6clientPort=2181 7# 集群中的每个节点都要写在这儿，并保证端口在集群之内畅通 8server.1=192.168.50.76:2888:3888 9server.2=192.168.50.77:2888:3888 10server.3=192.168.50.78:2888:3888 1.2 启动停止 启动命令：
1./bin/zkServer.sh start 停止命令：
1./bin/zkServer.sh stop 2. Kafka 以下操作在Kafka主目录下进行。
2.1 配置文件 修改配置文件./config/server.properties：
1# 每台节点上这个值不能相同，例如第一台用1，第二台用2，第三台用3 2broker.id=1 3port=9092 4# 允许删除topic。执行删除时topic将被标记为删除，重启后正式删除文件 5delete.topic.enable=true 6# 修改成keys目录 7log.dirs=/opt/tools/kafka_data 8# 绑定服务的IP。如果为空，则所有IP都会被绑定端口。新版改成listeners 9host.name=192.168.50.76 10# 注册到zookeeper中的主机名，须确保通过客户端可以通过该地址访问到Kafka。新版改成advertised.listeners 11advertised.host.name=192.168.50.76 12# 集群使用的zookeeper主机 13zookeeper.connect=192.168.50.76:2181,192.168.50.77:2181,192.168.50.78:2181 2.1 启动停止 1bin/kafka-server-start.sh config/server.properties 2bin/kafka-server-stop.sh config/server.properties 2.2 创建topic 1./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test partitions指定分区数；replication-factor指定副本数。
附录. 参考资料 kafka学习笔记：知识点整理 </content>
    </entry>
    
     <entry>
        <title>在Ubuntu 16.04 LTS上设置DOCKER_OPTS</title>
        <url>https://orchidflower.github.io/2017/06/22/Using-DOCKER-OPTS-on-Ubuntu-16-04-LTS/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>Ubuntu</tag>
        </tags>
        <content type="html"> 之前一直使用Ubuntu 14.04来跑Docker。今天在16.04 LTS上跑Docker的时候发现设置DOCKER_OPTS的时候有些区别，特此记录一下。
1. 症状 之前在Ubuntu 14.04 LTS上都是通过修改/etc/default/docker文件来设置DOCKER_OPTS参数的，譬如像下面这个配置：
1# Docker Upstart and SysVinit configuration file 2DOCKER_OPTS=&amp;#34;-H unix:///var/run/docker.sock -H tcp://0.0.0.0:2345&amp;#34; 是通过使用-H tcp://0.0.0.0:2345参数，开启Docker的Remote API端口。这样就可以通过远程访问Docker服务。
今天在16.04 LTS版本上发现这样修改不起作用。具体表现是始终没有绑定到端口2345上，这个参数根本就没有起作用。
2. 原因 这个问题出现的原因是/etc/default/docker这个文件是用于SysVinit启动机制的一个配置文件。而Ubuntu 16.04 LTS使用systemd替代了init作为服务启动进程。新的启动机制不使用这个配置文件。
3. 解决办法 解决办法就是修改systemd的启动脚本，引入这个配置文件。打开/lib/systemd/system/docker.service这个文件，修改如下：
1EnvironmentFile=-/etc/default/docker 2ExecStart=/usr/bin/dockerd $DOCKER_OPTS -H fd:// 上述修改通过EnvironmentFile指定了环境变量文件（内容参考上面）。然后在ExecStart中使用了在环境变量文件中定义的DOCKER_OPTS环境变量。这样修改以后，就可以通过修改/etc/default/docker文件来修改DOCKER_OPTS变量了。
修改上述文件之后，使用下面的命令使配置生效：
1sudo systemctl daemon-reload 2sudo service docker restart 附录 Ubuntu 16.04 DOCKER_OPTS </content>
    </entry>
    
     <entry>
        <title>在Mac上运行SOAPUI 5.3.0</title>
        <url>https://orchidflower.github.io/2017/06/21/Running-SOAPUI-5-3-0-on-Mac-OSX/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>SOAPUI</tag><tag>Mac</tag><tag>SOAP</tag>
        </tags>
        <content type="html"> 0. 前言 Mac上找不到特别好的SOAP Webservice测试工具。以前用过SOAP UI，感觉很好。但是SOAP UI在Mac上安装有些问题。特此记录一下安装过程。
SoapUI目前最新的版本是5.3.0，目前已经开源。SmartBear在SOAP UI之后发布了新版本更名为SOAPUI NG。SOAPUI NG体积大了很多，而且功能更加繁琐，个人感觉还不如以前的版本好用。SoapUI以前收费，到了5.2.1以后版本就开源并且免费了。
SoapUI在Mac会出现无响应的现象：界面能够打开，但是画面卡住，鼠标显示成旋转彩球，无法操作。要正常使用需要修改一下才行。
1. 安装过程 因为SoapUI是Java程序，所以我安装的是zip包。不使用它的安装文件进行安装。下载地址：https://www.soapui.org/downloads/soapui.html。下载其Mac版本的zip包即可。
解压之后，找到/bin/soapui.sh，复制成soapui.command。然后打开soapui.command，修改：
1if [ $SOAPUI_HOME != &amp;#34;&amp;#34; ] 2then 3 JAVA_OPTS=&amp;#34;$JAVA_OPTS -Dsoapui.ext.libraries=$SOAPUI_HOME/bin/ext&amp;#34; 4 JAVA_OPTS=&amp;#34;$JAVA_OPTS -Dsoapui.ext.listeners=$SOAPUI_HOME/bin/listeners&amp;#34; 5 JAVA_OPTS=&amp;#34;$JAVA_OPTS -Dsoapui.ext.actions=$SOAPUI_HOME/bin/actions&amp;#34; 6	JAVA_OPTS=&amp;#34;$JAVA_OPTS -Djava.library.path=$SOAPUI_HOME/bin&amp;#34; 7	JAVA_OPTS=&amp;#34;$JAVA_OPTS -Dwsi.dir=$SOAPUI_HOME/wsi-test-tools&amp;#34; 8#uncomment to disable browser component 9 #JAVA_OPTS=&amp;#34;$JAVA_OPTS -Dsoapui.browser.disabled=true&amp;#34; 10fi 将最后一个注释打开即可。
2. 几个心得 使用JDK 6已经无法运行SoapUI 5.3.0了。至少需要JDK7； 运行SoapUI会自动切换GPU到独立显卡，目前没有好的解决办法； 上面的修改方法中-Dsoapui.browser.disabled=true添加到JAVA_OPTS开始部分居然不管用，必须添加到最后； 附录中提到需要修改soapui-settings.xml，实践证明并不需要； soapui-settings.xml会自动在用户的主目录创建。 附录A. 参考资料 Installing SoapUI on Mac Fix for soapUI freezing on Mac OS X Lion </content>
    </entry>
    
     <entry>
        <title>在Mac上如何安装FastDFS</title>
        <url>https://orchidflower.github.io/2017/06/18/How-to-install-FastDFS-on-Mac/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Mac</tag><tag>FastDFS</tag>
        </tags>
        <content type="html"> 项目中用到了FastDFS来做文件存储。最近重构的时候，因为经常处于移动办公的状态，所以访问公司的服务器不是很方便，所以感觉有必要在本机上搭建一套FastDFS的测试环境。
FastDFS是什么？
FastDFS是一个开源的轻量级分布式文件系统，它对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。 FastDFS为互联网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。 FastDFS里面有两种角色：Tracker、Storage。Tracker主要做调度工作，在访问上起负载均衡的作用。Storage存储节点存储文件，完成文件管理的所有功能：存储、同步和提供存取接口，FastDFS同时对文件的meta data进行管理。所谓文件的meta data就是文件的相关属性，以键值对（key value pair）方式表示，如：width=1024，其中的key为width，value为1024。文件meta data是文件属性列表，可以包含多个键值对。
1. Docker方式 因为之前用Docker用的比较多，所以首先想到的是用Docker来运行FastDFS。上hub.docker.io上找了找镜像，最后选择了luhuiguo/fastdfs这个镜像。很快写了一个docker-compose脚本：
1version: &amp;#39;3.3&amp;#39; 2services: 3 tracker: 4 image: luhuiguo/fastdfs 5 ports: 6 - &amp;#34;22122:22122&amp;#34; 7 command: 8 - tracker 9 volumes: 10 # let container use same timezone as host 11 - /etc/localtime:/etc/localtime 12 - /opt/docker/fastdfs/tracker:/var/fdfs 13 storage: 14 image: luhuiguo/fastdfs 15 ports: 16 - &amp;#34;23000:23000&amp;#34; 17 links: 18 - tracker 19 command: 20 - storage 21 environment: 22 TRACKER_SERVER: 192.168.255.199:22122 23 GROUP_NAME: group1 24 volumes: 25 - /etc/localtime:/etc/localtime 26 - /opt/docker/fastdfs/storage:/var/fdfs 执行起来，看起来也是正常的。但是使用程序访问的时候却失败了。抛出了异常：java.net.SocketTimeoutException: connect timed out。通过跟踪代码发现了原因：使用docker的时候，storage向tracker汇报的地址是docker内部的地址，而这个地址在Mac本机是无法直接访问的。通过代码访问Tracker的时候返回的地址就是docker内部的地址，自然会出现SocketTimeoutException了。
1.1 network host模式 因为知道docker有host这一网络模式，可以使docker容器使用与宿主机一样的网络。感觉上这样或许可以解决上面的问题，而且镜像的说明中也提到了这一点。于是加上了network_mode: host。但是启动之后发现还是一样的错误。经过搜索找到了原因：
**Mac上的Docker实际上是通过虚拟化方式运行在Mac系统上的。通过xhyve技术模拟出来一台Linux主机，然后在其中跑Docker进程。当使用host模式跑的时候，docker使用的是这个虚拟出来的Linux主机的网络作为Host网络，无法直接使用Mac主机的网络。因此依然无法连接是正常的。**也就是说，在Mac主机上，host这种网络是无法使用的。
2. 本机编译执行 既然使用Docker无法运行FastDFS，那只能通过编译源码来运行了。最新版本的FastDFS已经可以直接在Mac上编译了（不需要修改源码）。因此这种方法也不难。主要步骤如下：
2.0 关闭系统保护 从OSX 10.11开始，Mac对关键目录进行了保护（例如：/bin, /usr/bin等）。而要编译FastDFS却是要安装文件到/usr/bin等目录下，所以首先需要禁用系统保护。关闭的方法如下：
重启系统，重启的过程中按住Command&#43;R进入Recovery模式； 从菜单中选择“终端”或“Terminal”进入命令行模式； 输入命令csrutil disable关闭保护模式，然后输入reboot重启系统即可。 2.1 libfastcommon FastDFS依赖于libfastcommon，因此需要首先编译、安装libfastcommon，步骤如下：
1unzip libfastcommon-1.0.35.zip 2cd libfastcommon-1.0.35 3./make.sh 4./make.sh install 2.2 fastdfs FastDFS源码通过Github下载。下面以最新的5.10为例。编译、安装步骤如下：
1unzip fastdfs-5.10.zip 2cd fastdfs-5.10 3./make.sh 4./make.sh install 安装成功后，FastDFS相关的可执行文件被安装到/usr/bin目录下。相关的配置文件被放在/etc/fdfs下，这和在Linux上安装的结果是一样的。
2.3 启动tracker 下面首先启动Tracker服务。首先准备存储数据的目录，Tracker将会在该目录中保存运行时信息以及日志文件：
1mkdir -p /opt/tools/fastdfs/tracker 2chown -R cap:cap /opt/tools/fastdfs/tracker 然后准备配置文件，从sample文件复制一份以便修改：
1cd /etc/fdfs 2cp tracker.conf.sample tracker.conf 然后修改配置文件/etc/fdfs/tracker.conf，在Mac上单机安装只需要修改base_path，修改成上面刚刚创建的目录：
1base_path=/opt/tools/fastdfs/tracker 然后启动fastdfs，启动完成之后应该占用了22122端口：
1/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf 2netstat -nl | grep 22122 启动服务使用如下命令：
1/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf start 停止服务可以使用如下命令：
1/usr/bin/fdfs_trackerd /etc/fdfs/tracker.conf stop 2.4 启动storage 首先还是准备目录供Storage节点使用：
1mkdir -p /opt/tools/fastdfs/storage 2chown -R cap:cap /opt/tools/fastdfs/storage 准备配置文件：
1cp storage.conf.sample storage.conf 修改配置文件：
1# 基本路径，日志等存储在该目录下 2base_path=/opt/tools/fastdfs/storage 3# 存储目录，可以存在多个。FastDFS会按照调度方法使用这些不同的目录。默认使用Round Robin调度方法。 4store_path0=/opt/tools/fastdfs/storage 5# 如果部署集群的话，只要多写几个tracker_server就可以了。 6tracker_server=192.168.255.199:22122 启动服务可以使用如下命令：
1/usr/bin/fdfs_storaged /etc/fdfs/storage.conf start 停止服务命令：
1/usr/bin/fdfs_storaged /etc/fdfs/storage.conf stop 附录A. 参考资料 FastDFS FastDFS on Github FastDFS分布式文件系统集群安装与配置 Unable to connect to container using host network from host How to turn off system integrity protection on OS X </content>
    </entry>
    
     <entry>
        <title>Nginx配置导致的SSL证书认证失败</title>
        <url>https://orchidflower.github.io/2017/06/03/SSL-Authentication-Failure-caused-by-Nginx-Proxy/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Nginx</tag><tag>SSL</tag><tag>证书</tag>
        </tags>
        <content type="html">  注： 这是在之前博客上发过的文章，在实际使用中经常会有人碰到，特意转贴过来。
1. 背景 目前公司对外开放了一个云服务平台，提供一些功能供商户接入使用。整个项目的架构是基于Spring &#43; MyBatis的。另外，商户端的服务接口是基于SOAP WebService的，这部分使用CXF实现。 安全方面采用了Spring Security，可以对商户提供证书认证或密码认证。但是出于安全考虑，目前只开放了证书认证。为了使用证书认证商户，我们创建了一个自签名的CA，用来生成商户使用的客户端证书。在验证上，使用Nginx验证客户端证书是否是指定CA产生的。另外，为了防止被作废的证书（例如给商户颁发了新证书后，原证书应该作废，但是原证书也是由指定CA产生的）再次使用，在代码层面对证书进行了进一步的验证（这一点是通过Nginx将客户端证书作为Header传递到Java后台实现的，有时间以后再讲）。
2. 部署架构 云服务平台部署在aliyun上，大致上结构是这样的（只涉及到了网络访问层面的东西）：
1商户 -https-&amp;gt; aliyun负载均衡 -tcp转发-&amp;gt; Nginx -http-&amp;gt; Jetty --&amp;gt; ClientCertificateFromProxyFilter 商户访问云服务的时候，需要使用我们提供的客户端证书来建立https链接。aliyun的LB只负责TCP转发，不对协议进行分析。因此从aliyun到Nginx之间实际的数据流是https数据流。Nginx接受到请求后，验证客户端证书是否正确，并将客户端证书设置为HTTP请求中的Header变量，然后请求后台的Jetty服务器。 我们代码中实现了一个Filter（ClientCertificateFromProxyFilter），它的唯一作用是检查过来的HTTP请求中有没有变量SSL_CLIENT_CERT，如果有则把它转换成一个Certificate对象，添加到HTTP请求中，从而将一个HTTP请求模拟成一个HTTPS请求，这样Spring Security就能够进行证书认证了。
3. 问题 在上线之前，按照以往的经验，我们测试了通过浏览器访问受保护的资源来测试HTTPS是否工作正常。因为提前在浏览器中导入了客户端证书，因此浏览器上能够弹出对话框选择客户端证书，选择之后就能够访问指定的资源了。
我们推荐商户使用CXF作为接入方式，一般的代码如下：
1&amp;lt;jaxws:client id=&amp;#34;uidService&amp;#34; 2	serviceClass=&amp;#34;com.xwf.cloudauth....&amp;#34; 3	address=&amp;#34;https://.../api/UidApiService&amp;#34;&amp;gt; 4&amp;lt;/jaxws:client&amp;gt; 5&amp;lt;http-conf:conduit name=&amp;#34;*.http-conduit&amp;#34;&amp;gt; 6	&amp;lt;http-conf:tlsClientParameters disableCNCheck=&amp;#34;true&amp;#34;&amp;gt; 7	&amp;lt;sec:keyManagers keyPassword=&amp;#34;123456&amp;#34;&amp;gt; 8	&amp;lt;sec:keyStore type=&amp;#34;PKCS12&amp;#34; password=&amp;#34;123456&amp;#34; resource=&amp;#34;...com.p12&amp;#34;/&amp;gt; 9	&amp;lt;/sec:keyManagers&amp;gt; 10	&amp;lt;sec:trustManagers&amp;gt; 11	&amp;lt;sec:keyStore type=&amp;#34;JKS&amp;#34; password=&amp;#34;changeit&amp;#34; resource=&amp;#34;cacerts&amp;#34; /&amp;gt; 12	&amp;lt;/sec:trustManagers&amp;gt; 13	&amp;lt;/http-conf:tlsClientParameters&amp;gt; 14	&amp;lt;http-conf:client Connection=&amp;#34;Keep-Alive&amp;#34; 15	MaxRetransmits=&amp;#34;1&amp;#34; AllowChunking=&amp;#34;false&amp;#34; /&amp;gt; 16&amp;lt;/http-conf:conduit&amp;gt; 但是商户实际接入的时候却碰到了问题：
1Caused by: org.apache.cxf.transport.http.HTTPException: HTTP response &amp;#39;401: Full authentication is required to access this resource&amp;#39; when communicating with https://... 2	at org.apache.cxf.transport.http.HTTPConduit$WrappedOutputStream.handleResponseInternal(HTTPConduit.java:1549) 3	at org.apache.cxf.transport.http.HTTPConduit$WrappedOutputStream.handleResponse(HTTPConduit.java:1504) 4	at org.apache.cxf.transport.http.HTTPConduit$WrappedOutputStream.close(HTTPConduit.java:1310) 5	at org.apache.cxf.transport.AbstractConduit.close(AbstractConduit.java:56) 6	at org.apache.cxf.transport.http.HTTPConduit.close(HTTPConduit.java:628) 7	at org.apache.cxf.interceptor.MessageSenderInterceptor$MessageSenderEndingInterceptor.handleMessage(MessageSenderInterceptor.java:62) 8	... 38 more 4. 解决过程 401错误代表未授权，所以首先怀疑是客户端证书不正确。
4.1 切换到本地测试 收到客户反馈之后，首先想到的可能是证书发放的不正确，毕竟已经通过浏览器通过了测试。 首先在本地测试环境进行了测试。因为之前测试坏境中配置的连接服务的代码中启用了用户名密码认证，因此首先做的是将用户名、密码认证部分屏蔽掉，然后进行测试，结果还真发现了问题。 这下子有点着急了，担心有大的bug存在。毕竟产品已经上线，碰到这种bug可比较麻烦了。
4.2 本地问题的解决 经过添加日志、断点在本地环境进行了调试，找到了本地报401错误的原因：本地环境中的证书是被废弃掉的了，本地环境证书重发后并没有同步到本地SVN中，因此才会出现401错误。证书通过了Nginx的验证，但是被Java层的代码拦截掉（因为客户提交过来的代码与数据库中用户相关的证书不一致）。 通过将本地证书替换之后，问题得到了解决。原来本地环境只是虚惊一场。
4.3 发布调试版本 本地环境问题解决之后，更加怀疑生产环境的问题来源于证书不匹配。但是经过仔细分析客户证书文件及数据库中的记录，发现并不能够支持这种想法。 没有办法的情况下，只好在代码中（主要是ClientCertificateFromProxyFilter）添加了更多的调试信息，临时发布了调试版本。再次测试，发现在ClientCertificateFromProxyFilter中没有收到SSL_CLIENT_CERT这个变量。初步断定问题出在Nginx转发上（从Nginx到Jetty没有转发客户端证书）。
4.4 Wireshark 确定问题出在Nginx层之后事情陷入了僵局，因为实在不知道为什么会产生这种情况。 因为前一阵子研究过SSL握手的过程，当时使用过Wireshark进行过网络抓包。当事情陷入僵局的时候，想起来可以使用这种方法分析一下协议。经过抓包，比各个环境（测试环境、生产环境/浏览器及Java环境），发现了问题所在，原来在生产环境上Java根本没有发送客户端证书到Nginx上去！
4.5 协议分析 没有办法的情况下，只好回头又去分析SSL协议：
SSL我握手过程 SSL协议（HTTPS）握手、工作流程分析（双向HTTPS分析） 使用Wireshark观察SSL/TLS握手过程-双向认证、单项认证 发现在双向认证过程中，在server hello done结束之前，服务器应该发送certificate request 到客户端。这样客户端才能够决定发送客户端证书到服务器进行认证。但是在生产环境使用Java访问的时候，服务器没有发送该请求；但是奇怪的是当使用浏览器访问的时候，这个请求又出现了。
4.6 SNI 再次陷入了僵局。同样的HTTPS请求为什么会导致不同的认证顺序和结果呢？经过漫长的，漫无目的的搜索后，终于找到了一点眉目。原来这是一个兼容性问题：SNI。 这里先介绍一下SNI的概念：
SNI（Server Name Indication）是为了解决一个服务器使用多个域名和证书的SSL/TLS扩展。一句话简述它的工作原理就是，在连接到服务器建立SSL连接之前先发送要访问站点的域名（Hostname），这样服务器根据这个域名返回一个合适的证书。目前，大多数操作系统和浏览器都已经很好地支持SNI扩展，OpenSSL 0.9.8已经内置这一功能。
我们的云认证平台后台有很多台服务器，配置了多个域名，但是对外的出口是唯一的，都是使用Nginx作为代理/反向代理的。这样就用到了SNI技术，在一台机器上同时对多个域名提供服务。当浏览器访问的时候，因为浏览器支持SNI技术，因此会提供域名给Nginx，这样Nginx能够从配置好的多个域名配置文件中找到需要的证书及客户端证书CA配置信息进行验证。 但是当Java访问的时候，就碰到了问题：因为Java不能够自动支持SNI协议（Java8中提供了SNI的支持，但是需要手工编码），因此在上面的Spring配置中，并没有办法把域名发送给Nginx，因此Nginx不知道使用哪个配置中的证书及客户端证书CA配置信息。
4.7 解决方法 后来从网上找到了这样一篇文章：Using nginx and client certificate!，这才最终明白了怎么解决问题。
Nginx有一个default server的概念。也就是说当出现不支持SNI协议的客户端时，将使用default server的配置进行验证。当没有配置default server的时候，Nginx将使用找到的第一个配置文件中的配置（经过测试，应该是按照字母顺序排序的）。 而在我们生产环境的配置中，第一个找到的配置文件中没有指定客户端证书CA！！
1server { 2 listen 443; 3 server_name ...xwf-id.com; 4 ssl on; 5 ssl_certificate /etc/nginx/keys/xwfserver.pem; 6 ssl_certificate_key /etc/nginx/keys/xwfserver.key; 7 ssl_session_timeout 5m; 8 ssl_verify_client off; 9 10 location / { 11 proxy_buffer_size 8k; 12 proxy_buffers 8 64k; 13 proxy_buffering on; 14 proxy_pass http://prm_admin; 15 proxy_set_header Host $host; 16 proxy_set_header X-Real-IP $remote_addr; 17 proxy_set_header X-Forwarded-Host $host; 18 proxy_set_header X-Forwarded-Server $host; 19 proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; 20 } 21} 所以当Java访问的时候，服务器端告诉客户端，不需要提供客户端证书。。。
4.8 安全考虑 最后，我们添加了一个default server来解决这个问题：
1server { 2 listen 443 default_server; 3 server_name a; 4 ssl on; 5 ssl_certificate /etc/nginx/keys/xwfserver.pem; 6 ssl_certificate_key /etc/nginx/keys/xwfserver.key; 7 ssl_session_timeout 5m; 8 ssl_client_certificate /etc/nginx/keys/ca-certs.pem; 9 ssl_verify_client optional_no_ca; 10 11 location / { 12 return 200; 13 } 14} 这里需要说明的一个问题是：因为我们服务器上有两个服务器要进行客户端证书认证，因此有两个自签名的CA存在。为了解决能够验证两个证书CA签名的证书，在/etc/nginx/keys/ca-certs.pem中需要同时包含两个CA证书。 但是这也带来了一定的风险：使用网站A证书认证的用户有可能访问到网站B的内容！
但是因为我们目前的体系中，使用ClientCertificateFromProxyFilter对证书有效性进行了进一步的验证，所以这一问题在我们的系统中没有导致风险。如果其他系统中要用到这个功能，需要对这部分的风险性投入关注。
5. 总结 问题终于解决了，看看时间已经是凌晨5点了。总结一下经验教训：
通过这次事故，对SSL通讯的握手过程有了进一步的了解。 对Wireshark也有了更进一步的了解。 以后产品上线的时候，还是要使用真正的代码进行以下测试，这样就能够今早发现这个Java的SNI兼容性问题了。 </content>
    </entry>
    
     <entry>
        <title>DelegatingFilterProxy源码分析</title>
        <url>https://orchidflower.github.io/2017/06/02/The-source-code-of-DelegatingFilterProxy/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Spring</tag><tag>Security</tag><tag>Java</tag>
        </tags>
        <content type="html"> 1. 背景 1&amp;lt;filter&amp;gt; 2	&amp;lt;filter-name&amp;gt;springSecurityFilterChain&amp;lt;/filter-name&amp;gt; 3	&amp;lt;filter-class&amp;gt;org.springframework.web.filter.DelegatingFilterProxy&amp;lt;/filter-class&amp;gt; 4&amp;lt;/filter&amp;gt; 5 6&amp;lt;filter-mapping&amp;gt; 7	&amp;lt;filter-name&amp;gt;springSecurityFilterChain&amp;lt;/filter-name&amp;gt; 8	&amp;lt;url-pattern&amp;gt;/documentation/*&amp;lt;/url-pattern&amp;gt; 9&amp;lt;/filter-mapping&amp;gt; 用过Spring Security的人都会熟悉以上代码，一般教程上都会说明，使用Spring Security就需要在web.xml中指定以上代码。从这个配置中，可能会给我们造成一个错觉，以为DelegatingFilterProxy类就是springSecurity的入口，但其实这个类位于spring-web这个jar下面，说明这个类本身是和springSecurity无关。
2. 真相 DelegatingFilterProxy类继承于抽象类GenericFilterBean,间接地implement 了javax.servlet.Filter接口，Servlet容器在启动时，首先会调用Filter的init方法,GenericFilterBean的作用主要是可以把Filter的初始化参数自动地set到继承于GenericFilterBean类的Filter中去。在其init方法的如下代码就是做了这个事：
1PropertyValues pvs = new FilterConfigPropertyValues(filterConfig, this.requiredProperties); 2BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this); 3ResourceLoader resourceLoader = new ServletContextResourceLoader(filterConfig.getServletContext()); 4bw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, this.environment)); 5initBeanWrapper(bw); 6bw.setPropertyValues(pvs, true); 另外在init方法中调用了initFilterBean()方法，该方法是GenericFilterBean类是特地留给子类扩展用的：
1Override 2protected void initFilterBean() throws ServletException { 3	synchronized (this.delegateMonitor) { 4	if (this.delegate == null) { 5	// If no target bean name specified, use filter name. 6	if (this.targetBeanName == null) { 7	this.targetBeanName = getFilterName(); 8	} 9	// Fetch Spring root application context and initialize the delegate early, 10	// if possible. If the root application context will be started after this 11	// filter proxy, we&amp;#39;ll have to resort to lazy initialization. 12	WebApplicationContext wac = findWebApplicationContext(); 13	if (wac != null) { 14	this.delegate = initDelegate(wac); 15	} 16	} 17	} 18} 可以看出上述代码首先看Filter是否提供了targetBeanName初始化参数，如果没有提供则直接使用filter的name做为beanName,产生了beanName后，由于我们在web.xml的filter的name是springSecurityFilterChain,从spring的IOC容器中取出bean的代码是initDelegate方法，下面是该方法代码：
1protected Filter initDelegate(WebApplicationContext wac) throws ServletException { 2 Filter delegate = wac.getBean(getTargetBeanName(), Filter.class); 3 if (isTargetFilterLifecycle()) { 4 delegate.init(getFilterConfig()); 5 } 6 return delegate; 7} 通过跟踪代码，发现取出的bean是org.springframework.security.FilterChainProxy，该类也是继承于GenericFilterBean,取出bean后，判断targetFilterLifecycle属性是false还是true,决定是否调用该类的init方法。这个FilterChainProxy bean实例最终被保存在DelegatingFilterProxy类的delegate属性里,
下面看一下DelegatingFilterProxy类的doFilter方法 ：
1public void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) 2 throws ServletException, IOException { 3 4 // Lazily initialize the delegate if necessary. 5 Filter delegateToUse = null; 6 synchronized (this.delegateMonitor) { 7 if (this.delegate == null) { 8 WebApplicationContext wac = findWebApplicationContext(); 9 if (wac == null) { 10 throw new IllegalStateException(&amp;#34;No WebApplicationContext found: no ContextLoaderListener registered?&amp;#34;); 11 } 12 this.delegate = initDelegate(wac); 13 } 14 delegateToUse = this.delegate; 15 } 16 17 // Let the delegate perform the actual doFilter operation. 18 invokeDelegate(delegateToUse, request, response, filterChain); 19 } 真正要关注invokeDelegate(delegateToUse, request, response, filterChain);这句代码,在下面可以看出DelegatingFilterProxy类实际是用其delegate属性即org.springframework.security.FilterChainProxy实例的doFilter方法来响应请求。
1protected void invokeDelegate( 2 Filter delegate, ServletRequest request, ServletResponse response, FilterChain filterChain) 3 throws ServletException, IOException { 4 5 delegate.doFilter(request, response, filterChain); 6 } 以上就是DelegatingFilterProxy类的一些内部运行机制，其实主要作用就是一个代理模式的应用,可以把servlet 容器中的filter同spring容器中的bean关联起来。
此外还要注意一个DelegatingFilterProxy的一个初始化参数：targetFilterLifecycle ,其默认值为false 。 但如果被其代理的filter的init()方法和destry()方法需要被调用时，需要设置targetFilterLifecycle为true。具体可见DelegatingFilterProxy中的如下代码：
1protected void initFilterBean() throws ServletException { 2 synchronized (this.delegateMonitor) { 3 if (this.delegate == null) { 4 // If no target bean name specified, use filter name. 5 if (this.targetBeanName == null) { 6 this.targetBeanName = getFilterName(); 7 } 8 // Fetch Spring root application context and initialize the delegate early, 9 // if possible. If the root application context will be started after this 10 // filter proxy, we&amp;#39;ll have to resort to lazy initialization. 11 WebApplicationContext wac = findWebApplicationContext(); 12 if (wac != null) { 13 this.delegate = initDelegate(wac); 14 } 15 } 16 } 17 } 18 19 20protected Filter initDelegate(WebApplicationContext wac) throws ServletException { 21 Filter delegate = wac.getBean(getTargetBeanName(), Filter.class); 22 if (isTargetFilterLifecycle()) { //注意这行 23 delegate.init(getFilterConfig()); 24 } 25 return delegate; 26 } 3. 结论 DelegatingFilterProxy是Spring-web中的一个通用Filter，它可以达到如下目的，解决如下问题： 通过Delegate模式，将Filter的功能转移到一个Spring管理的Bean上去，这样这个Bean就可以实现Filter功能，而且又享受了Spring带来的好处。 另外：这个Bean需要实现Filter接口。
4. 结论2 当不指定targetBeanName的时候，DelegatingFilterProxy会使用FilterName来查找指定的Bean并完成初始化。这也解释了，使用Spring Security的时候，要求的FilterName一定要是：springSecurityFilterChain。
</content>
    </entry>
    
     <entry>
        <title>使用Docker&#43;Apache2&#43;WebSVN搭建SVN服务器</title>
        <url>https://orchidflower.github.io/2017/05/26/Running-SVN-Server-using-Docker-Apache2-WebSVN/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>SVN</tag><tag>WebSVN</tag>
        </tags>
        <content type="html"> 1. 背景 虽然现在的SVN已经用的越来越少，很多人都切换到了Git上。但是以前的一些历史项目还是需要SVN支持的。 之前的SVN服务器是直接搭建在一台Ubuntu服务器上的。当时一起搭建了WebSVN。也曾经研究过怎么搭建WebSVN，但是现在也不能够工作了，时间长久了也忘了怎么搭建了。所以想研究一下怎么使用Docker来完成一样的工作。
2. 构建过程 SVN搭建需要Apache配合。而WebSVN需要PHP的配合。这次构建镜像是以Ubuntu 14.04.5为基础的。然后在镜像基础上安装Apache2,Subversion,WebSVN等内容。
2.1 Dockerfile 1FROM ubuntu:14.04.5 2RUN sed -i &amp;#34;s/archive/cn.archive/g&amp;#34; /etc/apt/sources.list \ 3 &amp;amp;&amp;amp; apt-get update \ 4 &amp;amp;&amp;amp; apt-get install -y apache2 subversion libapache2-svn websvn \ 5 &amp;amp;&amp;amp; sed -i &amp;#34;s/&amp;#39;UTF-8&amp;#39;, &amp;#39;ISO/&amp;#39;GBK&amp;#39;, &amp;#39;UTF-8&amp;#39;, &amp;#39;ISO/g&amp;#34; /usr/share/websvn/include/command.php \ 6 &amp;amp;&amp;amp; apt-get autoclean &amp;amp;&amp;amp; apt-get clean &amp;amp;&amp;amp; apt-get autoremove \ 7 &amp;amp;&amp;amp; a2enmod auth_digest 8ENV SERVER_NAME=localhost \ 9 APACHE_RUN_USER=www-data \ 10 APACHE_RUN_GROUP=www-data \ 11 APACHE_PID_FILE=/var/run/apache2/apache2.pid \ 12 APACHE_RUN_DIR=/var/run/apache2 \ 13 APACHE_LOCK_DIR=/var/lock/apache2 \ 14 APACHE_LOG_DIR=/var/log/apache2 \ 15 APACHE_LOG_LEVEL=warn 16COPY buildtime/apache2-foreground /usr/local/bin/ 17COPY buildtime/default.conf /etc/apache2/sites-available/000-default.conf 18CMD [&amp;#34;apache2-foreground&amp;#34;] 构建命令：docker build . -t svnbase
2.2 解读 FROM 指定了基础镜像 RUN 指定了构建过程中需要执行的指令 ENV 设置了运行Apache所需要的一些环境变量 COPY 将一些预先写好的配置文件复制到镜像中； CMD 指定了镜像的启动命令。 其中的RUN命令最复杂，完成了最重要的一部分工作。我们逐条解读。
2.2.1 修改Ubuntu源地址 国内的网络环境导致了直接使用基础镜像中的源下载包会非常慢，因此有必要切换到国内的镜像地址。这个是通过编辑/etc/apt/sources.list文件完成的。使用命令：
1sed -i &amp;#34;s/archive/cn.archive/g&amp;#34; /etc/apt/sources.list 完成了对这个文件的修改。其做法就是将archive.ubuntu.com这个域名替换为：cn.archive.ubuntu.com。
2.2.2 安装相关组件 这部分包含如下几条指令，这部分比较基础，不做过多解读。
1apt-get update \ 2 &amp;amp;&amp;amp; apt-get install -y apache2 subversion libapache2-svn websvn 2.2.3 修复WebSVN的中文编码问题 默认情况下，WebSVN只支持UTF-8编码的源文件。如果源码中有GBK编码的，会显示为乱码。通过网上查找，可以通过修改源码解决。参考资料：中文解决办法1
1sed -i &amp;#34;s/&amp;#39;UTF-8&amp;#39;, &amp;#39;ISO/&amp;#39;GBK&amp;#39;, &amp;#39;UTF-8&amp;#39;, &amp;#39;ISO/g&amp;#34; /usr/share/websvn/include/command.php 2.2.4 清理缓存，减小镜像体积 下面的命令清理apt-get生成的缓存，从而减小镜像的体积。
1apt-get autoclean &amp;amp;&amp;amp; apt-get clean &amp;amp;&amp;amp; apt-get autoremove 2.3 其他文件 2.3.1 apache2-foreground 使用下面的脚本启动Apache服务，并显示log文件内容。注意：单纯的使用service start会导致镜像很快退出。
1#!/bin/bash 2set -e 3 4# Apache gets grumpy about PID files pre-existing 5rm -f /var/run/apache2/apache2.pid &amp;amp;&amp;amp; service apache2 start &amp;amp;&amp;amp; tail -f /var/log/apache2/access.log &amp;amp;&amp;amp; service apache2 stop 2.3.2 default.conf 1&amp;lt;VirtualHost *:80&amp;gt; 2 ServerName 127.0.0.1 3 4 ServerAdmin webmaster@localhost 5 DocumentRoot /var/www/html 6 7 &amp;lt;Location /svnrep&amp;gt; 8 DAV svn 9 SVNParentPath /opt/scmroot/svn/svnrep 10 SVNListParentPath on 11 AuthType Digest 12 AuthName &amp;#34;SVN Access&amp;#34; 13 AuthUserFile /opt/scmroot/svndigest 14 Require valid-user 15 &amp;lt;/Location&amp;gt; 16 17 Alias /websvn /usr/share/websvn 18 19 &amp;lt;Directory /usr/share/websvn&amp;gt; 20 DirectoryIndex index.php 21 Options FollowSymLinks 22 Order allow,deny 23 Allow from all 24 &amp;lt;IfModule mod_php5.c&amp;gt; 25 php_flag magic_quotes_gpc Off 26 php_flag track_vars On 27 &amp;lt;/IfModule&amp;gt; 28 AuthType Digest 29 AuthName &amp;#34;SVN Access&amp;#34; 30 AuthUserFile /opt/scmroot/svndigest 31 Require valid-user 32 &amp;lt;/Directory&amp;gt; 33 34 ErrorLog ${APACHE_LOG_DIR}/error.log 35 CustomLog ${APACHE_LOG_DIR}/access.log combined 36&amp;lt;/VirtualHost&amp;gt; 在这个配置文件中我们指定了几个特定的路径，这几个路径需要在运行镜像的时候挂载覆盖：
/opt/scmroot/svnrep SVN仓库存放的路径； /opt/scmroot/svndigest 访问SVN仓库的用户配置文件。需要使用htdigest文件生成。 AuthName 指定了Digest认证中的realm。在创建svndigest的时候需要使用同样的值“SVN Access”。 3. 使用 3.1 docker-compose.yaml 我们使用Docker-compose来使用这个镜像。
1version: &amp;#39;2&amp;#39; 2services: 3 apache: 4 image: svnbox 5 volumes: 6 # let container use same timezone as host 7 - /etc/localtime:/etc/localtime 8 - /opt/docker/svnbox/runtime/svnrep:/opt/scmroot/svnrep 9 - /opt/docker/svnbox/runtime/svndigest:/opt/scmroot/svndigest 10 - /opt/docker/svnbox/runtime/svn_deb_conf.inc:/etc/websvn/svn_deb_conf.inc 11 - /opt/docker/svnbox/runtime/index.html:/var/www/index.html 12 ports: 13 - &amp;#34;85:80&amp;#34; 14 restart: always 15 hostname: apache 3.2 解读 image 指定了镜像； volumes 指定了要挂载的本地目录。其中： svnrep 是存放所有SVN仓库的目录； svndigest 是存放用户信息的文件。使用htdigest命令创建（考虑到安全性，选择了Digest认证，而不采用Basic认证）。 svn_deb_conf.inc WebSVN配置文件。主要可以用来添加SVN仓库，以供WebSVN访问。 index.html 是这个Apache需要的首页文件。 3.3 其他文件 3.3.1 svn_deb_conf.inc 1&amp;lt;?php 2// 使用日志替代显示Age。缺省情况下WebSVN显示一个Age信息，包括修改人，修改时间（是距今多少天这种修改时间） 3$config-&amp;gt;setShowAgeInsteadOfDate(false); 4// flatView 模式只显示当前目录的文件。而默认情况下是先是一个目录树，点击目录将在当前页面展开当前目录的内容。 5//$config-&amp;gt;useFlatView(); 6// 扩展Tab键为4个空格 7$config-&amp;gt;expandTabsBy(4); 8// 在日志视图显示修改的内容（哪些文件被修改了） 9$config-&amp;gt;setLogsShowChanges(true); 10// 添加要被WebSVN浏览的SVN仓库。不添加的就不显示。 11$config-&amp;gt;addRepository(&amp;#34;AuthServer&amp;#34;, &amp;#34;file:///opt/scmroot/svn/svnrep/AuthServer&amp;#34;); 12$config-&amp;gt;addRepository(&amp;#34;CodeConvert&amp;#34;, &amp;#34;file:///opt/scmroot/svn/svnrep/CodeConvert&amp;#34;); 13$config-&amp;gt;addRepository(&amp;#34;eCodeHSM&amp;#34;, &amp;#34;file:///opt/scmroot/svn/svnrep/eCodeHSM&amp;#34;); 14$config-&amp;gt;addRepository(&amp;#34;eCodeHSM_ezTokenPIN&amp;#34;, &amp;#34;file:///opt/scmroot/svn/svnrep/eCodeHSM_ezTokenPIN&amp;#34;); 15$config-&amp;gt;addRepository(&amp;#34;HSMCardManager&amp;#34;, &amp;#34;file:///opt/scmroot/svn/svnrep/HSMCardManager&amp;#34;); 16$config-&amp;gt;addRepository(&amp;#34;Software&amp;#34;, &amp;#34;file:///opt/scmroot/svn/svnrep/Software&amp;#34;); 17$config-&amp;gt;addRepository(&amp;#34;vcproj&amp;#34;, &amp;#34;file:///opt/scmroot/svn/svnrep/vcproj&amp;#34;); 18$config-&amp;gt;setEnscriptPath(&amp;#34;/usr/bin&amp;#34;); 19$config-&amp;gt;setSedPath(&amp;#34;/bin&amp;#34;); 20$config-&amp;gt;useEnscript(); 21?&amp;gt; 这个配置文件中对WebSVN进行了进一步的配置。其中最主要的是使用addRepository添加本地SVN仓库（如果不添加，WebSVN是无法浏览SVN仓库的）。另外一些配置可以看源码中的注释。
3.3.2 index.html 这个是首页，可以随便编辑内容。
1&amp;lt;html&amp;gt; 2&amp;lt;head&amp;gt; 3&amp;lt;/head&amp;gt; 4&amp;lt;body&amp;gt; 5&amp;lt;/body&amp;gt; 6&amp;lt;/html&amp;gt; 3.3.3 svndigest 使用htdigest命令创建。例如：
1$ htdigest -c svndigest &amp;#34;SVN Access&amp;#34; test 2Adding user test in realm SVN Access 3New password: 4Re-type new password: 4. 怎么访问 启动之后，使用：
http://[server-ip]:85/svnre/&amp;hellip; 访问SVN； http://[server-ip]:85/websvn 访问WebSVN。 附录. 参考资料 docker-svnbox on Github WebSVN(2.3.3)查看文件中文乱码解决方法 apt-get指令的autoclean,clean,autoremove的区别 Package management with APT WebSVN(2.3.3)查看文件中文乱码解决方法&amp;#160;&amp;#x21a9;&amp;#xfe0e;
</content>
    </entry>
    
     <entry>
        <title>在Tomcat中使用ThreadLocal以及Session</title>
        <url>https://orchidflower.github.io/2017/05/04/ThreadLocal-and-Session-in-Tomcat/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Tomcat</tag><tag>Java</tag><tag>并发</tag>
        </tags>
        <content type="html"> 最近运营同事在管理平台（生产环境）上碰到一个问题：登录之后会莫名其妙地变成未登录状态，被踢回登录页面。
管理平台使用的Spring MVC框架实现的后台接口，React实现的前台页面。之前引入React的时候已经做过前后端分离。但是当时考虑到技术栈的原因，没有对登录体系进行彻底改造，没有引入AccessToken来维护登录状态，依然保留了Java的Session机制。考虑到管理平台属于内部使用，访问量不大，因此直接在Nginx层使用iphash进行了Session粘滞，确保同一个用户的请求总是被同一个的后台Tomcat处理，这样就可以使用传统的session机制保持用户登录状态。
排查过程中，由于踢出登录情况比较随机，所以最初怀疑是超时时间设置有问题，但是一直无法重现错误。一直耽搁了好几天，很幸运的，昨天测试的同学终于找到了重现的步骤：在管理平台执行某个数据导出操作，导出操作耗时比较长，在操作没有结束的时候点击其他链接，就会出现未登录踢回登录页面的情况。
1. SessionContext 经过检查代码，发现出现登录异常问题的时候返回的错误码是：LOGIN_OVERTIME，确实是超时的返回代码。但是测试中发现即使刚刚登录，按照上面操作也会出现问题，显然真正的原因不是超时。
没办法，开始扒代码，先找到返回错误码的地方：
1private BaseResult isLogon() { 2 BaseResult result = new BaseResult(); 3 UserVO user = SessionContext.getSessionContext().getCurrentUser(); 4 if (user != null) { 5 result.setSuccess(true); 6 } else { 7 result.setCode(ResultCode.LOGIN_OVERTIME.getCode()); 8 result.setMsg(&amp;#34; &amp;#34;); 9 //result.setMsg(ResultCode.LOGIN_OVERTIME.getDesc()); 10 } 11 return result; 12} 逻辑很简单，获取当前的SessionContext，如果currentUser不为空则认为已经登录，否则没有登录。
继续看SessionContext：
1public class SessionContext { 2 private transient static final ThreadLocal&amp;lt;SessionContext&amp;gt; SESSION_CONTEXT = new ThreadLocal&amp;lt;SessionContext&amp;gt;(); 3 4 private HttpServletRequest request; 5 private HttpServletResponse response; 6 ... 7 public UserVO getCurrentUser() { 8 return (UserVO) request.getSession().getAttribute(&amp;#34;currUser&amp;#34;); 9 } 10 11 public void setCurrentUser(UserVO user) { 12 request.getSession().setAttribute(&amp;#34;currUser&amp;#34;, user); 13 } 14 15 public void initSession(HttpServletRequest request, HttpServletResponse response) { 16 this.request = request; 17 this.response = response; 18 } 19 ...	20 public static SessionContext getSessionContext() { 21 if (SESSION_CONTEXT.get() == null) { 22 SessionContext sc = new SessionContext(); 23 SESSION_CONTEXT.set(sc); 24 } 25 return SESSION_CONTEXT.get(); 26 } 27} 上面的代码的目的是使用ThreadLocal保存SessionContext对象。而SessionContext对象是通过initSession函数注入了request、response后创建的。getCurrentUser获取的是实际上是SessionContext对应的request对象中的内容。
2. 问题原因 扒到以上代码，终于发现问题出在哪儿了：因为Tomcat使用的是线程池（ThreadPool），一个线程池内的线程是复用的，并不能够保证每次web请求都使用同样的线程进行处理；也无法保证一个线程只为一个用户服务。所以在Web容器环境中使用ThreadLocal要特别小心，最好是不用，它和本地环境中的ThreadLocal还是有很多差异的。具体到之前的问题：当一个操作花费时间很长的时候，操作还没有结束，线程依然繁忙，进行第二次请求时，Tomcat会启用新的线程接受处理，但是新的线程ThreadLocal中显然没有对应的SessionContext，自然会被判定为未登录。
3. 修复方法 这部分代码是之前同事遗留下来的，限于时间原因，一直没有仔细看，原来隐藏着这种bug。如果要修复了，方法大概有如下几种：
就是引入AccessToken机制。用户登录之后分配AccessToken，该AccessToken使用Redis等外部存储进行保存。因为Token每次都跟随请求发送过来，这样就可以摆脱session粘滞的限制； 如果保持现有的session粘滞配置的话，可以考虑引入redis，通过request.getSession().getId()获得的sessionId作为主键保存currentUser等信息。我们知道Tomcat中SessionID是通过Cookie传递的（JSESSIONID），同时在Tomcat中也开辟了一块内存保存Session相关的信息。因为配置了Session粘滞，所以同一个用户来的请求，总是转发到同一台Tomcat上处理。所以根据请求携带的Cookie可以找到对应的sessionId，也能够找到Tomcat中对应的Session数据，从而找到当前用户的登录状态。 4. 内存泄露 另外，上面的代码中实际上是有内存泄露问题的：request、response对象被赋值到SessionContext对象，然后被注入到了ThreadLocal中。而Tomcat的线程池对象是持久对象，不会很快被释放。因此这两个对象很难被释放掉。当访问量越大，内存消耗会越快。只是目前的管理平台访问量比较小，所以问题不突出，一直没有发现。
总之：在并发状态下使用Tomcat的ThreadLocal是不可靠的。最好的办法是慎用。
</content>
    </entry>
    
     <entry>
        <title>Java SSL握手记录分析</title>
        <url>https://orchidflower.github.io/2017/04/28/Java-SSL-Handshake-Log/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Java</tag><tag>SSL</tag>
        </tags>
        <content type="html"> 公司项目当中经常使用CXF库连接WebService服务，而且我们自己提供的服务也是基于CXF的SOAP服务，经常需要指导客户怎么连接我们的服务。CXF库整个体系架构比较庞大，相关的类、知识点都比较多。尤其是连接SSL双向认证服务的时候，经常碰到问题。
使用双向SSL认证的时候，在Spring中配置起来非常简单，但是一旦出错就比较难找问题。经过多次尝试，最后发现还是分析SSL握手记录比较靠谱，比较容易找出真正的问题所在。特此记录一下自己的一些心得，以作备忘并希望能够帮到其他人。
1. Spring中的配置 使用CXF连接SOAP WebService，在Spring中配置起来非常简单。
1.1 spring配置 1... 2&amp;lt;context:property-placeholder location=&amp;#34;classpath:config.properties&amp;#34; /&amp;gt; 3 4&amp;lt;jaxws:client id=&amp;#34;devicelinkService&amp;#34; 5 serviceClass=&amp;#34;com.service.api_3_0.ApiCustomerService30&amp;#34; 6 address=&amp;#34;${devicelink.url}&amp;#34;&amp;gt; 7&amp;lt;/jaxws:client&amp;gt; 8 9&amp;lt;http-conf:conduit name=&amp;#34;${devicelink.serveraddress}/.*&amp;#34;&amp;gt; 10 &amp;lt;!-- 客户端证书认证相关配置 //--&amp;gt; 11 &amp;lt;http-conf:tlsClientParameters disableCNCheck=&amp;#34;true&amp;#34;&amp;gt; 12 &amp;lt;sec:keyManagers keyPassword=&amp;#34;${cert.file.pwd}&amp;#34;&amp;gt; 13 &amp;lt;sec:keyStore type=&amp;#34;PKCS12&amp;#34; password=&amp;#34;${cert.file.pwd}&amp;#34; resource=&amp;#34;${cert.file}&amp;#34;/&amp;gt; 14 &amp;lt;/sec:keyManagers&amp;gt; 15 &amp;lt;sec:trustManagers&amp;gt; 16 &amp;lt;sec:keyStore type=&amp;#34;JKS&amp;#34; password=&amp;#34;changeit&amp;#34; resource=&amp;#34;cacerts&amp;#34; /&amp;gt; 17 &amp;lt;/sec:trustManagers&amp;gt; 18 &amp;lt;/http-conf:tlsClientParameters&amp;gt; 19 20 &amp;lt;http-conf:client Connection=&amp;#34;Keep-Alive&amp;#34; 21 MaxRetransmits=&amp;#34;1&amp;#34; AllowChunking=&amp;#34;false&amp;#34;/&amp;gt; 22 &amp;lt;!-- 如果服务支持Basic认证，则可以使用下面的配置 //--&amp;gt; 23 &amp;lt;!-- 24 &amp;lt;http-conf:authorization&amp;gt; 25 &amp;lt;sec:UserName&amp;gt;${devicelink.username}&amp;lt;/sec:UserName&amp;gt; 26 &amp;lt;sec:Password&amp;gt;${devicelink.password}&amp;lt;/sec:Password&amp;gt; 27 28 &amp;lt;sec:AuthorizationType&amp;gt;Basic&amp;lt;/sec:AuthorizationType&amp;gt; 29 &amp;lt;/http-conf:authorization&amp;gt; 30 //--&amp;gt; 31&amp;lt;/http-conf:conduit&amp;gt; 32... 几个配置项：
jaxws:client 用来声明一个Spring Bean。可以在代码中使用@Autowired引用； http-conf:conduit 用来配置认证相关的内容； http-conf:tlsClientParameters 配置SSL认证相关的内容。可以配置Java SSL用的keyManager/trustManager； http-conf:authorization 配置Basic认证相关信息，可以指定Basic认证所需的用户名、密码等。 上面的代码中使用了几个变量，他们是通过context:property-placeholder引入的property文件定义的。包括：
deviceLink.url 服务访问地址 deviceLink.serveraddress 服务器地址 cert.file 证书地址 cert.file.pwd 证书密码 deviceLink.username 访问服务的用户名 deviceLink.password 访问服务的密码 1.2 config.properties 这是properties文件中定义的变量，通过context:property-placeholder配置被引入Spring配置中。
1devicelink.serveraddress=http://server.address 2devicelink.url=http://server.address/api/CustomerApi30 3devicelink.username=... 4devicelink.password=... 5cert.file.pwd=... 6cert.file=....p12 使用CXF的相关配置就是这么多，确实比较简单。这是因为CXF隐藏了很多实现的细节。但是这也带来难以排错的弊端。下面将介绍一下如何通过SSL握手日志找到问题所在。
2. 握手过程 通常的握手过程是这样的： Java SSL也是同样的步骤。粗略分为三步：
ClientHello ServerHello KeyExchange 握手结束 3. 打开SSL握手日志 首先说一下如何打开SSL握手日志。方法是在Java启动命令行中增加-Djavax.net.debug=SSL或者-Djavax.net.debug=ALL即可打开SSL握手日志。
4. 日志分析 Java的握手日志中，使用***作为每一段内容的分隔符。使用这个分隔符可以把几步内容大体上分隔开，所以阅读起来还是比较方便的。
4.0. 准备阶段 4.0.1 找到客户端证书 当配置了客户端证书的时候，首先打印的就是找到了key。如下：
1found key for : did.xwf-id.com key 2chain [0] = [ 3[ 4 ... 如果没有配置客户端证书，或者配置有问题，则不会有这一部分日志出现。
4.0.2 添加信任证书 然后就是从系统中添加可信任的CA证书，这个过程会添加很多证书进来。来源主要有两个：
$JAVA_HOME/jre/lib/security/cacerts 程序中配置的trustStore指定的证书库 1adding as trusted cert: 2 Subject: CN=Equifax Secure Global eBusiness CA-1, O=Equifax Secure Inc., C=US 3... 4.1. ClientHello 准备阶段不算是正式的SSL握手过程，只是创建了SSL握手需要的环境（Context）。从ClientHello开始，SSL握手正式开始：
1*** ClientHello, TLSv1 2RandomCookie: ... 3Session ID: {} 4Cipher Suites: [TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,...] 5Compression Methods: { 0 } 6Extension elliptic_curves, curve names: {secp256r1, ...} 7Extension ec_point_formats, formats: [uncompressed] 4.2. ServerHello ClientHello消息被发送给服务提供方，然后收到的消息就是服务器返回的ServerHello消息报文。在Java的SSL握手日志中是看不到服务器上的处理流程的，能看到的只是Java处理这个报文的解析过程。这个一定要清楚：日志中显示的都是调用者处理的日志，并不是服务器端的实际处理顺序，所以顺序可能和服务器端不一致，这是正常的。
首先显示的是Server选中的加密算法，这里是TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA：
1*** ServerHello, TLSv1 2RandomCookie: GMT: -1611070835 bytes = { ...} 3Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA 4Compression Method: 0 5Extension renegotiation_info, renegotiated_connection: &amp;lt;empty&amp;gt; 6Extension ec_point_formats, formats: [uncompressed, ansiX962_compressed_prime, ansiX962_compressed_char2] 收到ServerHello之后，就开始根据收到的内容创建Session，证书验证、交换密钥等操作了。
4.2.1 初始化Session 初始化Session：
1*** 2%% Initialized: [Session-1, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA] 3... 4.2.2 网站证书链 从之前添加的CA证书中找到了证书链，说明服务器证书是合法的：
1*** Certificate chain 2chain [0] = [ 3[ 4 Version: V3 5 Subject: CN=*.xwf-id.com, OU=IT DEPT, O=&amp;#34;Iraid Finance Information &amp;amp; Technology (Shanghai) Co.,Ltd&amp;#34;, L=Shanghai, ST=Shanghai, C=CN 6 Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11 7... 8] 9chain [1] = [ 10[ 11 Version: V3 12 Subject: CN=Symantec Class 3 Secure Server CA - G4, OU=Symantec Trust Network, O=Symantec Corporation, C=US 13 Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11 14 ... 15] 然后就提示找到了可信任的证书，也就是上面chain [1]中对应的证书：
1*** 2Found trusted certificate: 3[ 4[ 5 Version: V3 6 Subject: CN=Symantec Class 3 Secure Server CA - G4, OU=Symantec Trust Network, O=Symantec Corporation, C=US 7 Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11 8... 如果服务提供方的证书是自签名证书，那么要注意日志中是否出现了上述日志。如果没有，则很有可能握手失败。需要将提供方的证书添加到trustManager中对应的证书库中来解决问题。
4.2.3 ECDH ServerKeyExchange 密钥交换算法初始化，这里是ECDH算法的：
1*** ECDH ServerKeyExchange 2Server key: Sun EC public key, 256 bits 3 public x coord: 43374987853469150916971894311198082576230263269301289184949927385170106253395 4 public y coord: 92135670098354144912439154833828289482869500140098079447653500663810560580845 5 parameters: secp256r1 [NIST P-256, X9.62 prime256v1] (1.2.840.10045.3.1.7) 4.2.4 CertificateRequest ServerHelloDone报文中包含了服务器可以接受的客户端证书的CA列表。客户端需要根据这个CA列表从本地筛选可用的客户端证书。
1*** CertificateRequest 2Cert Types: RSA, DSS, ECDSA 3Cert Authorities: 4&amp;lt;EMAILADDRESS=mailadmin@xwf-id.com, CN=devborgen.xwf-id.com, OU=Operation Department, O=iRaid, L=Shanghai, ST=Shanghai, C=CN&amp;gt; 5&amp;lt;EMAILADDRESS=mailadmin@xwf-id.com, CN=devcap.xwf-id.com, OU=Development Department, O=iRaid, L=Shanghai, ST=Shanghai, C=CN&amp;gt; 如果服务器端没有要求客户端证书验证，则没有上述内容。
4.2.5 ServerHelloDone ServerHello信息解析完毕。
1*** ServerHelloDone 2[read] MD5 and SHA1 hashes: len = 4 30000: 0E 00 00 00 .... 4matching alias: did.xwf-id.com key 5*** Certificate chain 6chain [0] = [ 7[ 8[ 9 Version: V3 10 Subject: CN=did.xwf-id.com 11 Signature Algorithm: SHA1withRSA, OID = 1.2.840.113549.1.1.5 12 ... 上面代表找到了客户端证书。如果服务器端开启了强制要求客户端证书，而本地没有配置，则会出现这样的提示：
1*** ServerHelloDone 2[read] MD5 and SHA1 hashes: len = 4 30000: 0E 00 00 00 .... 4Warning: no suitable certificate found - continuing without client authentication 5*** Certificate chain 6&amp;lt;Empty&amp;gt; 出现了上述提示，就需要检查keyManager中的配置是否正确，查查为什么找不到客户端证书了。
4.3. ClientKeyExchange 最后一步就是密钥交换：
1*** 2*** ECDHClientKeyExchange 3ECDH Public value: { ... } 4... 5*** CertificateVerify 6... 7*** Finished 8verify_data: { 234, 76, 169, 101, 128, 33, 222, 63, 185, 227, 150, 56 } 9... 至此握手结束，生成了session并进行了缓存。
1*** 2%% Cached client session: [Session-1, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA] 通过上面的日志分析，可以有效地发现经常碰到的问题，也容易定位问题究竟出在哪儿。
附录A. 参考资料 深入研究SSL【第二章 part-1】-SSL握手协议的研究 SSL/TLS 握手优化详解 附录B. 补充知识-证书链 配置服务端证书链时，有两点需要注意：1）证书是在握手期间发送的，由于 TCP 初始拥塞窗口的存在，如果证书内容太长可能会产生额外的往返开销；2）如果配置的证书没包含中间证书，大部分浏览器可以正常工作，方法是暂停验证并根据站点证书指定的父证书 URL 自己获取中间证书。这个过程会产生额外的 DNS 解析、建立 TCP 连接等开销，非常影响性能。
基于此，配置证书链的的最佳实践是只包含站点证书和中间证书，不要包含根证书，但不要漏掉中间证书。大部分证书都是「站点证书 – 中间证书 – 根证书」这样三级，这时服务端只需要发送前两个证书（站点证书 - 中间证书）即可。但也有的证书有四级，那就需要发送站点证书外加两个中间证书了。
</content>
    </entry>
    
     <entry>
        <title>通过Zabbix监控业务数据（续）</title>
        <url>https://orchidflower.github.io/2017/04/20/Monitoring-data-in-mysql-using-Zabbixpart2/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Zabbix</tag>
        </tags>
        <content type="html"> 昨天配置好报警条件之后，今天早上检查发现昨天晚上发出了报警。但是看上去像是误报。 在凌晨2:44:02触发了警报，然后在2:44:32警报解除，持续时间30秒。如下两图： 从感觉上像是误报。
1. 误报排除 1.1 报警条件 昨天设置好的报警条件如下：
CODE_ALL、CODE_100在最近30秒钟有数据； 最近300秒（5分钟）CODE_ALL总计大于30； CODE_100/CODE_ALL&amp;lt;0.7 1.2 收到的数据 要确定报警是否正确，就需要查看当时收到的数据情况。所以从Zabbix的最新数据（Latest Data）中查看最近收到的数据。找到的数据如下： 首先是ERROR_CODE_100的数据： 然后看ERROR_CODE_ALL的数据： 1.3 疑问 按照之前的条件来说，表达式处理的数据应该是从2：40到2：44这5分钟的数据，也就是(2&#43;3&#43;6&#43;4&#43;6)/(2&#43;5&#43;7&#43;5&#43;7)=80%，明显不符合要求啊，怎么会报警呢？
但是仔细一看，原来是这样啊！在这5分钟之前CODE_ALL收到的最后一条数据时间是2:39:02，按照300秒的时间跨度，这一条记录也是符合表达式要求的。所以实际上进行运算的表达式变成了：(2&#43;3&#43;6&#43;4&#43;6)/(2&#43;5&#43;7&#43;5&#43;7&#43;6)=65.6%。这样确实就触发了警报。
1.4 解决 使用300秒这种时间跨度会出现多使用一条数据的情况，这是一开始没有想到的，对Zabbix的运作机制了解的不够透彻。对于这种时效性要求比较强的报警条件，使用Zabbix还是要比较仔细考虑逻辑是否有漏洞的。 想了想，既然时间跨度不好掌握，可以限制为使用收到的记录条数进行限制。所以最后改成的条件如下，这几天再关注一下是否工作符合预期： 2. 三种模式的示意图 Zabbix Item的类型比较多，理解起来可能有些绕。所以特意画张图，应该会有助于理解的更清楚。
</content>
    </entry>
    
     <entry>
        <title>通过Zabbix监控业务数据</title>
        <url>https://orchidflower.github.io/2017/04/19/Monitoring-data-in-mysql-in-Zabbix/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Zabbix</tag>
        </tags>
        <content type="html"> 为了事后分析服务质量，我们的云认证系统将商户访问记录保存到了数据库中（MySQL）。在日志中我们记录了商户每次访问的返回结果，耗费时间等信息。通过这些信息我们可以分析发现服务什么时候性能比较低，什么时候处理效果比较差。
之前通过写脚本，每小时对这些信息进行一次统计，并根据情况（如错误比例过高等）发送邮件通知给相关人员。但是这存在两个问题：
响应不及时：因为一小时才统计一次，所以滞后效应太明显，经常问题已经发生很久报警才发送出来； 报警条件更新不方便：报警条件只能通过脚本编写人员实现，修改起来不方便。 鉴于此，一直想对这个报警体系进行改造，最后选择通过Zabbix实现这个功能。
1. 背景介绍 Zabbix这里就不介绍了，具体怎么操作网上很多教程。这里会介绍我在使用中碰到的问题，以及对应的解决办法，不涉及具体操作。
这次改造主要对返回值进行判断。简单介绍一下数据：每条记录都有一个返回值字段ERROR_CODE，其可能的值为：
100 服务处理成功； 441 服务处理失败（服务失败，但是如果比例过高，可能有隐含的问题发生。例如商户提交的信息有问题，编码错误导致问题等）； 442 有异常发生； 443 有超时发生。 这次希望达到的目标为： 当成功比例过低（例如低于70%）的时候，触发报警；另外检查频度要提高（例如1分钟检查一次，不再1小时一次），这样可以快速发现问题。但是具体的报警条件还要考虑访问量等要素：例如晚上访问量很少，经常1分钟只有几条，这时很容易出发70%这个警戒线，所以还需要考虑过滤这种情况。
2. 使用Zabbix 定下了目标，最初感觉实现起来比较容易，所以通过修改Zabbix agent，创建了几个Item，分别用来采集每分钟的编码100、441、442、443的记录数量、以及成功率，Zabbix中创建对应的Item。然后创建Trigger，判断成功率是否小于70即可。
但是这样使用起来发现有问题：从数据库中获取上述记录数以及成功率的脚本执行速度较慢，偶尔会出现执行超时的问题，这会导致数据采集中断（Zabbix无法采集到数据），影响判断效果。虽然后来发现脚本本身优化有问题，经过优化速度有所提升，但是这种长时间的操作理应使用Zabbix Agent Active模式来处理。最后决定切换到Zabbix agent(active)。
3. 使用Zabbix Agent active Zabbix agent和Zabbix agent(active)的区别在于后者会主动从Server拉取要监控的项目，成功采集之后提交给Server，相当于两步操作；而前者则是Server直接发命令给Agent，并等待返回，相当于一步操作。Active模式就是为了解决部分采集项耗时时间长而设计的。
切换到Active Agent比较简单，只要在/etc/zabbix/zabbix_agentd.conf中指定配置即可：
1# 指定Zabbix服务器地址 2ServerActive=192.168.251.11 3# 配置当前主机的Hostname，需要与Zabbix中配置的主机名对应，否则会无法获取监控项 4Hostname=192.168.61.53 然后在Zabbix中把对应Item项改成Zabbix agent(active)即可。
这样配置下来，解决了上面的耗时过长问题。但是实际使用中又发现了新问题。这个问题跟我们采用的报警判断条件有关。所以先介绍一下报警条件的思路：要触发警报，需要满足以下条件：
最近5分钟内成功率低于70%（不是只判断当前1分钟，因为考虑单分钟可能有采样不够的问题）； 最近5分钟访问总量不低于50（如果过低，因为采样条数有限，所以可能误判）。 要满足上面这种判断，上面的数据采集方式有很大的问题：
数据不是同时采集的：Zabbix无法驱动Agent同时采集一批Item，Agent只能一个一个的进行采集。这就导致几个Item并不是同一时期的数据。例如有可能这样：错误码100的信息是0点整采集的，而错误码441的信息可能是0点0分10秒采集的，错误码442的信息采集的时间可能是0点0分30秒。拿不同时间点采集的数据去计算成功率是不正确的； 如果单纯的采用每分钟的成功率进行平均（avg），也是不准确的，因为每分钟的访问量是不一样的。正确的算法是成功率与访问量进行加权平均。但是上述采集方法显然满足不了这种计算要求。 4. 使用Zabbix Trapper 经过阅读官方文档，发现可以使用Zabbix Trapper这种模式来解决问题。
Trapper类型的Item一般翻译为捕捉器，可能理解起来有些困难，其核心的用法是Zabbix创建此种类型的Item，但是不会主动去进行数据采集。而不管是Agent、Agent（active）实际上都是Zabbix在主动收集数据，只是主动的有可能是Zabbix Server（对应Zabbix Agent类型）或者Zabbix Agent（对应Zabbix Agent active类型）。但是对Zabbix Trapper类型，Zabbix只是准备好了数据存放的地方，等待数据的到来。
使用Trapper类型，数据采集的工作由使用者来实现。数据采集完成后，可以通过zabbix_sender发送到Zabbix Server中。然后Server就可以对各种Trigger进行判断了。也就是说，Trapper类型将数据采集功能交给了使用者。
我采用的方法是通过cron定时执行（每分钟）一个脚本，脚本负责采集数据并发送给Zabbix。脚本内容大体如下，可供参考：
1# 获取当前时间 2DATE_NOW=`date &#43;&amp;#39;%Y-%m-%d %H:%M&amp;#39;` 3# 获取上次执行时间 4DATE_LAST=`cat /tmp/last.access.txt` 5if [ -z &amp;#34;$DATE_LAST&amp;#34; ]; then 6 # 如果没有上次执行时间，上次执行时间假定为5分钟前 7 DATE_LAST=`date -d&amp;#39;-5 minute&amp;#39; &#43;&amp;#39;%Y-%m-%d %H:%M&amp;#39;` 8fi 9# 保存上次执行时间 10echo $DATE_NOW &amp;gt; /tmp/last.access.txt 11# 获取统计信息 12sql=&amp;#34;select count(id) as error_all, count(if(error_code=100,id,null)) as error_100,count(if(error_code=441,id,null)) as error_441,count(if(error_code=442, id, null)) as error_442,coun 13t(if(error_code=443,id,null)) as error_443,count(if(error_code=100,id,null))/count(id)*100 as percent from xwf_logs.uid_bankcard_auth_no_otp_log where ACCESS_TIME&amp;lt;&amp;#39;${DATE_NOW}&amp;#39; and AC 14CESS_TIME&amp;gt;=&amp;#39;${DATE_LAST}&amp;#39;&amp;#34; 15result=`${MYSQL_CONN_READ} -e &amp;#34;${sql}&amp;#34;` 16error_all=`echo $result | awk &amp;#39;{print $7}&amp;#39;` 17error_100=`echo $result | awk &amp;#39;{print $8}&amp;#39;` 18error_441=`echo $result | awk &amp;#39;{print $9}&amp;#39;` 19error_442=`echo $result | awk &amp;#39;{print $10}&amp;#39;` 20error_443=`echo $result | awk &amp;#39;{print $11}&amp;#39;` 21error_per=`echo $result | awk &amp;#39;{print $12}&amp;#39;` 22# 发送到Zabbix中 23echo Data was sent at: $DATE_NOW 24zabbix_sender -z $ZABBIX_SERVER -p $ZABBIX_PORT -s $HOST_NAME -k uid.logs[ERROR_CODE_ALL] -o $error_all 25zabbix_sender -z $ZABBIX_SERVER -p $ZABBIX_PORT -s $HOST_NAME -k uid.logs[ERROR_CODE_100] -o $error_100 26zabbix_sender -z $ZABBIX_SERVER -p $ZABBIX_PORT -s $HOST_NAME -k uid.logs[ERROR_CODE_441] -o $error_441 27zabbix_sender -z $ZABBIX_SERVER -p $ZABBIX_PORT -s $HOST_NAME -k uid.logs[ERROR_CODE_442] -o $error_442 28zabbix_sender -z $ZABBIX_SERVER -p $ZABBIX_PORT -s $HOST_NAME -k uid.logs[ERROR_CODE_443] -o $error_443 29zabbix_sender -z $ZABBIX_SERVER -p $ZABBIX_PORT -s $HOST_NAME -k uid.logs[ERROR_CODE_100_PERCENT] -o $error_per 30echo Data was sent successfully. 31echo ---------------------------------------------- 上述代码中，使用一条语句计算所有的指标，这样及减轻了MySQL的压力，也保证了数据都是同一个是简单采集出来的。另外，通过使用临时文件/tmp/last.access.txt保存上次数据采集的时间点，保证了即使定时任务触发有所变化，也不会导致部分数据没有采集到。
Trigger中的条件设置成这样： 也就是最近5分钟内访问量&amp;gt;50并且成功率低于70%就触发报警。
5. 解决误报 5.1 数据提交顺序 配置完成之后，运行一段时间发现经常误报：明明检查数据不符合条件，但是就是会触发一个状态OK的报警通知，持续时间（Duration）为0，没有对应的PROBLEM状态的报警。这真是非常奇怪。
这个问题耗费了很长时间，经过仔细研读Zabbix的官方手册，发现里面有这么一段 Triggers：
Trigger status (the expression) is recalculated every time Zabbix server receives a new value that is part of the expression. 也就是说，当Trigger的表达式依赖于多个Item（例如上面的依赖于ALL和100两个Item）的时候，当每一个Item的新值到来的时候，Zabbix都会对Trigger进行重新计算。Zabbix不会等到多个数据都齐全之后再进行判断。
返回头看上面的脚本，先提交了ALL，然后提交了100。这样Zabbix先拿到了新的ALL值，**然后就会拿最近的5分钟的ERROR_CODE_100的值（这时实际上只有4个，最新的数据服务器还没有收到），和最近5分钟的ERROR_CODE_ALL的值（5个）一起计算成功率，显然这样很容易触发低于70%这个条件。所以Zabbix就认为这个Trigger处于PROBLEM状态。但是当100的数据也收到之后，Zabbix再次重新计算，又发现状态实际上是OK的。**所以就出现上面那种反复出现OK报警的情况。但是为什么没有对应的PROBLEM报警，可能是Zabbix本身进行了限制，不发送这种Duration很短的PRBLEM状态。有时间看看源码确认一下。
最先想到的解决办法是将脚本中的数据提交顺序换一下，将100的数据先提交，然后是ALL。但是实际上这样也是有问题的，它会导致Trigger从PRBLEM状态错误的变成OK状态（5个100数据和4个ALL数据计算成功率）。所以最后的解决办法是这样： 就是判断最近30秒之内ALL和100的数据有没有，没有就认为数据不全，认为状态正常。只有当两者数据都有的情况下，才计算比例是否小于70%。
5.2 Recovery条件 仔细分析一下就会发现，上面的判断条件在Trigger状态为PROBLEM的时候还是有问题的：当ALL或者100的数据没有收到的时候，不进行计算百分比，上面的Express被判断没有问题，Trigger就会被判定为OK。但是当数据齐全之后，计算百分比之后发现还是有问题。这样就导致了状态反复切换，频繁的发送PRBLEM、OK的报警信息。
这个问题的解决办法是增加Recovery Expression到Trigger中。这个Expression的作用是当Trigger处于PROBLEM状态的时候，即使判断Expression状态没有问题（FALSE），还需要判断Recovery Expression装个表达式，只有它判断为TRUE的时候才解除报警状态。
最后增加Recovery Expression，内容如下： 在这个表达式中，会判断成功率高于等于70%才认为状态恢复。
6. 心得 Zabbix提供的基本功能能够满足大部分的需求，同时它还提供了很好的扩展方法。例如这里用到的Trapper，可以让用户自由的采集数据，而Zabbix专心干好它的Trigger功能，各司其职，配合高效。 官方文档作为权威资料一定要看，很多疑难问题，可以在里面找到权威解答。 附录A. 参考资料 Zabbix Trigger expression Zabbix Supported trigger functions Zabbix Sender </content>
    </entry>
    
     <entry>
        <title>在Linode节点上开启BBR算法</title>
        <url>https://orchidflower.github.io/2017/04/17/Enable-BBR-on-Linode/</url>
        <categories>
          <category>翻墙</category>
        </categories>
        <tags>
          <tag>Linode</tag><tag>Shadowsocks</tag><tag>BBR</tag>
        </tags>
        <content type="html"> BBR是Google开源的TCP拥堵控制算法，与2016年9月开源。BBR的目的是要尽量跑满带宽, 并且尽量不要有排队的情况, 其使用效果并不比速锐差。
Linux kernel 4.9&#43; 已支持 tcp_bbr。我在Linode安装了4.10.10内核，可以开启BBR。但是Linode自带的4.9无法开启。
1. BBR简介 关于其具体原理及各种分析可以看知乎上的讨论贴，很有技术含量。这里只做简单介绍。BBR试图解决两个问题：
在有一定丢包率的网络链路上充分利用带宽。非常适合高延迟、高带宽的网络链路： 标准TCP算法在只要有万分之一的丢包率情况下，带宽就只剩 30%；千分之一丢包率时只剩 10%；有百分之一的丢包率时几乎就卡住了。而 TCP BBR 在丢包率 5% 以下几乎没有带宽损失，在丢包率 15% 的时候仍有 75% 带宽。
降低网络链路上的 buffer 占用率，从而降低延迟。非常适合慢速接入网络的用户 延迟越高的用户，采用 TCP BBR 后的延迟下降比例越高，原来需要 10 秒的现在只要 2 秒了。
2. 启用BBR 目前VPS供应商的默认内核应该还没有这么新。即使是Linode提供了4.9.15，但是应该没有编译tcp_bbr模块进去，所以照样无法开启BBR功能。因此启用BBR需要首先安装新内核，然后开启相关配置即可。
2.1 更新内核 启用BBR需要替换内核。我用的VPS是Linode的。而Linode提供了一个比较方便的方式来切换内核，大大降低了新手操作的风险。它可以在管理后台选择需要启动的内核。通常我们可以新安装一个内核，而不用删除原有内核，在管理后台选择GRUB2启动我们新安装的内核即可，方便又安全。这样就有机会切换回原有的内核，而不用重新安装整个系统。
我在Linode的节点使用的Ubuntu 16.04LTS。这个版本默认内核可以选择到4.9.15。但是依然不支持BBR。因此需要安装新内核。
安装方法比较简单：
1wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.10.10/linux-image-4.10.10-041010-generic_4.10.10-041010.201704120813_amd64.deb 2dpkg -i linux-image-4.10.10-041010-generic_4.10.10-041010.201704120813_amd64.deb 这样就安装了新版本的内核。
然后在Linode管理控制台里面选择Boot Settings中的Kernel选择GRUB 2即可。选择之后，重启机器即可。 2.2 启用BBR 重启之后首先查看内核是否正确：
1root@localhost:~# uname -a 2Linux localhost 4.10.10-041010-generic #201704120813 SMP Wed Apr 12 12:15:07 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 表明已经升级到了4.10.10版本的内核。
然后查看是否编译了tcp_bbr模块：
1root@localhost:~# lsmod | grep tcp_bbr 2tcp_bbr 6015 13 如果没有启用bbr则上面没有输出或者报错。
上面条件都满足之后就可以开启BBR了。
1echo &amp;#34;net.core.default_qdisc=fq&amp;#34; &amp;gt;&amp;gt; /etc/sysctl.conf 2echo &amp;#34;net.ipv4.tcp_congestion_control=bbr&amp;#34; &amp;gt;&amp;gt; /etc/sysctl.conf 3sysctl -p 然后执行以下命令查看是否启用成功：
1root@localhost:~# sysctl net.ipv4.tcp_available_congestion_control 2sysctl net.ipv4.tcp_congestion_controlnet.ipv4.tcp_available_congestion_control = bbr cubic reno 3root@localhost:~# sysctl net.ipv4.tcp_congestion_control 4net.ipv4.tcp_congestion_control = bbr 如果结果都有bbr, 则证明你的内核已开启BBR。
2.3 效果 在我的Linode fremon节点上，开启之后大概能带来几倍的差距。开启后可以看1440p，1080p很流畅。 BBR有点不足的地方是使用中总是要缓冲一段时间然后才能够达到慢速，不会一下子达到。可能是因为我这边网络延迟有点大，毕竟有250-300ms了。
附录A. 参考资料 Linux Kernel 4.9 中的 BBR 算法与之前的 TCP 拥塞控制相比有什么优势？ Google BBR on Github Ubuntu kernel mainline 4.10.10 Kernel </content>
    </entry>
    
     <entry>
        <title>在VSCode中为Vue.js开发启用静态类型检查Flow</title>
        <url>https://orchidflower.github.io/2017/04/11/Using-flow-js-for-vue-in-VSCode/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Vue.js</tag><tag>Flow</tag><tag>静态类型</tag>
        </tags>
        <content type="html"> 众所周知，Javascript是一种弱类型（或者称为动态类型）语言，即变量的类型是不确定的。例如，下面代码中的temp一开始是字符串，后来又变成了数字：
1temp = &amp;#39;hello&amp;#39;; 2temp = 5; 弱类型语言变量类型完全由当时的值决定，所以称为“弱类型”。这样设计有其好处，可以写出非常简洁的代码。但是在构建大型项目的时候，无法在编译期发现问题会导致很难发现问题，反而会为程序员带来非常大的负担。这实际上限制了JS项目的规模，无法开发过于复杂的项目。
1. 强类型解决方案 一直有人在尝试为Javascript增加强类型系统的支持。目前看来比较流行的有两种方案：Typescript和Flow.js。
1.1 Typescript TypeScript是一种由微软开发的自由和开源的编程语言。它是JavaScript的一个超集，而且本质上向这个语言添加了可选的静态类型和基于类的面向对象编程。在编译期会去掉类型和特有语法，生成纯粹的Javascript代码。由于最终执行的还是Javascript，所以Typescript不会带来兼容性问题。TypeScript 是 JavaScript 的超集，这意味着他支持所有的 JavaScript 语法。并在此之上对 JavaScript 添加了一些扩展，如 class / interface / module 等。这样会大大提升代码的可阅读性。
目前版本是2.2。官方网址为：https://www.typescriptlang.org/。
Typescript带来的好处重点有：
静态类型检查； IDE智能提示； 代码重构； 可读性。 Angular 2.0框架已经采用了Typescript语言重写。
1.2 Flow Flow是Facebook出品的，针对JavaScript的静态类型检查工具，目前版本v0.43.1。其代码托管在github之上，并遵守BSD开源协议。官网地址：http://flow.org。同为Facebook出品，React采用了Flow。另外，Vue.js也采用了Flow作为静态检查的工具。
1.3 比较 相对来说，Flow的代码侵入性比较小一些。并且可以通过babel-plugin-transform-flow-strip-types转一下就可以得到去除Flow特性的代码。另一点来说，代码可以部分切换采用，成本比较低，能够使用Babel&#43;ESLint&#43;Webpack这种比较成熟的体系。这方面的讨论可以参考附录中的 Vue 2.0 为什么选用 Flow 进行静态代码检查而不是直接使用 TypeScript？ ，里面有Vue.js开发者尤雨溪关于这方面的思考与回答。
我比较认同以上观点，Flow代码侵入性比较小，可以保证代码比较符合ES的发展规律，免得受制于具体厂商的技术。所以最后开发中选择了在Vue.js开发中使用Flow技术。当然，我在后台开发（Node.js）相关代码中也引入了Flow。不过这部分配置比较容易，下面会顺带提到。
2. 工具链简介 Javascript开发对工具链的使用越来越重，通常前端开发都会用到诸如：Webpack、Babel、ESLint等工具。先简单介绍一下各工具的主要用途：
Babel： 编译工具。鉴于执行环境（浏览器、Node）与JS规范（ES6、ES7等，或者React、Vue.js等定义的规范）之间存在差异，不能够直接在执行环境运行我们写的代码，因此需要使用编译工具将我们写的代码编译成执行环境可以理解的代码，这就是Babel的作用。 Webpack： 打包工具。能够将各种资源（JS、JSX）、样式（CSS、LESS、SASS）、图片等都作为模块来处理，并最终打包成一个文件，即解决了代码依赖问题，也提高了加载速度； ESLint： 代码问题检查工具。Linter类的工具都是通过扫描代码，通过已有的规则发现代码中可能存在的问题。而ESLint就是针对JS代码的Linter工具。 3. 环境配置 3.1 目标及思路 这次配置的目标是：在VSCode中可以通过Flow发现代码中的问题，能够支持.js、.vue文件；在Webpack中配置能够对Flow相关代码正确编译。
这次配置的核心思路是利用ESLint的插件机制，通过插件eslint-plugin-flow实现对Flow支持。而VSCode有一个很好用的ESLint插件，可以在打开文件的时候自动对文件内容进行Lint操作，从而提示出各种潜在问题。这样通过配置ESLint的规则，不光可以实现普通Lint问题的发现，还可以实现Flow相关问题的发现：例如可以要求变量必须有类型等。
下面按照顺序描述各个步骤需要做的更改。
3.2 Flow 首先就是安装Flow。虽然可以将Flow安装到全局，但是为了以后方便管理，推荐安装到项目本身。
1npm install flow-bin --save-dev 3.2.1 .flowconfig 在项目根目录，增加一个配置文件.flowconfig，下面的配置是我现在用的。Flow默认会扫描整个工程中的所有代码，通过 ignore 配置忽略不需要检测的代码。其他配置项以后会专门写个介绍。
1[ignore] 2.*/node_modules/.* 3 4[include] 5./src/.*/*.vue 6 7[libs] 8 9[options] 3.2.2 验证 现在可以验证一下了。在代码开始的地方增加注释：/* @flow */，然后执行命令进行检查：
1$ ./node_modules/.bin/flow src/utils.js 2... 3src/utils.js:8 4 8: module.exports.toHex = function(source) { 5 ^^^^^^ parameter `source`. Missing annotation 6... 可以看到已经能够检查出来问题了。
3.3 eslint 然后安装eslint插件（如果你的项目中已经使用了eslint，那这步可以省略）：
1# eslint 2npm install eslint --save-dev 3# parser babel-eslint 4npm install babel-eslint --save-dev 5# flowtype plugin 6npm install eslint-plugin-flowtype --save-dev 7# html plugin (used for .vue) 8npm install eslint-plugin-html --save-dev 9# vue plugin &amp;amp; vue rules config 10npm install eslint-plugin-vue eslint-config-vue --save-dev eslint-plugin-flowtype 就是用来进行Flow检测用的插件。eslint-plugin-html，eslint-plugin-vue两个插件是为了检查.vue文件用的。eslint-config-vue是vue检测方面的一些规则，使用这个我们可以快速上手，不用逐条配置vue相关的规则。
3.3.1 .eslintrc.json eslint依赖于一个配置文件，之前版本叫.eslintrc，最近版本的eslint支持多种格式的配置，可以是json/yaml/js等，对应的配置文件也需要添加对应的文件后缀。这里我用的是json格式，内容如下：
1{ 2 &amp;#34;parser&amp;#34;: &amp;#34;babel-eslint&amp;#34;, 3 &amp;#34;plugins&amp;#34;: [ 4 &amp;#34;html&amp;#34;, 5 &amp;#34;flowtype&amp;#34; 6 ], 7 &amp;#34;extends&amp;#34;: [ 8 &amp;#34;eslint:recommended&amp;#34;, 9 &amp;#34;plugin:flowtype/recommended&amp;#34;, 10 &amp;#34;vue&amp;#34; 11 ], 12 &amp;#34;rules&amp;#34;: { 13 &amp;#34;indent&amp;#34;: 0, 14 &amp;#34;semi&amp;#34;: 0, 15 &amp;#34;camelcase&amp;#34;: 0, 16 &amp;#34;no-console&amp;#34;: 0 17 } 18} plugins中指定的是eslint的插件：html引入vue中html内容的lint；flowtype引入的是Flow方面的lint； extends中指定的是ESLint的Rules集合。通常我们会在网上找到一些已经成熟的Lint规则集合，它们经过实践证明是有效的。我们可以使用一些这种规则的集合，然后通过后面的rules配置微调一些不同的地方。这样可以减少很多配置的工作量。上面配置中指定了三个集合。 各个公司或者各个项目都会有一些例外，指定了上面的推荐规则集之后可以通过rules进行微调。 3.3.2 .eslintignore eslint默认会扫描项目下的所有文件，通过.eslintignore可以将不需要检查的内容屏蔽掉。例如：node_modules中的第三方库；dist下面的Babel编译后的文件等。
1# node_modules 2node_modules/* 3 4# flow-typed: flow typed libdefs 5flow-typed/* 6 7# vendor: vendor library 8**/vendor/*.js 9 10# dist: generated by babel compiliation 11dist/* 3.4 VSCode 在VSCode中我们需要安装ESLint这个插件，方法很简单，搜索“ESLint”，安装ESLint这个插件就可以了。
3.4.1 settings.json 安装ESLint之后还需要进行一些设置，关闭VSCode本身的Javascript校验机制，另外还需要配置一下，否则会对.vue文件无效。配置如下（选择首选项-设置即可）：
1... 2	&amp;#34;javascript.validate.enable&amp;#34;: false, 3 &amp;#34;eslint.validate&amp;#34;: [ 4 &amp;#34;javascript&amp;#34;, 5 &amp;#34;javascriptreact&amp;#34;, 6 &amp;#34;html&amp;#34;, 7 &amp;#34;vue&amp;#34; 8 ] 9 ... 完成上述配置之后，VSCode中的ESLint就配置完毕了。重启一下VSCode，随便打开一个js文件或者.vue文件，应该就能够看到配置后的效果了。
3.5 Webpack 首先是安装Flow需要的插件。Flow代码会在Babel编译的时候完全去除掉，从而变成纯粹的Javascript代码。
1npm install babel-plugin-transform-flow-strip-types --save-dev 2npm install babel-plugin-syntax-flow --save-dev 3npm install babel-plugin-transform-class-properties --save-dev 3.5.1 .babelrc 然后在.babelrc中引入这几个插件即可：
1 &amp;#34;plugins&amp;#34;: [ 2 ... 3 &amp;#34;babel-plugin-transform-class-properties&amp;#34;, 4 &amp;#34;babel-plugin-syntax-flow&amp;#34;, 5 &amp;#34;babel-plugin-transform-flow-strip-types&amp;#34; 6 ... 7 ] 4. 一些失败的方案 4.1 vscode-flow-ide &amp;amp; flow-language-support 这两个是VSCode的插件，看介绍能够直接对JS文件进行Flow方面的Lint工作，能够发现Flow方面的问题。但是使用中发现无法对.vue文件进行这种工作，所以最后放弃掉了。
4.2 eslint-plugin-flowtype-errors 这个插件也是与eslint配合的。配置比eslint-plugin-flowtype简单。但是它没有办法自定义Rules。其中有个规则用于检测require模块是否存在的。因为我们不会对第三方库进行Flow扫描，所有Flow无法知道第三方库（例如element-ui）是个什么情况。这时就会报出Required module not found这个提示，网上目前也没有好的解决办法。需要手写libdef文件或者使用flow-typed工具生成libdef文件来解决。最后发现使用起来反倒麻烦了。所以最后放弃掉，切换到eslint-plugin-flowtype。
附录 强类型 JavaScript 的解决方案 Vue 2.0 为什么选用 Flow 进行静态代码检查而不是直接使用 TypeScript？ </content>
    </entry>
    
     <entry>
        <title>Node.js 使用Redis发布订阅模式</title>
        <url>https://orchidflower.github.io/2017/03/30/Nodejs-using-redis-publish-subscribe/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Node.js</tag><tag>Redis</tag>
        </tags>
        <content type="html"> 1. 背景 最近在用Node.js做一个管理系统的时候碰到了一个场景：为了访问性能，系统在内存中（不是Redis）缓存了一些常用数据，例如系统菜单树之类的。但是什么时候刷新这些缓存就成了问题。当然在单服务器模式下也不是大问题，只要在更新数据的时候删除内存中的缓存数据即可。但是这一方法在分布式服务中就无效了：同时会有多个这种系统在跑，但是只有一台服务器接到了处理请求，其他服务器根本没有办法刷新内存中的数据。 当然有人会说将缓存放到Redis中不就解决问题了？但是如果数据量稍大一些，而且访问频繁、更新却不频繁，放到Redis中每次访问都会对Redis带来不小的压力，显得很没有必要。 这种情况下，自然就可以使用Redis的发布订阅机制来解决问题了：当数据更新之后，只要发布一个消息到Redis，所有服务器都可以收到消息，执行刷新缓存的操作了。
2. Redis发布订阅机制介绍 Redis 发布订阅(pub/sub)是一种消息通信模式。有两类参与者：发送者(pub)发送消息，订阅者(sub)接收消息。发布者和订阅者通过频道（Channel）进行沟通。发布者发布消息到指定频道上，订阅者订阅特定的频道，获取发布者发布的消息。
下图展示了频道 channel1 ，以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系： 当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端： 3. 代码示例 使用Node.js调用Redis的发布订阅机制非常简单。我用的Redis客户端是：node_redis。
基本上把所有功能都封装到了cache-service中。发布者、订阅者的代码基本上与Redis无关了，理论上可以切换到其他同类的服务上去。 注：代码使用ES2017的特性（await/async）。
3.1 cache-services.js 1// 订阅接口 2// channel 需要订阅的channel 3// callback 处理订阅的消息的回调函数，可以为async function 4exports.subscribe = async function(channel, callback) { 5 // 读取redis配置信息 6 var redisConfig = config.get(&amp;#34;redis&amp;#34;); 7 var options = { 8 host: redisConfig.host, 9 port: redisConfig.port, 10 user: redisConfig.user, 11 password: redisConfig.password, 12 db: redisConfig.database 13 }; 14 // 创建redis client 15 var subClient = redis.createClient(options); 16 // 添加订阅监听处理函数 17 subClient.on(&amp;#34;message&amp;#34;, async function(channel, message) { 18 logger.info(format.vsprintf(&amp;#34;Received subscribe message, channel [%s] message [%s]&amp;#34;, [channel, message])); 19 // 调用回调函数 20 await callback(channel, message); 21 }); 22 // 开始订阅 23 subClient.subscribe(&amp;#34;channel_update_permissions&amp;#34;); 24 // 订阅成功 25 subClient.on(&amp;#34;ready&amp;#34;, function() { 26 logger.info(format.vsprintf(&amp;#39;Redis [%s:%s/%s] is connected and ready for subscribe channel [%s] use.&amp;#39;, [redisConfig.host, redisConfig.port, redisConfig.database, channel])); 27 }); 28 // 错误处理 29 redisClient.on(&amp;#34;error&amp;#34;, function (err) { 30 logger.error(&amp;#34;Subscribe channel [&amp;#34;&#43;channel&#43;&amp;#34;] encountered error. Error:&amp;#34; &#43; err); 31 }); 32 // 将client加到全局map中，以备后用 33 subscribeClients.set(channel, subClient); 34}; 35 36// 调用publish功能。使用普通redis client即可 37exports.publish = async function(channel, message) { 38 await redisClient.publish(channel, message); 39}; 说明：按照node_redis官方文档的说明，调用了subscribe的客户端将进入订阅模式，无法执行其他操作。因此这里每次都创建一个新的redis连接，并且设置了一个内部表，用于保存这些创建的链接。
When a client issues a SUBSCRIBE or PSUBSCRIBE, that connection is put into a &amp;ldquo;subscriber&amp;rdquo; mode. At that point, only commands that modify the subscription set are valid and quit (and depending on the redis version ping as well). When the subscription set is empty, the connection is put back into regular mode.
3.2 调用订阅功能，监听事件。在必要的时候自动加载权限表 1// 加载权限表 2async function initPermssionTable() { 3} 4 5// 系统启动的时候自动加载权限表 6(async function() { 7 permissionTable = await initPermssionTable(); 8 logger.info(&amp;#34;Permission table initialized.&amp;#34;); 9 cacheServices.subscribe(&amp;#34;channel_update_permissions&amp;#34;, async function(channel, message) { 10 logger.info(&amp;#34;Try to reload permission table....&amp;#34;); 11 permissionTable = await initPermssionTable(); 12 logger.info(&amp;#34;Permission table reloaded successfully!&amp;#34;); 13 }); 14})(); 3.3 发布通知 1 ... 2 // 更新全局权限表，通过redis.publish实现 3 await cacheServices.publish(&amp;#34;channel_update_permissions&amp;#34;, &amp;#34;anything&amp;#34;); 4 ... 附录A. 参考资料 Node.js Redis on Github Redis 发布订阅 Redis Pub/Sub: Howto Guide </content>
    </entry>
    
     <entry>
        <title>Docker for Mac磁盘性能低下的解决办法</title>
        <url>https://orchidflower.github.io/2017/03/29/Performance-regression-on-Docker-for-Mac/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>Mac</tag>
        </tags>
        <content type="html"> 最近备份恢复Gogs的时候，发现同样的配置参数在Mac上访问Gogs的用户首页特别慢，大概耗时8秒，而在Linux上面运行的时候不到1秒钟。后来就上网搜索，加上自己试验，最后找到了原因应该是Gogs镜像本身的问题（可能是采用了alpine这一内核，但是具体原因不详，有待进一步实验）。
这个过程中曾经怀疑是Docker运行MySQL过慢的原因，虽然最终发现不是，但是搜索过程中发现了Docker for Mac确实有性能问题，那就是对大量磁盘IO的操作性能会非常差，大概会差10倍。
具体讨论可以看附录的帖子，这里大概摘录一下：
It seems the VM calls the virtio-blk implementation of flush in hyperkit approximately 25000 times. Each of these is implemented currently by an fsync(F_FULLFSYNC) to avoid writes being partially written or re-ordered over a power loss (as recommended by the Apple docs). Unfortunately each fsync(F_FULLFSYNC) seems to take about 10ms which accounts for the slowdown.
I agree that there are important use-cases where data persistence is less important than throughput, especially on developer setups or CI builds where containers are ephemeral. I&amp;rsquo;ll investigate the possibility of a configuration option.
解决办法 帖子里面也给出了解决办法，就是通过修改配置文件。以下方法适应于17.03.0-CE。
1$ cd ~/Library/Containers/com.docker.docker/Data/database/ 2git reset --hard 3HEAD is now at 5e56922 last-start-time changed at 1487162086 4$ echo os &amp;gt; com.docker.driver.amd64-linux/disk/on-flush 5$ git add com.docker.driver.amd64-linux/disk/on-flush 6$ git commit -s -m &amp;#39;Use fsync&amp;#39; 7[master d0b523f] Use fsync 8 1 file changed, 1 insertion(&#43;), 1 deletion(-) 附录A. 参考资料 Severe Docker 1.12.1 performance regression with DB2 images (~10x slower) #668 </content>
    </entry>
    
     <entry>
        <title>Electron开发使用Vue Devtools</title>
        <url>https://orchidflower.github.io/2017/03/29/Using-Vue-Devtools-in-Electron/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Electron</tag><tag>Vue.js</tag>
        </tags>
        <content type="html"> 最近在用Electron &#43; Vue.js 2.0写一个桌面工具。使用下来感觉Electron用起来还是挺爽的。之前为了开发跨平台的桌面应用，我曾经用过Python&#43;wxPython，Swing，SWT等各种技术，但是都有这样那样的问题（例如打包比较麻烦、界面各平台不太一致等）。而Electron基于目前成熟的前端技术，通过内嵌的浏览器内核实现了统一的表现形式，这一点用于做跨平台开发真是太方便了。
1. Electron介绍 Electron技术出现已经有几年了。这里只是简单记录一下：
简而言之，Electron 提供了一个实时构建桌面应用的纯 JavaScript 环境。Electron 可以获取到你定义在 package.json 中 main 文件内容，然后执行它。通过这个文件（通常我们称之为 main.js），可以创建一个应用窗口，这个应用窗口包含一个渲染好的 web 界面，还可以和系统原生的 GUI 交互。
具体来说，就是当你启动了一个 Electron 应用，就有一个主进程（main process ）被创建了。这条进程将负责创建出应用的 GUI（也就是应用的窗口），并处理用户与这个 GUI 之间的交互。
但直接启动 main.js 是无法显示应用窗口的，在 main.js 中通过调用BrowserWindow模块才能将使用应用窗口。然后每个浏览器窗口将执行它们各自的渲染器进程（ renderer process ）。渲染器进程将会处理一个真正的 web 页面（HTML &#43; CSS &#43; JavaScript），将页面渲染到窗口中。鉴于 Electron 使用的是基于 Chrominum 的浏览器内核，你就不太需要考虑兼容的问题。
kmokidd 使用 Electron 构建桌面应用
2. 安装Vue Devtools 今天主要讲一下怎么在Electron中安装Vue devtools，以方便开发。方法参考Electron官方文档，这里只做记录和翻译。
2.1 特别说明 因为Electron是基于Chromium内核的，和Chrome同根同源。因此这里的方法是在Chrome安装Dev Vuetools，然后添加到Electron中的方法。
2.2 安装步骤 首先在Chrome中安装Vue Devtools； 在Chrome中打开about:extensions，并且开启开发者模式，这样就可以获取扩展程序的ID，记住这个ID，例如我这边的值是nhdogjmejiglipccpnnnanhbledajbpd，下面需要用到。 打开文件管理器或者Finder，导航到Chrome保存扩展程序的文件夹： 在Windows上：%LOCALAPPDATA%\Google\Chrome\User Data\Default\Extensions 在Linux可能是（看不同的版本）： ~/.config/google-chrome/Default/Extensions/ ~/.config/google-chrome-beta/Default/Extensions/ ~/.config/google-chrome-canary/Default/Extensions/ ~/.config/chromium/Default/Extensions/ 在Mac上是：~/Library/Application Support/Google/Chrome/Default/Extensions 在上面的文件夹中找到刚才获取的ID对应的那个文件夹，打开，记录下文件夹中存在的文件夹名字，一般是版本号。这样就获取了最终需要使用的文件夹地址。例如我这边这个地址是：~/Library/Application Support/Google/Chrome/Default/Extensions/nhdogjmejiglipccpnnnanhbledajbpd/3.1.2_0。 在Electron应用中添加如下代码： 1app.on(&amp;#39;ready&amp;#39;, createWindow) 2 3function createWindow() { 4 ... 5 // Open the DevTools. 6 if (process.env.NODE_ENV === &amp;#39;development&amp;#39;) { 7 BrowserWindow.addDevToolsExtension(&amp;#34;/Users/zhang/Library/Application Support/Google/Chrome/Default/Extensions/nhdogjmejiglipccpnnnanhbledajbpd/3.1.2_0&amp;#34;); 8 } 9 ... 10} 2.3 限制 BrowserWindow.addDevToolsExtension需要在ready事件之后调用，我上面的代码就是在app的ready事件中调用的； Electron版本不能低于1.2.1，因为对Extension tools的支持API是这个版本添加的。 附录A. 参考资料 Using DevTools Extension in Electron Vue-devtools for Electron apps </content>
    </entry>
    
     <entry>
        <title>在Ubuntu 14.04上安装Docker 17.03.0-ce</title>
        <url>https://orchidflower.github.io/2017/03/28/install-docker-17-03-0-ce-on-ubuntu-14-04/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Docker</tag>
        </tags>
        <content type="html"> 0. 概述 Docker在1.13.x版本之后更新了版本号规则，区分了社区版和企业版。这导致了安装方式有所变化。所以特意参考官方的帮助重新整理了一下安装步骤。
适应范围：Ubuntu 14.04。安装版本：17.03.0-ce（社区版）。
1. 依赖安装 1.1 curl等依赖 1sudo apt-get -y install \ 2 apt-transport-https \ 3 ca-certificates \ 4 curl 1.2 add-apt-repository 官方的文档中遗漏了对这个的安装，所以直接按照官方文档安装会在用到这个工具的时候报错。我们首先要安装它。它的作用是维护apt的source.list文件，可以添加一个源。
1sudo apt-get install software-properties-common python-software-properties 2. 开始安装 2.1 安装gpg-key 1curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 2.2 添加apt源 1sudo add-apt-repository \ 2 &amp;#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ 3 $(lsb_release -cs) \ 4 stable&amp;#34; 2.3 安装Docker ce 1sudo apt-get update 2sudo apt-get -y install docker-ce 3. 验证 1sudo docker run hello-world 附录A. 参考资料 Docker Community Edition for Ubuntu installation Ubuntu Missing add-apt-repository command </content>
    </entry>
    
     <entry>
        <title>Node.js从入门到放弃（一）-基础知识</title>
        <url>https://orchidflower.github.io/2017/02/27/nodejs-learning-note-01/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Node.js</tag><tag>前端</tag>
        </tags>
        <content type="html"> 最近一周比较忙，一直忙着搭建开发平台。之前不就刚用Golang搭建了一个服务端开发平台。完成之后，就需要针对Golang开发的服务开发一个管理平台，用Golang也能做，但是感觉还是麻烦，最后决定使用Node.js。
这次搭建的平台倾向于使用比较新的一些Node.js特性，例如ES6、async/await解决回调地狱等。之前用过Node.js，但是属于浅尝辄止，这次准备充分了解一下。因此有了这些学习笔记。
概述 Node.js这几年可以说是如日中天，使用Javascript这种传统意义上的前端开发语言进行后端开发，开发效率成倍提升：省去了编译、发布的过程，开发中服务器重启再也不像Java那么笨重耗时，修改之后秒起的感觉爽得不要不要的。
Node.js的运行效率也还不错，虽然不能和Java、Golang之类的比较，但是对付负载、并发量不大的管理系统还是绰绰有余。因此个人感觉在后台管理系统中使用Node.js正是上佳之选。
本篇主要是Javascript的一些基本知识。来源自网上不同的地方，也有自己写的一些心得。
名词解释 使用Node.js的时候会碰到很多新名词，这里整理了以下经常见到的东西。对概念有个明确的了解有助于之后的学习。
ECMA Ecma国际（Ecma International）是一家国际性会员制度的信息和电信标准组织。1994年之前，名为欧洲计算机制造商协会（European Computer Manufacturers Association）。因为计算机的国际化，组织的标准牵涉到很多其他国家，因此组织决定改名表明其国际性。现名称已不属于首字母缩略字。
ECMAScript 就是Javascript的国际标准。Javascript发布以来出现了很多变种，例如Netscape的Javascript、Microsoft的JScript等等。后来通过ECMA组织重新进行了标准化，形成了ECMAScript。
所以说ECMAScript就是JavaScript语言的正式名称。自从Sun公司宣布拥有JavaScript这个名字之后，商标上出现冲突，所以对JavaScript拥有认证权利的ECMA委员会强制改成这个名字。
历次版本 ECMAScript 1 1997年6月，首版； ECMAScript 2 1998年6月，格式修正，以使得其形式与ISO/IEC16262国际标准一致； ECMAScript 3 1999年12月 强大的正则表达式，更好的文字链处理，新的控制指令，异常处理，错误定义更加明确，数输出的格式化及其它改变； ECMAScript 4 未完成&amp;hellip;可能更明确的类的定义，命名空间等等&amp;hellip; ECMAScript 5 2009年12月发布。2004年6月欧洲计算机制造商协会发表了ECMA-357标准，它是ECMAScript的一个扩延，它也被称为E4X（ECMAScript for XML）。 ECMAScript 2015 2015年6月17日发布。截止发布日期，JavaScript的官方名称是ECMAScript 2015，Ecma国际意在更频繁地发布包含小规模增量更新的新版本，下一版本将于2016年发布，命名为ECMAScript 2016。从现在开始，新版本将按照ECMAScript&#43;年份的形式发布。 ES6 ES6就是ES2015。
ES2016、ES2017 从ES5 2009-ES6 2015经历了6年，语言的变化比较大。为了避免剧烈的变动，从ES7 2016开始，版本发布会变得更加频繁，每次的变动也更小。每年会发布一个新版本，其中包含所有已经完成的特性。所以之后对应的版本就是ES2016、ES2017。。。每一版本都包含一些新增的特性。
ES6目前的兼容情况 Javascript是一门活的语言，最近几年一直在更新。因此很多特性并不是所有环境都已经支持，包括Node.js、浏览器，会有很多特性并不支持。
对于Node.js兼容情况，可以通过网站 Node green: es2015 support status 查看。浏览器兼容情况可以通过网站 es2015 compatibility status 查看。
为了在项目中使用ES6的特性，对于后端开发，可以选择新版本的Node.js或者使用Babel进行编译；对于前端来说，Babel是唯一的选择。
TC39 Process TC39 TC39（Technical Committee 39）是一个推动JavaScript发展的委员会，受特许解决JavaScript语言相关事宜。它的成员由各个主流浏览器厂商的代表构成。会议的每一项决议必须大部分人赞同，并且没有人强烈反对才可以通过。因为，对成员来说，同意就意味着有责任去实现它。
每一项新特性，要最终纳入ECMAScript规范中，TC39拟定了一个处理过程，称为TC39 process。其中共包含5个阶段，Stage 0 ~ Stage 4。
Stage 0: strawman 一种推进ECMAScript发展的自由形式，任何TC39成员，或者注册为TC39贡献者的会员，都可以提交。
Stage 1: proposal 该阶段产生一个正式的提案。 （1）确定一个带头人来负责该提案，带头人或者联合带头人必须是TC39的成员。 （2）描述清楚要解决的问题，解决方案中必须包含例子，API以及关于相关的语义和算法。 （3）潜在问题也应该指出来，例如与其他特性的关系，实现它所面临的挑战。 （4）polyfill和demo也是必要的。
Stage 2: draft 草案是规范的第一个版本，与最终标准中包含的特性不会有太大差别。 草案之后，原则上只接受增量修改。 （1）草案中包含新增特性语法和语义的，尽可能的完善的形式说明，允许包含一些待办事项或者占位符。 （2）必须包含2个实验性的具体实现，其中一个可以是用转译器实现的，例如Babel。
Stage 3: candidate 候选阶段，获得具体实现和用户的反馈。 此后，只有在实现和使用过程中出现了重大问题才会修改。 （1）规范文档必须是完整的，评审人和ECMAScript的编辑要在规范上签字。 （2）至少要有两个符合规范的具体实现。
Stage 4: finished 已经准备就绪，该特性会出现在年度发布的规范之中。 （1）通过Test 262的验收测试。 （2）有2个通过测试的实现，以获取使用过程中的重要实践经验。 （3）ECMAScript的编辑必须规范上的签字。
按照上述的流程，一个特性从Stage 0走到Stage 4就算正式发布了。正式发布的特性将被加入到当年的版本中，例如变成ES2017或者ES2018的新特性。
Babel Babel是一个转换编译器，它能将ES6转换成可以在浏览器中运行的代码。Babel由来自澳大利亚的开发者Sebastian McKenzie创建。他的目标是使Babel可以处理ES6的所有新语法，并为它内置了React JSX扩展及Flow类型注解支持。
据codemix创始人Charles Pick介绍，Babel是所有ES6转换编译器中与ES6规范兼容度最高的，甚至超过了谷歌创建已久的Traceur编译器。Babel允许开发者使用ES6的所有新特性，而且不会影响与老版本浏览器的兼容性。此外，它还支持许多不同的构建&amp;amp;测试系统，使开发者很容易将它集成到自己的工具链中。 Charles认为，Babel从根本上讲是一个平台，这是它与compile-to-JS语言CoffeeScript和TypeScript最大的不同。Babel的插件系统允许开发者自定义代码转换器并插入到编译过程。这些转换器会接收一棵抽象语法树，并在代码转换成可执行的JavaScript之前对其进行操作。codemix已经尝试开发了静态&amp;amp;运行时类型检查、闭包消除、JavaScript“健康宏（hygienic macros）”等插件。 Babel不仅跟踪ES6的进展情况，而且还是ES7或ES2016的试验场。比如，它已经支持async/await， 使开发者更容易编写异步JavaScript代码，而且与使用回调或Promises相比，代码更简洁易懂。虽然主流浏览器可能还需要几年的时间才能支持 这种异步JavaScript代码编写方式，但Babel使开发者现在就可以用上它。这得益于Babel与JavaScript技术委员会（TC39）保持着高度一致，能够在ECMAScript新特性标准化之前为开发者提供现实世界可用的实现。而同时，这也有利于JavaScript的进一步发展，因为其团队可以在ECMAScript规范最后定稿前就获得来自现实世界的反馈。 Babel还能提升JavaScript的执行速度。由于JavaScript 文件加载和执行速度慢会严重影响用户体验，所以JIT没有时间在运行时执行所有技术上可行的优化。相比之下，Babel是在编译时运行，没有这么严格的时 间限制。借助强大的作用域跟踪和类型推断功能及插件系统，开发者可以构建转换器来执行此类优化，比如上文提到的闭包消除可以将闭包转换成平常的函数。
下一篇博客将重点讲一下Babel的生态系统及简单的使用。
附录. 参考资料 Node green: es2015 support status es2015 compatibility status ES6 Browser Support detection </content>
    </entry>
    
     <entry>
        <title>安装Go语言调试工具dlv</title>
        <url>https://orchidflower.github.io/2017/02/15/install-golang-debugger-dlv-on-mac/</url>
        <categories>
          <category>开发</category>
        </categories>
        <tags>
          <tag>Golang</tag><tag>Dlv</tag><tag>调试</tag>
        </tags>
        <content type="html"> Dlv，也成为Delve，是Go语言的源码调试工具。由derekparker开发，开源与Github。在Mac上配置Go语言开发环境的时候，经常碰到的问题就是Dlv调用总是不成功，无法启动应用，无法调试等等。大部分的问题都与Mac的安全机制有关。Mac上使用codesign对应用进行签名，没有签名的程序会受到一些限制，例如无法作为调试程序。
当然如果为了方便，你可以通过Homebrew安装Homebrew编译好的Dlv。下面描述的是如何从源码构建这一工具。Delve作者专门写了一篇文档（请看附录的链接），描述如何对Dlv进行自签名。方法是生成一个自签名的证书，然后从源码编译安装Dlv。
0. 前提 需要安装Xcode命令行工具。运行以下命令安装：
1xcode-select --install 1. 签名证书准备 1.1 第一步：创建证书 打开钥匙串访问； 菜单栏中选择钥匙串访问-证书助理-创建证书开始创建自签名证书； 证书名称设置为dlv-cert（记住这个名字，后面会用到）；身份类型选择自签名根证书；证书类型选择代码签名，最后在让我覆盖这些默认值处打上勾，选择继续； 在接下来的窗口中把有效期改长一些，例如改成10年（3650天）； 然后一直往后，直到出现选择指定用于该证书的位置，选择钥匙串系统，然后选择创建； 这样证书就创建好了。 1.2 第二部：后续操作 在钥匙串访问窗口左面选择钥匙串系统；然后在右面选择刚才创建的证书（按名字查找，例如dlv-cert）； 点鼠标右键，选择显示简介打开证书详细信息窗口； 在信任一栏中代码签名处选择始终信任，这样使用该证书进行签名操作的时候就不会弹出提示框询问了。 然后在窗口左面选择密钥，在右面根据名字选择对应的专用密钥，点击鼠标右键选择显示简介； 在弹出的窗口中选择访问控制标签页，然后选择允许所有应用程序访问此项目，这样进行调试的时候就不需要每次输入密码了。 1.3 说明 以上步骤请确认执行完毕，否则会出现诸如error: could not launch process: could not fork/exec之类的错误。
2. 安装和签名 证书搞定之后，其他操作就简单了。按照下面命令操作即可。
2.1 下载源码 1mkdir $GOPATH/src/github.com/derekparker &amp;amp;&amp;amp; cd $GOPATH/src/github.com/derekparker 2git clone https://github.com/derekparker/delve.git &amp;amp;&amp;amp; cd delve 2.2 签名安装 1CERT=dlv-cert make install 2.3 升级 升级时不需要重新生成证书，只需要更新源码重新编译签名即可。
附录A. 参考资料 Installation on OSX Mac 平台: 使用 vscode 搭建 Golang 开发环境 Delve on Github Debugging Go code using VS Code </content>
    </entry>
    
     <entry>
        <title>Hexo博客提交搜索引擎</title>
        <url>https://orchidflower.github.io/2017/02/14/submit-to-search-engine/</url>
        <categories>
          <category>博客</category>
        </categories>
        <tags>
          <tag>Hexo</tag><tag>博客</tag>
        </tags>
        <content type="html"> 新博客上线多天之后，通过百度和Google仍然搜索不到我写的内容。忽然意识到这应该是网站没有被搜索引擎索引。经过搜索，发现还真是这么回事。直接搜索：site:orchidflower.oschina.io和site:orchidflower.github.io，发现真的没有找到相关的记录。
经过上网查找原因，找到了一些资料，原来Hexo已经有这方面的解决方案了。
根据网上搜索到的资料，要解决这个问题总体上可以分为两步：
在搜索引擎注册网站； 提交链接信息或者站点地图给搜索引擎。 下面简单描述一下过程。
1. 注册网站 不论Google还是百度都提供了站长工具，可以让网站拥有者自助提交网站信息。相当于给搜索引擎的爬虫指个方向，能够更快速的索引你的网站。相关的网站地址为：Google搜索引擎提交入口，百度提交入口。
1.1 前提条件 首先你要有对应的搜索引擎的账号。因为Google和百度的操作过程基本类似，所以只描述Google的操作步骤。
1.2 步骤 登录Google之后，选择添加一个网址。添加完之后需要做验证。验证的目的是证明你对提交的网址确实有管理权，防止别人胡乱操作。验证的方法有几种，比较方便的有：
1.2.1 HTML验证 验证方式就是将Google提供的文件放置到你网站的根目录上，Google可以访问到就可以了。
所以下载验证文件，放到source目录中，执行hexo deploy重新发布应该就可以了；
1.2.2 HTML标记验证 验证方式就是在网站的页面中添加一个meta属性，这样Google访问网页后可以从中解析出来对应的meta，以此证明网站归你管理。
这种方式Hexo已经提供了内置支持。只需要修改Hexo的_config.yml文件，添加如下内容即可：
1google_site_verification: [your code from google] 2baidu_site_verification: [your code from baidu] 添加之后，执行hexo generate; hexo deploy，应该就可以了。
1.2.3 完成验证 无论采取上面那种方式，博客重新发布之后就可以在Google中点击验证确认网站所有权了。正常情况下，这样研究就通过了。如果碰到问题，请仔细检查以上几步是否有操作错误。
2. 提交链接信息 要让搜索引擎索引我们的网站，比较好的方法是提交站点地图文件（sitemap.xml）给搜索引擎。
站点地图文件是一个xml文件，其中包含了我们网站所有有效的链接，这样搜索引擎可以直接从中抓取有用的链接，理论上可以不用使用爬虫对网站进行扫描了。
幸运的是Hexo目前有插件可以很方便的生成站点地图文件。生成的文件会随着deploy发布到我们的网站上。这个文件可以通过url直接访问到，我们只需要将这个url提交给所搜引擎即可，不用每次更新之后再次提交。一次提交，终生受益:)
2.1 安装插件 首先是安装插件。这两个插件实际上的功能差不多，如果你只有一个域名，提交给Google和百度的站点地图文件是一样的，那随便安装哪一个都可以。但是如果你有多个域名（镜像），像我这样在Github和OSChina上都有站点，那就需要安装两个插件，分别用来生成提交给Google和百度的站点地图文件。
对我来说，使用hexo-generator-sitemap生成提交给Google的文件，里面的链接都是对应网址orchidflower.github.io的；使用hexo-generator-baidu-sitemap生成提交给百度的文件，里面的链接都是orchidflower.oschina.io的。
1npm install hexo-generator-sitemap --save 2npm install hexo-generator-baidu-sitemap --save 2.2 修改 默认情况下，这两个插件生成的url都会使用_config.yml文件中的url属性计算出来的路径。这样实际上生成的两个文件中的链接是一样的，这样不符合我的要求。所以我对hexo-generator-sitemap插件进行了一点修改，从而针对Google的文件里面制定了Github上面的网址。修改方法如下：
修改文件node_modules/hexo-generator-sitemap/sitemap.xml：
1&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; 2&amp;lt;urlset xmlns=&amp;#34;http://www.sitemaps.org/schemas/sitemap/0.9&amp;#34;&amp;gt; 3 {% for post in posts %} 4 &amp;lt;url&amp;gt; 5 &amp;lt;loc&amp;gt;{{ (config.urlforgoogle&#43;post.path) | uriencode }}&amp;lt;/loc&amp;gt; 6 {% if post.updated %} 7 &amp;lt;lastmod&amp;gt;{{ post.updated.toISOString() }}&amp;lt;/lastmod&amp;gt; 8 {% elif post.date %} 9 &amp;lt;lastmod&amp;gt;{{ post.date.toISOString() }}&amp;lt;/lastmod&amp;gt; 10 {% endif %} 11 &amp;lt;/url&amp;gt; 12 {% endfor %} 13&amp;lt;/urlset&amp;gt; 第5行中，使用了一个变量config.urlforgoogle，这里指定了Github站点的地址。具体值可以参考下面的说明。
2.3 配置文件 修改配置文件_config.yml，增加如下内容：
1urlforgoogle: http://orchidflower.github.io/ 2 3# 自动生成sitemap 4sitemap: 5 path: sitemap.xml 6baidusitemap: 7 path: baidusitemap.xml 其中指定了urlforgoogle，配置了提交给Google的站点地图文件中的站点是Github上的。另外两个参数分别指定了两个地图文件的名字。
2.4 提交 分别把http://orchidflower.github.io/sitemap.xml提交给Google；把http://orchidflower.oschina.io/baidusitemap.xml提交给百度。然后就是等待吧。
3. 后续 2.13 提交给Google和百度； 2.14 已经能够通过Google搜索到；百度还不行。 附录A. 参考资料 hexo干货系列：（六）hexo提交搜索引擎（百度&#43;谷歌） Hexo&#43;Next主题博客提交百度谷歌收录 </content>
    </entry>
    
     <entry>
        <title>从一台没有外网连接的阿里云主机上访问微信API</title>
        <url>https://orchidflower.github.io/2017/02/12/access-weixin-qyapi-from-one-server-without-internet-on-aliyun/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>阿里云</tag><tag>Ubuntu</tag><tag>微信</tag>
        </tags>
        <content type="html"> 1. 背景 公司的生产环境是部署在阿里云上的。Zabbix最初装在一台没有外网连接的ECS上，通过Nginx进行访问。但是后来发现如果需要报警，需要从Zabbix这台主机访问微信公众号服务器（qyapi.weixin.qq.com）。运维的兄弟最初选择了固定带宽的网络，但是考虑到费用问题，后期想切换到按量付费的网络，但是阿里云居然不支持这种切换（这里吐槽一下阿里的设计）。
由于该主机是按照包月包年方式购买的，退掉重新申请主机安装Zabbix显然不划算。在主机到期之前，必须想办法实现在没有外网的情况下访问微信服务器（考虑到费用问题，原先固定带宽已经被修改成了0M，也就没有费用了）。
2. 解决 考虑到整个生产环境中有多台能够访问Internet的主机，所以自然的想到是不是可以通过其他主机中转这种访问呢？
2.1 Nginx 最先想到的方案是通过Nginx，通过Nginx做一个正向代理，代理到微信公众号服务器（ https://qyapi.weixin.qq.com ），然后通过从Zabbix访问Nginx代理后的站点。但是通过搜索发现，Nginx不支持这种代理方式（Forward Proxy）连接https服务器。具体的可以看附录中的连接。以下是Nginx作者的答复：
1&amp;gt; Is there any schedule to support the feathure, forward proxy ? 2Not in near future: there is alreay good forward proxy Squid. 2.2 iptables 然后又想到是不是可以使用iptables进行端口转发呢？但是可能是我对iptables还不够熟悉，按照附录4的命令总也调试不成功，总是会返回超时。这个方法没有解决问题。
2.3 socat 这时想起以前用过一个小工具socat，用它将一个unix socket转换成一个tcp socket，它的用处就是将一个流转换成另一个流。经过尝试果然可以。命令也很简单：
1socat TCP-LISTEN:443,fork,reuseaddr TCP:140.207.127.79:443 然后在Zabbix主机上使用curl访问试试：
1root@prd-zabbix:~# curl https://192.168.61.64 2curl: (51) SSL: certificate subject name &amp;#39;qy.weixin.qq.com&amp;#39; does not match target host name &amp;#39;192.168.61.64&amp;#39; 已经可以访问了，说明服务已经中转到微信的服务器上了。
3. 后续操作 3.1 域名 上面使用curl出现的提示表明，我们必须使用域名进行访问才能够被正确处理。这一点可以通过本地域名映射进行解决。可以通过修改/etc/hosts增加映射的方式解决。因为我们本地的Zabbix是通过Docker运行的，这个修改就要通过Docker运行。我们使用的是docker-compose，在docker-compose.yaml中增加如下配置即可：
1extra_hosts: 2 - &amp;#34;qyapi.weixin.qq.com:192.168.61.64&amp;#34; 这样，在Zabbix运行的容器中，域名qyapi.weixin.qq.com指向了192.168.61.64这台主机。而对这台主机上的443端口的访问被重定向到了140.207.127.79:443，从而实现了对微信公众号服务器的访问。
3.2 多服务器 使用nslookup查询可以知道对应于域名qyapi.weixin.qq.com，微信是提供了多台服务器的：
1root@prd-zabbix:~# nslookup qyapi.weixin.qq.com 2Server: 100.100.2.138 3Address: 100.100.2.138#53 4 5Non-authoritative answer: 6qyapi.weixin.qq.com canonical name = qy.weixin.qq.com. 7Name: qy.weixin.qq.com 8Address: 140.207.189.106 9Name: qy.weixin.qq.com 10Address: 140.207.127.79 上面的解决方案中只指向了一台服务器，这样如果这台服务器出现问题的时候可能会导致访问失败。可以考虑的一个方案是在另一台主机上使用socat做同样的转发工作，只是转发给另一台主机。这样应该可以解决部分问题。但是还不是最完美的解决方案。有待于以后继续研究。
3.3 自启动 需要考虑服务器重启的情况下，要自动启动socat。这个在Ubuntu上可以通过修改/etc/rc.local文件解决：
1socat TCP-LISTEN:443,fork,reuseaddr TCP:140.207.127.79:443 &amp;amp; 2exit 0 附录A. 参考资料 Re: https and nginx as forward proxy Nginx as forward proxy for HTTPS Lets Talk About Proxies, Pt. 2: Nginx as a Forward HTTP Proxy - See more at: https://blog.opendns.com/2015/11/03/lets-talk-about-proxies-pt-2-nginx-as-a-forward-http-proxy/ Forward a TCP port to another IP or port using NAT with Iptables socat port forwarding for https Execute a Script at Startup and Shutdown on Ubuntu </content>
    </entry>
    
     <entry>
        <title>在Mac上启用Docker的Bash Completion</title>
        <url>https://orchidflower.github.io/2017/02/12/enable-docker-bash-completion-on-mac/</url>
        <categories>
          <category>运维</category>
        </categories>
        <tags>
          <tag>Docker</tag><tag>Mac</tag><tag>Bash</tag>
        </tags>
        <content type="html"> 1. 背景 在Ubuntu上使用Docker的时候，使用tab键自动完成docker命令感觉非常方便，例如：只需要输入image或者container ID的前几位就可以使用Tab键补齐整个命令行。但是在Mac上却没有办法实现相同的操作。
经过搜索终于找到了原因：原来是因为没有启用Bash completion功能导致的。而实际上Docker安装包内已经提供了针对Docker的Bash Completion脚本，只需要启用即可。
2. 安装 要启用Docker的Bash Completion功能，需要满足两个条件：
你用的是Bash这个shell（好像废话了，嘿嘿）； 安装有Bash completion这个功能。 但是Mac上默认是没有安装Bash completion功能的。需要通过Homebrew进行安装。如果之前没有安装过Homebrew，首先参考附录安装。
2.1 安装bash-completion 安装bash-completion。方法如下：
1brew install bash-completion 2.2 启用bash-completion 然后将/Applications/Docker.app/Contents/Resources/etc目录中的docker-compose.bash-completion,docker.bash-completion两个文件拷贝到/usr/local/etc/bash_completion.d目录中。
最后修改.bash_profile，增加如下内容即可：
1[ -f /usr/local/etc/bash_completion ] &amp;amp;&amp;amp; . /usr/local/etc/bash_completion 附录A. 参考资料 Command Line Completion Homebrew Official Website 附录B. Homebrew使用记录 1zhang@zhangdeMacBook-Pro:~$ brew info bash-completion 2bash-completion: stable 1.3 (bottled) 3Programmable completion for Bash 3.2 4https://bash-completion.alioth.debian.org/ 5/usr/local/Cellar/bash-completion/1.3_1 (189 files, 607.8K) * 6 Poured from bottle on 2017-01-16 at 18:09:59 7From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/bash-completion.rb 8==&amp;gt; Caveats 9Add the following lines to your ~/.bash_profile: 10 [ -f /usr/local/etc/bash_completion ] &amp;amp;&amp;amp; . /usr/local/etc/bash_completion 11 12Bash completion has been installed to: 13 /usr/local/etc/bash_completion.d </content>
    </entry>
    
     <entry>
        <title>使用Hexo搭建个人博客</title>
        <url>https://orchidflower.github.io/2017/01/24/hexo-deploy/</url>
        <categories>
          <category>博客</category>
        </categories>
        <tags>
          <tag>Hexo</tag><tag>博客</tag>
        </tags>
        <content type="html"> 0. 什么是Hexo Hexo 是高效的静态站点生成框架，它基于 Node.js。 通过 Hexo 你可以轻松地使用 Markdown 编写文章，除了 Markdown 本身的语法之外，还可以使用 Hexo 提供的 标签插件 来快速的插入特定形式的内容。 网上关于Hexo介绍的文章已经很多，这里不写一般的安装部署步骤，只写一些不常提到的地方。
1. 主题 主题首推Next（ https://github.com/iissnan/hexo-theme-next ），该主题可定制性高，而且集成了很多第三方插件，使用起来非常方便。
个人感觉Next有几点功能做的非常棒：
文章可以带有导航功能，只需要配置好主题参数，就可以在侧栏中显示文章的导航信息，这对于比较长的博文来说非常实用； 集成了很多实用的第三方服务。例如：数据统计（百度、Google、通讯等）、内容分享服务、评论系统、搜索服务等，能够满足大部分人的需要，不需要额外定制其他功能了； 除了第三方搜索服务以外，还提供了本地搜索服务，搜索速度很快，也不依赖于第三方，非常方便快捷。 2. 网页托管 Hexo生成的静态页面可以部署到任何Web服务器中。当然对于普通用户来说，没有自己的服务器，这时可以通过Github Pages功能或者OSChina Pages功能部署到Github或者OSChina上去。
2.1 Github 作为Github，我们会有一个二级域名：[yourname].github.io，如果要将我们的博客内容部署到这个地址上，则需要按照Github的要求创建一个名字叫[yourname].github.io（注意替换[yourname]部分为你自己的名字）的项目，然后把页面上传到里面。
2.2 OSChina 作为OSChina的用户，我们会有一个二级域名：[yourname].oschina.io。我们需要创建一个仓库，名字和你的名字相同即可。
3. 定制 根据自己的需要，我对Next主题主要调整了以下几处参数：
切换Schema到Pisces，调整侧边栏到左侧； 菜单中增加about、categories等栏目； 启用本地搜索功能，通过侧边栏的搜索功能可以访问到； 启用了duoshuo提供的评论系统； 启用了Leancloud提供的阅读技术功能； 3.1 附加说明 考虑到安全原因，使用Leancloud服务的时候一定要设置Web安全域名，限制能够更新数据的网站，具体可以参考附录中的说明。
附录. 参考资料 Hexo中文文档 Hexo主题Next 为NexT主题添加文章阅读量统计功能 </content>
    </entry>
    
     <entry>
        <title>安个新家</title>
        <url>https://orchidflower.github.io/2017/01/22/hello-world/</url>
        <categories>
          
        </categories>
        <tags>
          
        </tags>
        <content type="html"> 一直找不到合适的博客供应商，之前用过CSDN，体验一直不好。最近在研究Node.js，所以发现了Hexo Hexo，感觉还是不错的，挺有兴趣尝试一下的。所以在oschina上开通了Pages功能，以后就在这儿安家了。
</content>
    </entry>
    
</search>